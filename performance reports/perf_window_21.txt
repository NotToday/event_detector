Sents length :  43592  Anchor length :  43592  Vocab length :  8777
dimension: 300, train_size: 30514, test_size: 6538, length: 21
anchor dimension  (30514,)
Writing to /home/soumyadeep/EventDetection/runs/1523702904

training: 1.3099324703216553 epoch = 0 step = 1 loss = 3.782722234725952
training: 0.4986546039581299 epoch = 0 step = 2 loss = 3.6814985275268555
training: 0.5356380939483643 epoch = 0 step = 3 loss = 3.6383163928985596
training: 0.4901289939880371 epoch = 0 step = 4 loss = 3.539092779159546
training: 0.5103104114532471 epoch = 0 step = 5 loss = 3.4806528091430664
training: 0.5499539375305176 epoch = 0 step = 6 loss = 3.3769876956939697
training: 0.4528183937072754 epoch = 0 step = 7 loss = 3.340869903564453
training: 0.5165386199951172 epoch = 0 step = 8 loss = 3.1644208431243896
training: 0.6232779026031494 epoch = 0 step = 9 loss = 3.1131210327148438
training: 0.5110528469085693 epoch = 0 step = 10 loss = 3.1472060680389404
training: 0.48461484909057617 epoch = 0 step = 11 loss = 2.957915782928467
training: 0.4347255229949951 epoch = 0 step = 12 loss = 3.016974925994873
training: 0.6825721263885498 epoch = 0 step = 13 loss = 3.0622966289520264
training: 0.4897730350494385 epoch = 0 step = 14 loss = 2.9943900108337402
training: 0.49309635162353516 epoch = 0 step = 15 loss = 2.775184154510498
training: 0.5302009582519531 epoch = 0 step = 16 loss = 2.8240597248077393
training: 0.6596992015838623 epoch = 0 step = 17 loss = 2.834566354751587
training: 0.46344661712646484 epoch = 0 step = 18 loss = 2.6963162422180176
training: 0.47774720191955566 epoch = 0 step = 19 loss = 3.056218385696411
training: 0.42349672317504883 epoch = 0 step = 20 loss = 2.7145793437957764
training: 0.752025842666626 epoch = 0 step = 21 loss = 2.856154203414917
training: 0.49513888359069824 epoch = 0 step = 22 loss = 2.769489288330078
training: 0.5215458869934082 epoch = 0 step = 23 loss = 2.8610591888427734
training: 0.4530453681945801 epoch = 0 step = 24 loss = 2.9484481811523438
training: 0.6900689601898193 epoch = 0 step = 25 loss = 2.7015810012817383
training: 0.47730493545532227 epoch = 0 step = 26 loss = 2.8580727577209473
training: 0.5243077278137207 epoch = 0 step = 27 loss = 2.751890182495117
training: 0.4343717098236084 epoch = 0 step = 28 loss = 2.848466157913208
training: 0.6850435733795166 epoch = 0 step = 29 loss = 2.7936313152313232
training: 0.6336750984191895 epoch = 0 step = 30 loss = 2.6512186527252197
training: 0.48831820487976074 epoch = 0 step = 31 loss = 2.663219928741455
training: 0.6920473575592041 epoch = 0 step = 32 loss = 2.636643648147583
training: 0.4625132083892822 epoch = 0 step = 33 loss = 2.5145423412323
training: 0.5085330009460449 epoch = 1 step = 34 loss = 2.644716739654541
training: 0.5091497898101807 epoch = 1 step = 35 loss = 2.719984769821167
training: 0.6843826770782471 epoch = 1 step = 36 loss = 2.7432849407196045
training: 0.4994688034057617 epoch = 1 step = 37 loss = 2.5328338146209717
training: 0.5555198192596436 epoch = 1 step = 38 loss = 2.7280631065368652
training: 0.6432323455810547 epoch = 1 step = 39 loss = 2.5630087852478027
training: 0.6458268165588379 epoch = 1 step = 40 loss = 2.592529773712158
training: 0.5267980098724365 epoch = 1 step = 41 loss = 2.7002439498901367
training: 0.5040299892425537 epoch = 1 step = 42 loss = 2.6343538761138916
training: 0.41138458251953125 epoch = 1 step = 43 loss = 2.716722249984741
training: 0.7309935092926025 epoch = 1 step = 44 loss = 2.601935625076294
training: 0.4842350482940674 epoch = 1 step = 45 loss = 2.370326280593872
training: 0.46338319778442383 epoch = 1 step = 46 loss = 2.6058361530303955
training: 0.5712776184082031 epoch = 1 step = 47 loss = 2.5290675163269043
training: 0.5655410289764404 epoch = 1 step = 48 loss = 2.6456446647644043
training: 0.46463489532470703 epoch = 1 step = 49 loss = 2.4612441062927246
training: 0.5443980693817139 epoch = 1 step = 50 loss = 2.6084015369415283
training: 0.521784782409668 epoch = 1 step = 51 loss = 2.5906076431274414
training: 0.6376979351043701 epoch = 1 step = 52 loss = 2.51175856590271
training: 0.5488317012786865 epoch = 1 step = 53 loss = 2.6883656978607178
training: 0.5352847576141357 epoch = 1 step = 54 loss = 2.5066497325897217
training: 0.4492323398590088 epoch = 1 step = 55 loss = 2.38958477973938
training: 0.5887651443481445 epoch = 1 step = 56 loss = 2.2386233806610107
training: 0.5466113090515137 epoch = 1 step = 57 loss = 2.5334854125976562
training: 0.5692641735076904 epoch = 1 step = 58 loss = 2.467858076095581
training: 0.4596982002258301 epoch = 1 step = 59 loss = 2.464390277862549
training: 0.6440808773040771 epoch = 1 step = 60 loss = 2.791545867919922
training: 0.47271299362182617 epoch = 1 step = 61 loss = 2.6795365810394287
training: 0.5876092910766602 epoch = 1 step = 62 loss = 2.6816837787628174
training: 0.48731517791748047 epoch = 1 step = 63 loss = 2.6962108612060547
training: 0.5089592933654785 epoch = 1 step = 64 loss = 2.6372435092926025
training: 0.6179118156433105 epoch = 1 step = 65 loss = 2.442610025405884
training: 0.3621828556060791 epoch = 1 step = 66 loss = 2.166753053665161
training: 0.5342130661010742 epoch = 2 step = 67 loss = 2.3033878803253174
training: 0.7013125419616699 epoch = 2 step = 68 loss = 2.2596237659454346
training: 0.5767204761505127 epoch = 2 step = 69 loss = 2.5960068702697754
training: 0.5400581359863281 epoch = 2 step = 70 loss = 2.4526753425598145
training: 0.44913339614868164 epoch = 2 step = 71 loss = 2.200143575668335
training: 0.5387086868286133 epoch = 2 step = 72 loss = 2.3571105003356934
training: 0.4481391906738281 epoch = 2 step = 73 loss = 2.597954511642456
training: 0.46309518814086914 epoch = 2 step = 74 loss = 2.4327690601348877
training: 0.5252997875213623 epoch = 2 step = 75 loss = 2.302354335784912
training: 0.6852927207946777 epoch = 2 step = 76 loss = 2.2448067665100098
training: 0.4090406894683838 epoch = 2 step = 77 loss = 2.6367366313934326
training: 0.5858156681060791 epoch = 2 step = 78 loss = 2.3709216117858887
training: 0.5330255031585693 epoch = 2 step = 79 loss = 2.3214402198791504
training: 0.6913058757781982 epoch = 2 step = 80 loss = 2.2034451961517334
training: 0.42510509490966797 epoch = 2 step = 81 loss = 2.283367872238159
training: 0.4771871566772461 epoch = 2 step = 82 loss = 2.421658515930176
training: 0.5246076583862305 epoch = 2 step = 83 loss = 2.479813814163208
training: 0.6188709735870361 epoch = 2 step = 84 loss = 2.3335354328155518
training: 0.49131083488464355 epoch = 2 step = 85 loss = 2.250352621078491
training: 0.5289406776428223 epoch = 2 step = 86 loss = 2.3465845584869385
training: 0.5269424915313721 epoch = 2 step = 87 loss = 2.5747580528259277
training: 0.5653340816497803 epoch = 2 step = 88 loss = 2.2066233158111572
training: 0.5982434749603271 epoch = 2 step = 89 loss = 2.3226542472839355
training: 0.425079345703125 epoch = 2 step = 90 loss = 2.5714619159698486
training: 0.5147333145141602 epoch = 2 step = 91 loss = 2.5674285888671875
training: 0.5782003402709961 epoch = 2 step = 92 loss = 2.228691339492798
training: 0.5166587829589844 epoch = 2 step = 93 loss = 2.5030577182769775
training: 0.4306974411010742 epoch = 2 step = 94 loss = 2.133119821548462
training: 0.5009186267852783 epoch = 2 step = 95 loss = 2.4032275676727295
training: 0.6326158046722412 epoch = 2 step = 96 loss = 2.3499841690063477
training: 0.4106912612915039 epoch = 2 step = 97 loss = 2.258375406265259
training: 0.6969034671783447 epoch = 2 step = 98 loss = 2.1467573642730713
training: 0.461895227432251 epoch = 3 step = 99 loss = 2.1382083892822266
training: 0.5931487083435059 epoch = 3 step = 100 loss = 2.2321324348449707

Devolope:
Devoloped = 0.5978367328643799, epoch = 3 step = 101 loss = 2.6033895015716553
Devoloped = 0.370955228805542, epoch = 3 step = 102 loss = 2.512551784515381
Devoloped = 0.5579981803894043, epoch = 3 step = 103 loss = 2.87577223777771
Devoloped = 0.6842963695526123, epoch = 3 step = 104 loss = 2.4752936363220215
Devoloped = 0.6287646293640137, epoch = 3 step = 105 loss = 2.6619157791137695
Devoloped = 0.47022294998168945, epoch = 3 step = 106 loss = 2.5533559322357178
Devoloped = 0.6388430595397949, epoch = 3 step = 107 loss = 2.5230395793914795

Evaluate:
[37  0  0 ...  0  0  0]
[0 0 0 ... 0 0 0]
Testing 1.7342278957366943 step = 107
 precision= 0.46223241590214065 recall= 0.46223241590214065 f1_score= 0.46223241590214065
107 0.46223241590214065 0.46223241590214065 0.46223241590214065

training: 0.7157101631164551 epoch = 3 step = 108 loss = 2.1711559295654297
training: 0.5583882331848145 epoch = 3 step = 109 loss = 2.094529151916504
training: 0.6365764141082764 epoch = 3 step = 110 loss = 2.2833330631256104
training: 0.6869533061981201 epoch = 3 step = 111 loss = 2.2007744312286377
training: 0.44620251655578613 epoch = 3 step = 112 loss = 2.1436145305633545
training: 0.5971007347106934 epoch = 3 step = 113 loss = 2.1703085899353027
training: 0.514275074005127 epoch = 3 step = 114 loss = 2.3182284832000732
training: 0.6756429672241211 epoch = 3 step = 115 loss = 2.4098782539367676
training: 0.3878026008605957 epoch = 3 step = 116 loss = 2.223551034927368
training: 0.6158337593078613 epoch = 3 step = 117 loss = 2.1354026794433594
training: 0.5610196590423584 epoch = 3 step = 118 loss = 2.212778329849243
training: 0.7739977836608887 epoch = 3 step = 119 loss = 2.1791889667510986
training: 0.5114295482635498 epoch = 3 step = 120 loss = 1.9853218793869019
training: 0.543682336807251 epoch = 3 step = 121 loss = 2.1590147018432617
training: 0.7103848457336426 epoch = 3 step = 122 loss = 2.0471339225769043
training: 0.5045342445373535 epoch = 3 step = 123 loss = 2.1487395763397217
training: 0.5155577659606934 epoch = 3 step = 124 loss = 2.0551607608795166
training: 0.47376585006713867 epoch = 3 step = 125 loss = 2.1916418075561523
training: 0.4796884059906006 epoch = 3 step = 126 loss = 1.8939661979675293
training: 0.45545005798339844 epoch = 3 step = 127 loss = 2.002685070037842
training: 0.511530876159668 epoch = 3 step = 128 loss = 1.8576850891113281
training: 0.46396923065185547 epoch = 3 step = 129 loss = 2.3020453453063965
training: 0.5040836334228516 epoch = 3 step = 130 loss = 1.9491933584213257
training: 0.6502506732940674 epoch = 3 step = 131 loss = 1.8314310312271118
training: 0.5202789306640625 epoch = 3 step = 132 loss = 1.9579945802688599
training: 0.5283710956573486 epoch = 3 step = 133 loss = 2.2438197135925293
training: 0.4150960445404053 epoch = 3 step = 134 loss = 2.250709056854248
training: 0.804412841796875 epoch = 3 step = 135 loss = 2.3014516830444336
training: 0.5493388175964355 epoch = 3 step = 136 loss = 2.0683536529541016
training: 0.5328555107116699 epoch = 3 step = 137 loss = 2.098796844482422
training: 0.6770665645599365 epoch = 4 step = 138 loss = 2.048358201980591
training: 0.44399070739746094 epoch = 4 step = 139 loss = 2.0172252655029297
training: 0.4612112045288086 epoch = 4 step = 140 loss = 1.8413419723510742
training: 0.5026509761810303 epoch = 4 step = 141 loss = 1.902236819267273
training: 0.72694993019104 epoch = 4 step = 142 loss = 1.8915486335754395
training: 0.5417115688323975 epoch = 4 step = 143 loss = 1.8416125774383545
training: 0.5103590488433838 epoch = 4 step = 144 loss = 1.768362045288086
training: 0.46483516693115234 epoch = 4 step = 145 loss = 2.084270715713501
training: 0.5405135154724121 epoch = 4 step = 146 loss = 1.7264304161071777
training: 0.4672427177429199 epoch = 4 step = 147 loss = 1.9983384609222412
training: 0.525580883026123 epoch = 4 step = 148 loss = 1.8825865983963013
training: 0.39151573181152344 epoch = 4 step = 149 loss = 2.0091588497161865
training: 0.5299594402313232 epoch = 4 step = 150 loss = 1.7741343975067139
training: 0.5307056903839111 epoch = 4 step = 151 loss = 2.1492538452148438
training: 0.5091805458068848 epoch = 4 step = 152 loss = 1.8246065378189087
training: 0.5217108726501465 epoch = 4 step = 153 loss = 1.8940210342407227
training: 0.4266934394836426 epoch = 4 step = 154 loss = 1.766683578491211
training: 0.6612739562988281 epoch = 4 step = 155 loss = 1.5689953565597534
training: 0.516834020614624 epoch = 4 step = 156 loss = 1.981934666633606
training: 0.4940457344055176 epoch = 4 step = 157 loss = 1.9514793157577515
training: 0.45641326904296875 epoch = 4 step = 158 loss = 1.5768611431121826
training: 0.6720130443572998 epoch = 4 step = 159 loss = 1.9363192319869995
training: 0.5484895706176758 epoch = 4 step = 160 loss = 1.863743782043457
training: 0.436598539352417 epoch = 4 step = 161 loss = 1.8871299028396606
training: 0.5239882469177246 epoch = 4 step = 162 loss = 1.9174598455429077
training: 0.5740039348602295 epoch = 4 step = 163 loss = 1.6435809135437012
training: 0.40917348861694336 epoch = 4 step = 164 loss = 1.7096588611602783
training: 0.4662034511566162 epoch = 4 step = 165 loss = 1.8209412097930908
training: 0.4937882423400879 epoch = 4 step = 166 loss = 1.9777765274047852
training: 0.6824040412902832 epoch = 4 step = 167 loss = 1.8000963926315308
training: 0.49518799781799316 epoch = 4 step = 168 loss = 1.679433822631836
training: 0.6081671714782715 epoch = 4 step = 169 loss = 2.046877861022949
training: 0.47552943229675293 epoch = 4 step = 170 loss = 0.6429706811904907
training: 0.613696813583374 epoch = 5 step = 171 loss = 1.7955816984176636
training: 0.46800756454467773 epoch = 5 step = 172 loss = 1.3583253622055054
training: 0.4815804958343506 epoch = 5 step = 173 loss = 1.4769830703735352
training: 0.5336792469024658 epoch = 5 step = 174 loss = 1.6782641410827637
training: 0.6862523555755615 epoch = 5 step = 175 loss = 1.4593935012817383
training: 0.5327615737915039 epoch = 5 step = 176 loss = 1.7128218412399292
training: 0.5010433197021484 epoch = 5 step = 177 loss = 1.6989954710006714
training: 0.43076181411743164 epoch = 5 step = 178 loss = 1.62349534034729
training: 0.714508056640625 epoch = 5 step = 179 loss = 1.862903356552124
training: 0.4164009094238281 epoch = 5 step = 180 loss = 1.4087365865707397
training: 0.5673129558563232 epoch = 5 step = 181 loss = 1.5171459913253784
training: 0.5122854709625244 epoch = 5 step = 182 loss = 1.6203856468200684
training: 0.6243476867675781 epoch = 5 step = 183 loss = 1.597585678100586
training: 0.47962093353271484 epoch = 5 step = 184 loss = 1.738335132598877
training: 0.47089529037475586 epoch = 5 step = 185 loss = 1.576485276222229
training: 0.522533655166626 epoch = 5 step = 186 loss = 1.3187556266784668
training: 0.6988203525543213 epoch = 5 step = 187 loss = 1.5176026821136475
training: 0.4607889652252197 epoch = 5 step = 188 loss = 1.4355509281158447
training: 0.5250093936920166 epoch = 5 step = 189 loss = 1.6533335447311401
training: 0.5623927116394043 epoch = 5 step = 190 loss = 1.4035552740097046
training: 0.5360252857208252 epoch = 5 step = 191 loss = 1.7133009433746338
training: 0.5202898979187012 epoch = 5 step = 192 loss = 1.458865761756897
training: 0.4851956367492676 epoch = 5 step = 193 loss = 1.489912986755371
training: 0.417344331741333 epoch = 5 step = 194 loss = 1.562951922416687
training: 0.6980748176574707 epoch = 5 step = 195 loss = 1.6900533437728882
training: 0.4792914390563965 epoch = 5 step = 196 loss = 1.8417431116104126
training: 0.4708991050720215 epoch = 5 step = 197 loss = 1.7555651664733887
training: 0.43798279762268066 epoch = 5 step = 198 loss = 1.5746859312057495
training: 0.6114635467529297 epoch = 5 step = 199 loss = 1.5370951890945435
training: 0.5100581645965576 epoch = 5 step = 200 loss = 1.5454663038253784

Devolope:
Devoloped = 0.48687219619750977, epoch = 5 step = 201 loss = 2.2962727546691895
Devoloped = 0.48629069328308105, epoch = 5 step = 202 loss = 2.461137533187866
Devoloped = 0.6723392009735107, epoch = 5 step = 203 loss = 2.291897773742676
Devoloped = 0.5164153575897217, epoch = 5 step = 204 loss = 2.4623167514801025
Devoloped = 0.4995248317718506, epoch = 5 step = 205 loss = 2.226378917694092
Devoloped = 0.5119857788085938, epoch = 5 step = 206 loss = 2.3538358211517334
Devoloped = 0.6963939666748047, epoch = 5 step = 207 loss = 2.448565721511841

Evaluate:
[0 0 5 ... 0 0 0]
[0 0 0 ... 0 0 0]
Testing 1.5044007301330566 step = 207
 precision= 0.5131498470948013 recall= 0.5131498470948013 f1_score= 0.5131498470948013
207 0.5131498470948013 0.5131498470948013 0.5131498470948013

training: 0.6592957973480225 epoch = 5 step = 208 loss = 1.7214691638946533
training: 0.48285460472106934 epoch = 5 step = 209 loss = 1.8440632820129395
training: 0.40949177742004395 epoch = 6 step = 210 loss = 1.4192144870758057
training: 0.47100186347961426 epoch = 6 step = 211 loss = 1.2772018909454346
training: 0.580805778503418 epoch = 6 step = 212 loss = 1.3162842988967896
training: 0.47481536865234375 epoch = 6 step = 213 loss = 1.3940924406051636
training: 0.6035571098327637 epoch = 6 step = 214 loss = 1.4264497756958008
training: 0.4637870788574219 epoch = 6 step = 215 loss = 1.2900549173355103
training: 0.5792803764343262 epoch = 6 step = 216 loss = 1.4479522705078125
training: 0.5483722686767578 epoch = 6 step = 217 loss = 1.2320640087127686
training: 0.511650562286377 epoch = 6 step = 218 loss = 1.2707440853118896
training: 0.5191521644592285 epoch = 6 step = 219 loss = 1.2540875673294067
training: 0.6364321708679199 epoch = 6 step = 220 loss = 1.2353746891021729
training: 0.4609975814819336 epoch = 6 step = 221 loss = 1.29384183883667
training: 0.512946367263794 epoch = 6 step = 222 loss = 1.3487564325332642
training: 0.5008738040924072 epoch = 6 step = 223 loss = 1.3101098537445068
training: 0.6025445461273193 epoch = 6 step = 224 loss = 1.105569839477539
training: 0.48183655738830566 epoch = 6 step = 225 loss = 1.315061330795288
training: 0.6100962162017822 epoch = 6 step = 226 loss = 1.2346186637878418
training: 0.4645850658416748 epoch = 6 step = 227 loss = 1.41676926612854
training: 0.6402654647827148 epoch = 6 step = 228 loss = 1.4902904033660889
training: 0.5148270130157471 epoch = 6 step = 229 loss = 1.3464605808258057
training: 0.4021463394165039 epoch = 6 step = 230 loss = 1.2228028774261475
training: 0.4506247043609619 epoch = 6 step = 231 loss = 1.2752121686935425
training: 0.6756272315979004 epoch = 6 step = 232 loss = 1.111305594444275
training: 0.44162774085998535 epoch = 6 step = 233 loss = 1.3515889644622803
training: 0.43805861473083496 epoch = 6 step = 234 loss = 1.361599087715149
training: 0.47751951217651367 epoch = 6 step = 235 loss = 1.1919530630111694
training: 0.5072777271270752 epoch = 6 step = 236 loss = 1.4625792503356934
training: 0.5396082401275635 epoch = 6 step = 237 loss = 1.2476238012313843
training: 0.4199538230895996 epoch = 6 step = 238 loss = 1.2887637615203857
training: 0.6023125648498535 epoch = 6 step = 239 loss = 1.3382995128631592
training: 0.4196949005126953 epoch = 6 step = 240 loss = 1.3880165815353394
training: 0.6737613677978516 epoch = 6 step = 241 loss = 1.1332769393920898
training: 0.49881434440612793 epoch = 7 step = 242 loss = 1.100974202156067
training: 0.5835886001586914 epoch = 7 step = 243 loss = 1.0538843870162964
training: 0.48819422721862793 epoch = 7 step = 244 loss = 0.9386347532272339
training: 0.5053160190582275 epoch = 7 step = 245 loss = 0.9812434315681458
training: 0.45843029022216797 epoch = 7 step = 246 loss = 1.0889540910720825
training: 0.3727102279663086 epoch = 7 step = 247 loss = 1.0187759399414062
training: 0.5220885276794434 epoch = 7 step = 248 loss = 1.00039541721344
training: 0.5951294898986816 epoch = 7 step = 249 loss = 1.0271753072738647
training: 0.5330934524536133 epoch = 7 step = 250 loss = 0.77933669090271
training: 0.5811216831207275 epoch = 7 step = 251 loss = 1.109199047088623
training: 0.4380934238433838 epoch = 7 step = 252 loss = 1.1821601390838623
training: 0.676079511642456 epoch = 7 step = 253 loss = 1.078566312789917
training: 0.5651764869689941 epoch = 7 step = 254 loss = 0.9070205688476562
training: 0.5075798034667969 epoch = 7 step = 255 loss = 0.9994210004806519
training: 0.46169495582580566 epoch = 7 step = 256 loss = 1.0121572017669678
training: 0.6143648624420166 epoch = 7 step = 257 loss = 1.1736295223236084
training: 0.574913740158081 epoch = 7 step = 258 loss = 1.0333107709884644
training: 0.5095329284667969 epoch = 7 step = 259 loss = 1.0781619548797607
training: 0.5728960037231445 epoch = 7 step = 260 loss = 1.1388983726501465
training: 0.5470380783081055 epoch = 7 step = 261 loss = 0.9961283206939697
training: 0.5595297813415527 epoch = 7 step = 262 loss = 0.9538251757621765
training: 0.43285036087036133 epoch = 7 step = 263 loss = 1.0152901411056519
training: 0.39972782135009766 epoch = 7 step = 264 loss = 1.0735574960708618
training: 0.727067232131958 epoch = 7 step = 265 loss = 0.9706851243972778
training: 0.43544769287109375 epoch = 7 step = 266 loss = 1.341496229171753
training: 0.49567437171936035 epoch = 7 step = 267 loss = 0.8929734230041504
training: 0.4388110637664795 epoch = 7 step = 268 loss = 0.882490873336792
training: 0.6705152988433838 epoch = 7 step = 269 loss = 1.1331686973571777
training: 0.6077125072479248 epoch = 7 step = 270 loss = 1.0864293575286865
training: 0.44036364555358887 epoch = 7 step = 271 loss = 1.1693836450576782
training: 0.4470031261444092 epoch = 7 step = 272 loss = 0.913818359375
training: 0.624098539352417 epoch = 7 step = 273 loss = 1.0625662803649902
training: 0.5363361835479736 epoch = 8 step = 274 loss = 0.8520315885543823
training: 0.5087728500366211 epoch = 8 step = 275 loss = 0.9418492317199707
training: 0.44144535064697266 epoch = 8 step = 276 loss = 0.8219386339187622
training: 0.6203272342681885 epoch = 8 step = 277 loss = 0.8027734756469727
training: 0.48883867263793945 epoch = 8 step = 278 loss = 0.9176482558250427
training: 0.5010149478912354 epoch = 8 step = 279 loss = 0.7837496399879456
training: 0.5450263023376465 epoch = 8 step = 280 loss = 0.8175308108329773
training: 0.5817551612854004 epoch = 8 step = 281 loss = 1.0392123460769653
training: 0.4380216598510742 epoch = 8 step = 282 loss = 0.9509122371673584
training: 0.4984912872314453 epoch = 8 step = 283 loss = 0.7629972696304321
training: 0.47815680503845215 epoch = 8 step = 284 loss = 0.915382981300354
training: 0.7095427513122559 epoch = 8 step = 285 loss = 0.8120699524879456
training: 0.4776573181152344 epoch = 8 step = 286 loss = 0.6828724145889282
training: 0.4920532703399658 epoch = 8 step = 287 loss = 0.7957082986831665
training: 0.4830753803253174 epoch = 8 step = 288 loss = 0.9324485063552856
training: 0.7409219741821289 epoch = 8 step = 289 loss = 0.740192174911499
training: 0.5029087066650391 epoch = 8 step = 290 loss = 0.7244272828102112
training: 0.4626631736755371 epoch = 8 step = 291 loss = 0.9894389510154724
training: 0.5776116847991943 epoch = 8 step = 292 loss = 0.7634249925613403
training: 0.629831075668335 epoch = 8 step = 293 loss = 0.7449460029602051
training: 0.5186822414398193 epoch = 8 step = 294 loss = 0.9530952572822571
training: 0.5649259090423584 epoch = 8 step = 295 loss = 0.7687952518463135
training: 0.48655104637145996 epoch = 8 step = 296 loss = 0.7517300248146057
training: 0.672205924987793 epoch = 8 step = 297 loss = 0.8509033918380737
training: 0.4687769412994385 epoch = 8 step = 298 loss = 0.737510621547699
training: 0.5100421905517578 epoch = 8 step = 299 loss = 0.9583081007003784
training: 0.5089578628540039 epoch = 8 step = 300 loss = 0.9407377243041992

Devolope:
Devoloped = 0.6376676559448242, epoch = 8 step = 301 loss = 1.8897266387939453
Devoloped = 0.47438502311706543, epoch = 8 step = 302 loss = 1.7183340787887573
Devoloped = 0.48520398139953613, epoch = 8 step = 303 loss = 1.812271237373352
Devoloped = 0.5949587821960449, epoch = 8 step = 304 loss = 1.767758846282959
Devoloped = 0.583266019821167, epoch = 8 step = 305 loss = 2.0206427574157715
Devoloped = 0.46718931198120117, epoch = 8 step = 306 loss = 2.153198719024658
Devoloped = 0.42003583908081055, epoch = 8 step = 307 loss = 1.7210427522659302
Devoloped = 0.439359188079834, epoch = 8 step = 308 loss = 4.030656337738037

Evaluate:
[ 0  0 31 ...  0  0  0]
[0 0 0 ... 0 0 0]
Testing 1.5675010681152344 step = 308
 precision= 0.6547400611620795 recall= 0.6547400611620795 f1_score= 0.6547400611620795
308 0.6547400611620795 0.6547400611620795 0.6547400611620795

training: 0.5700199604034424 epoch = 8 step = 309 loss = 0.9252164363861084
training: 0.6639409065246582 epoch = 8 step = 310 loss = 0.9135618805885315
training: 0.6428787708282471 epoch = 8 step = 311 loss = 0.866340160369873
training: 0.4552016258239746 epoch = 8 step = 312 loss = 0.8168262839317322
training: 0.49294161796569824 epoch = 8 step = 313 loss = 0.993272066116333
training: 0.6617641448974609 epoch = 9 step = 314 loss = 0.7493211030960083
training: 0.42934679985046387 epoch = 9 step = 315 loss = 0.7505105137825012
training: 0.5246021747589111 epoch = 9 step = 316 loss = 0.6114712357521057
training: 0.544151782989502 epoch = 9 step = 317 loss = 0.6080230474472046
training: 0.664130449295044 epoch = 9 step = 318 loss = 0.719781756401062
training: 0.540327787399292 epoch = 9 step = 319 loss = 0.802355945110321
training: 0.5316073894500732 epoch = 9 step = 320 loss = 0.9603406190872192
training: 0.45740604400634766 epoch = 9 step = 321 loss = 0.7718909978866577
training: 0.5764179229736328 epoch = 9 step = 322 loss = 0.569516122341156
training: 0.5252034664154053 epoch = 9 step = 323 loss = 0.8450407981872559
training: 0.5646045207977295 epoch = 9 step = 324 loss = 0.72165846824646
training: 0.5485529899597168 epoch = 9 step = 325 loss = 0.8780874609947205
training: 0.5282893180847168 epoch = 9 step = 326 loss = 0.7007513642311096
training: 0.5306689739227295 epoch = 9 step = 327 loss = 0.6951792240142822
training: 0.5147101879119873 epoch = 9 step = 328 loss = 0.8197602033615112
training: 0.6577107906341553 epoch = 9 step = 329 loss = 0.7721766233444214
training: 0.41736721992492676 epoch = 9 step = 330 loss = 0.7848777770996094
training: 0.5043067932128906 epoch = 9 step = 331 loss = 0.604738175868988
training: 0.4256925582885742 epoch = 9 step = 332 loss = 0.6330582499504089
training: 0.5845897197723389 epoch = 9 step = 333 loss = 0.8852578401565552
training: 0.5254104137420654 epoch = 9 step = 334 loss = 0.6448946595191956
training: 0.5832946300506592 epoch = 9 step = 335 loss = 0.9543262720108032
training: 0.47069621086120605 epoch = 9 step = 336 loss = 0.6378728747367859
training: 0.5429391860961914 epoch = 9 step = 337 loss = 0.8251256942749023
training: 0.5579981803894043 epoch = 9 step = 338 loss = 0.8176615834236145
training: 0.48891377449035645 epoch = 9 step = 339 loss = 0.9050548076629639
training: 0.41236090660095215 epoch = 9 step = 340 loss = 0.635067343711853
training: 0.4064054489135742 epoch = 9 step = 341 loss = 0.9024919271469116
training: 0.4746875762939453 epoch = 9 step = 342 loss = 0.6867464184761047
training: 0.5407588481903076 epoch = 9 step = 343 loss = 0.7397752404212952
training: 0.6767294406890869 epoch = 9 step = 344 loss = 0.7842104434967041
training: 0.5596029758453369 epoch = 9 step = 345 loss = 0.6834776401519775
training: 0.6523077487945557 epoch = 10 step = 346 loss = 0.7137060165405273
training: 0.5093202590942383 epoch = 10 step = 347 loss = 0.5755196809768677
training: 0.49648022651672363 epoch = 10 step = 348 loss = 0.7119241952896118
training: 0.5113189220428467 epoch = 10 step = 349 loss = 0.6101987361907959
training: 0.6649880409240723 epoch = 10 step = 350 loss = 0.6532484292984009
training: 0.4460721015930176 epoch = 10 step = 351 loss = 0.6806813478469849
training: 0.6566152572631836 epoch = 10 step = 352 loss = 0.718482494354248
training: 0.3856346607208252 epoch = 10 step = 353 loss = 0.53215491771698
training: 0.6418299674987793 epoch = 10 step = 354 loss = 0.5749083161354065
training: 0.4510536193847656 epoch = 10 step = 355 loss = 0.6644845008850098
training: 0.5920703411102295 epoch = 10 step = 356 loss = 0.6214401721954346
training: 0.523165225982666 epoch = 10 step = 357 loss = 0.579469621181488
training: 0.6449871063232422 epoch = 10 step = 358 loss = 0.5922820568084717
training: 0.42489123344421387 epoch = 10 step = 359 loss = 0.6325610876083374
training: 0.5365266799926758 epoch = 10 step = 360 loss = 0.6030175685882568
training: 0.4695737361907959 epoch = 10 step = 361 loss = 0.816612958908081
training: 0.5944163799285889 epoch = 10 step = 362 loss = 0.6982743144035339
training: 0.3780050277709961 epoch = 10 step = 363 loss = 0.6969609260559082
training: 0.6464958190917969 epoch = 10 step = 364 loss = 0.6589645147323608
training: 0.41211390495300293 epoch = 10 step = 365 loss = 0.6552037000656128
training: 0.6424486637115479 epoch = 10 step = 366 loss = 0.6575504541397095
training: 0.559241533279419 epoch = 10 step = 367 loss = 0.5498363971710205
training: 0.5522785186767578 epoch = 10 step = 368 loss = 0.7343603372573853
training: 0.4959428310394287 epoch = 10 step = 369 loss = 0.6345759630203247
training: 0.7166829109191895 epoch = 10 step = 370 loss = 0.5221615433692932
training: 0.5487329959869385 epoch = 10 step = 371 loss = 0.5589685440063477
training: 0.5215165615081787 epoch = 10 step = 372 loss = 0.7052503824234009
training: 0.6385388374328613 epoch = 10 step = 373 loss = 0.5773065686225891
training: 0.6239523887634277 epoch = 10 step = 374 loss = 0.5983210206031799
training: 0.5075235366821289 epoch = 10 step = 375 loss = 0.6045547723770142
training: 0.5363595485687256 epoch = 10 step = 376 loss = 0.6564157009124756
training: 0.578460693359375 epoch = 10 step = 377 loss = 0.608887791633606
training: 0.512913703918457 epoch = 10 step = 378 loss = 0.6081242561340332
training: 0.5648765563964844 epoch = 11 step = 379 loss = 0.5065324306488037
training: 0.5154423713684082 epoch = 11 step = 380 loss = 0.697376012802124
training: 0.7717065811157227 epoch = 11 step = 381 loss = 0.5379160642623901
training: 0.4850757122039795 epoch = 11 step = 382 loss = 0.5816677808761597
training: 0.5073623657226562 epoch = 11 step = 383 loss = 0.5767263174057007
training: 0.5811643600463867 epoch = 11 step = 384 loss = 0.557687520980835
training: 0.46749043464660645 epoch = 11 step = 385 loss = 0.5520573854446411
training: 0.35822081565856934 epoch = 11 step = 386 loss = 0.48539504408836365
training: 0.5756645202636719 epoch = 11 step = 387 loss = 0.666583240032196
training: 0.4808835983276367 epoch = 11 step = 388 loss = 0.5716511011123657
training: 0.5864143371582031 epoch = 11 step = 389 loss = 0.5927047729492188
training: 0.5306673049926758 epoch = 11 step = 390 loss = 0.5384972095489502
training: 0.46936678886413574 epoch = 11 step = 391 loss = 0.5552685260772705
training: 0.572465181350708 epoch = 11 step = 392 loss = 0.4760575592517853
training: 0.670839786529541 epoch = 11 step = 393 loss = 0.5909771919250488
training: 0.4727516174316406 epoch = 11 step = 394 loss = 0.7831984758377075
training: 0.5925338268280029 epoch = 11 step = 395 loss = 0.5142966508865356
training: 0.4484391212463379 epoch = 11 step = 396 loss = 0.7780822515487671
training: 0.7330689430236816 epoch = 11 step = 397 loss = 0.5318706035614014
training: 0.47134900093078613 epoch = 11 step = 398 loss = 0.5456925630569458
training: 0.5086071491241455 epoch = 11 step = 399 loss = 0.5236498117446899
training: 0.5197882652282715 epoch = 11 step = 400 loss = 0.5089433789253235

Devolope:
Devoloped = 0.5739791393280029, epoch = 11 step = 401 loss = 1.3029769659042358
Devoloped = 0.5264468193054199, epoch = 11 step = 402 loss = 1.2836384773254395
Devoloped = 0.5197939872741699, epoch = 11 step = 403 loss = 1.6355594396591187
Devoloped = 0.5600221157073975, epoch = 11 step = 404 loss = 1.4574086666107178
Devoloped = 0.567345142364502, epoch = 11 step = 405 loss = 1.5507988929748535
Devoloped = 0.5740900039672852, epoch = 11 step = 406 loss = 1.5841443538665771
Devoloped = 0.5213460922241211, epoch = 11 step = 407 loss = 1.2782502174377441
Devoloped = 0.7666242122650146, epoch = 11 step = 408 loss = 1.4499953985214233

Evaluate:
[31  0  7 ...  0  0  0]
[0 0 0 ... 0 0 0]
Testing 1.5238430500030518 step = 408
 precision= 0.7169724770642202 recall= 0.7169724770642202 f1_score= 0.7169724770642201
408 0.7169724770642202 0.7169724770642202 0.7169724770642201

training: 0.7347469329833984 epoch = 11 step = 409 loss = 0.5123463869094849
training: 0.5061581134796143 epoch = 11 step = 410 loss = 0.5295150279998779
training: 0.4531726837158203 epoch = 11 step = 411 loss = 0.6719651222229004
training: 0.46756839752197266 epoch = 11 step = 412 loss = 0.5395670533180237
training: 0.6626064777374268 epoch = 11 step = 413 loss = 0.6018366813659668
training: 0.44582128524780273 epoch = 11 step = 414 loss = 0.6032944321632385
training: 0.5005428791046143 epoch = 11 step = 415 loss = 0.5852319002151489
training: 0.4298551082611084 epoch = 11 step = 416 loss = 0.5139367580413818
training: 0.6687521934509277 epoch = 11 step = 417 loss = 0.5012222528457642
training: 0.4431755542755127 epoch = 11 step = 418 loss = 0.5774545669555664
training: 0.5770788192749023 epoch = 12 step = 419 loss = 0.5933418273925781
training: 0.5566458702087402 epoch = 12 step = 420 loss = 0.5438169836997986
training: 0.7153878211975098 epoch = 12 step = 421 loss = 0.5617387294769287
training: 0.41957736015319824 epoch = 12 step = 422 loss = 0.4220801889896393
training: 0.4344949722290039 epoch = 12 step = 423 loss = 0.5197649002075195
training: 0.5624632835388184 epoch = 12 step = 424 loss = 0.48806077241897583
training: 0.7575852870941162 epoch = 12 step = 425 loss = 0.5567087531089783
training: 0.4901611804962158 epoch = 12 step = 426 loss = 0.5443549752235413
training: 0.41790318489074707 epoch = 12 step = 427 loss = 0.6941008567810059
training: 0.46408581733703613 epoch = 12 step = 428 loss = 0.5385053157806396
training: 0.7068486213684082 epoch = 12 step = 429 loss = 0.56137615442276
training: 0.47093725204467773 epoch = 12 step = 430 loss = 0.5383464097976685
training: 0.4924964904785156 epoch = 12 step = 431 loss = 0.5436722040176392
training: 0.4481241703033447 epoch = 12 step = 432 loss = 0.45633557438850403
training: 0.7131307125091553 epoch = 12 step = 433 loss = 0.5812985897064209
training: 0.49267005920410156 epoch = 12 step = 434 loss = 0.52373868227005
training: 0.5194323062896729 epoch = 12 step = 435 loss = 0.5283017754554749
training: 0.4372532367706299 epoch = 12 step = 436 loss = 0.6256647109985352
training: 0.6122610569000244 epoch = 12 step = 437 loss = 0.5529229640960693
training: 0.4144868850708008 epoch = 12 step = 438 loss = 0.5012343525886536
training: 0.5576245784759521 epoch = 12 step = 439 loss = 0.5526919364929199
training: 0.6102027893066406 epoch = 12 step = 440 loss = 0.4753625988960266
training: 0.7282040119171143 epoch = 12 step = 441 loss = 0.5064181089401245
training: 0.5174233913421631 epoch = 12 step = 442 loss = 0.562902569770813
training: 0.4146864414215088 epoch = 12 step = 443 loss = 0.5899823904037476
training: 0.5177145004272461 epoch = 12 step = 444 loss = 0.5707648992538452
training: 0.7119753360748291 epoch = 12 step = 445 loss = 0.5299555063247681
training: 0.4903717041015625 epoch = 12 step = 446 loss = 0.5524426698684692
training: 0.5069775581359863 epoch = 12 step = 447 loss = 0.6109885573387146
training: 0.4600827693939209 epoch = 12 step = 448 loss = 0.6145167350769043
training: 0.6878757476806641 epoch = 12 step = 449 loss = 0.49666255712509155
training: 0.5129425525665283 epoch = 12 step = 450 loss = 0.5246388912200928
training: 0.49358367919921875 epoch = 12 step = 451 loss = 0.5354886054992676
training: 0.5505437850952148 epoch = 13 step = 452 loss = 0.5191942453384399
training: 0.42061805725097656 epoch = 13 step = 453 loss = 0.4168943166732788
training: 0.586383581161499 epoch = 13 step = 454 loss = 0.5060757398605347
training: 0.48758935928344727 epoch = 13 step = 455 loss = 0.48491793870925903
training: 0.4239206314086914 epoch = 13 step = 456 loss = 0.4444364309310913
training: 0.6780853271484375 epoch = 13 step = 457 loss = 0.5817487835884094
training: 0.463334321975708 epoch = 13 step = 458 loss = 0.47249293327331543
training: 0.6206989288330078 epoch = 13 step = 459 loss = 0.5103536248207092
training: 0.533066987991333 epoch = 13 step = 460 loss = 0.49165940284729004
training: 0.5373334884643555 epoch = 13 step = 461 loss = 0.4909432530403137
training: 0.5089917182922363 epoch = 13 step = 462 loss = 0.4458540678024292
training: 0.49816131591796875 epoch = 13 step = 463 loss = 0.5269045829772949
training: 0.5884790420532227 epoch = 13 step = 464 loss = 0.4890786409378052
training: 0.6336050033569336 epoch = 13 step = 465 loss = 0.4294745624065399
training: 0.5049631595611572 epoch = 13 step = 466 loss = 0.5732011795043945
training: 0.4544351100921631 epoch = 13 step = 467 loss = 0.5542296767234802
training: 0.46890807151794434 epoch = 13 step = 468 loss = 0.4276798367500305
training: 0.6162121295928955 epoch = 13 step = 469 loss = 0.5746674537658691
training: 0.5173428058624268 epoch = 13 step = 470 loss = 0.43736732006073
training: 0.4341707229614258 epoch = 13 step = 471 loss = 0.47660332918167114
training: 0.5186505317687988 epoch = 13 step = 472 loss = 0.4356672763824463
training: 0.6470944881439209 epoch = 13 step = 473 loss = 0.5879343748092651
training: 0.46308302879333496 epoch = 13 step = 474 loss = 0.45238590240478516
training: 0.5036790370941162 epoch = 13 step = 475 loss = 0.46599146723747253
training: 0.561333179473877 epoch = 13 step = 476 loss = 0.47021323442459106
training: 0.6629030704498291 epoch = 13 step = 477 loss = 0.49306896328926086
training: 0.3741896152496338 epoch = 13 step = 478 loss = 0.4562111496925354
training: 0.5187523365020752 epoch = 13 step = 479 loss = 0.480472594499588
training: 0.425123929977417 epoch = 13 step = 480 loss = 0.4681074619293213
training: 0.784754753112793 epoch = 13 step = 481 loss = 0.5188539028167725
training: 0.45627331733703613 epoch = 13 step = 482 loss = 0.4146747887134552
training: 0.5555291175842285 epoch = 13 step = 483 loss = 0.4808451235294342
training: 0.5394904613494873 epoch = 14 step = 484 loss = 0.39399227499961853
training: 0.526522159576416 epoch = 14 step = 485 loss = 0.5158421993255615
training: 0.5403528213500977 epoch = 14 step = 486 loss = 0.532897412776947
training: 0.5568320751190186 epoch = 14 step = 487 loss = 0.44869810342788696
training: 0.5186903476715088 epoch = 14 step = 488 loss = 0.3653923571109772
training: 0.5353538990020752 epoch = 14 step = 489 loss = 0.48779433965682983
training: 0.6146194934844971 epoch = 14 step = 490 loss = 0.4647101163864136
training: 0.4655933380126953 epoch = 14 step = 491 loss = 0.40109726786613464
training: 0.599968433380127 epoch = 14 step = 492 loss = 0.5266765356063843
training: 0.5328059196472168 epoch = 14 step = 493 loss = 0.42667239904403687
training: 0.46778011322021484 epoch = 14 step = 494 loss = 0.5034052729606628
training: 0.4672675132751465 epoch = 14 step = 495 loss = 0.4534382224082947
training: 0.5359129905700684 epoch = 14 step = 496 loss = 0.45397305488586426
training: 0.7002906799316406 epoch = 14 step = 497 loss = 0.4197176694869995
training: 0.4441816806793213 epoch = 14 step = 498 loss = 0.5206074714660645
training: 0.5560240745544434 epoch = 14 step = 499 loss = 0.47314882278442383
training: 0.46556687355041504 epoch = 14 step = 500 loss = 0.4330894947052002

Devolope:
Devoloped = 0.5375528335571289, epoch = 14 step = 501 loss = 0.9545098543167114
Devoloped = 0.5742883682250977, epoch = 14 step = 502 loss = 0.8930433988571167
Devoloped = 0.5193438529968262, epoch = 14 step = 503 loss = 0.9290711283683777
Devoloped = 0.4464223384857178, epoch = 14 step = 504 loss = 0.8782933354377747
Devoloped = 0.6451447010040283, epoch = 14 step = 505 loss = 0.9721214771270752
Devoloped = 0.4794909954071045, epoch = 14 step = 506 loss = 1.0727638006210327
Devoloped = 0.5415341854095459, epoch = 14 step = 507 loss = 0.846733808517456
Devoloped = 0.36432576179504395, epoch = 14 step = 508 loss = 0.7943465709686279

Evaluate:
[ 0  0  0 ...  0 31  0]
[0 0 0 ... 0 0 0]
Testing 1.588348150253296 step = 508
 precision= 0.7414373088685016 recall= 0.7414373088685016 f1_score= 0.7414373088685017
508 0.7414373088685016 0.7414373088685016 0.7414373088685017

training: 0.5385901927947998 epoch = 14 step = 509 loss = 0.4317548871040344
training: 0.8333635330200195 epoch = 14 step = 510 loss = 0.4785182476043701
training: 0.4238309860229492 epoch = 14 step = 511 loss = 0.4542377293109894
training: 0.4929640293121338 epoch = 14 step = 512 loss = 0.43070751428604126
training: 0.4936866760253906 epoch = 14 step = 513 loss = 0.41640394926071167
training: 0.6304833889007568 epoch = 14 step = 514 loss = 0.4532734155654907
training: 0.4889638423919678 epoch = 14 step = 515 loss = 0.5135300755500793
training: 0.4292919635772705 epoch = 14 step = 516 loss = 0.4254944324493408
training: 0.6199319362640381 epoch = 14 step = 517 loss = 0.43535786867141724
training: 0.7113618850708008 epoch = 14 step = 518 loss = 0.4271726608276367
training: 0.5248551368713379 epoch = 14 step = 519 loss = 0.5800168514251709
training: 0.613297700881958 epoch = 14 step = 520 loss = 0.42912858724594116
training: 0.7244226932525635 epoch = 14 step = 521 loss = 0.4502575695514679
training: 0.4297018051147461 epoch = 14 step = 522 loss = 0.42750537395477295
training: 0.5338757038116455 epoch = 14 step = 523 loss = 0.48287808895111084
training: 0.5553538799285889 epoch = 14 step = 524 loss = 0.4239580035209656
training: 0.5913777351379395 epoch = 15 step = 525 loss = 0.4122755229473114
training: 0.4911019802093506 epoch = 15 step = 526 loss = 0.5525860786437988
training: 0.4324784278869629 epoch = 15 step = 527 loss = 0.48822495341300964
training: 0.6350352764129639 epoch = 15 step = 528 loss = 0.43576112389564514
training: 0.5878217220306396 epoch = 15 step = 529 loss = 0.41249361634254456
training: 0.47706007957458496 epoch = 15 step = 530 loss = 0.5040104389190674
training: 0.5180041790008545 epoch = 15 step = 531 loss = 0.481997549533844
training: 0.5359938144683838 epoch = 15 step = 532 loss = 0.42938417196273804
training: 0.6039862632751465 epoch = 15 step = 533 loss = 0.42035067081451416
training: 0.5512242317199707 epoch = 15 step = 534 loss = 0.4759252071380615
training: 0.4532463550567627 epoch = 15 step = 535 loss = 0.4237765371799469
training: 0.4876575469970703 epoch = 15 step = 536 loss = 0.4683054983615875
training: 0.6506638526916504 epoch = 15 step = 537 loss = 0.44686755537986755
training: 0.5172977447509766 epoch = 15 step = 538 loss = 0.4391348958015442
training: 0.5029230117797852 epoch = 15 step = 539 loss = 0.4320867955684662
training: 0.584296703338623 epoch = 15 step = 540 loss = 0.4089224636554718
training: 0.6498661041259766 epoch = 15 step = 541 loss = 0.39592301845550537
training: 0.5441906452178955 epoch = 15 step = 542 loss = 0.41651105880737305
training: 0.42690539360046387 epoch = 15 step = 543 loss = 0.4839860796928406
training: 0.46125221252441406 epoch = 15 step = 544 loss = 0.4299600124359131
training: 0.7010805606842041 epoch = 15 step = 545 loss = 0.37382209300994873
training: 0.4888613224029541 epoch = 15 step = 546 loss = 0.4144579768180847
training: 0.5330600738525391 epoch = 15 step = 547 loss = 0.42521899938583374
training: 0.4714815616607666 epoch = 15 step = 548 loss = 0.43014830350875854
training: 0.6233780384063721 epoch = 15 step = 549 loss = 0.4208659529685974
training: 0.5442426204681396 epoch = 15 step = 550 loss = 0.4399678111076355
training: 0.4641437530517578 epoch = 15 step = 551 loss = 0.40281030535697937
training: 0.5174353122711182 epoch = 15 step = 552 loss = 0.4781257212162018
training: 0.5925486087799072 epoch = 15 step = 553 loss = 0.48891401290893555
training: 0.5331261157989502 epoch = 15 step = 554 loss = 0.42811307311058044
training: 0.6107258796691895 epoch = 15 step = 555 loss = 0.4343585669994354
training: 0.5099203586578369 epoch = 15 step = 556 loss = 0.4862239956855774
training: 0.4927632808685303 epoch = 15 step = 557 loss = 0.45752787590026855
training: 0.482987642288208 epoch = 16 step = 558 loss = 0.3852221369743347
training: 0.489422082901001 epoch = 16 step = 559 loss = 0.43108367919921875
training: 0.405376672744751 epoch = 16 step = 560 loss = 0.3850909471511841
training: 0.7183187007904053 epoch = 16 step = 561 loss = 0.46123215556144714
training: 0.5574550628662109 epoch = 16 step = 562 loss = 0.3723534345626831
training: 0.5676991939544678 epoch = 16 step = 563 loss = 0.44868648052215576
training: 0.38455748558044434 epoch = 16 step = 564 loss = 0.3948633372783661
training: 0.7791130542755127 epoch = 16 step = 565 loss = 0.4379809498786926
training: 0.4736490249633789 epoch = 16 step = 566 loss = 0.4216979146003723
training: 0.5217635631561279 epoch = 16 step = 567 loss = 0.44221383333206177
training: 0.44077587127685547 epoch = 16 step = 568 loss = 0.3927376866340637
training: 0.6074135303497314 epoch = 16 step = 569 loss = 0.37643688917160034
training: 0.574894905090332 epoch = 16 step = 570 loss = 0.39977318048477173
training: 0.46910905838012695 epoch = 16 step = 571 loss = 0.4513980746269226
training: 0.525846004486084 epoch = 16 step = 572 loss = 0.41417601704597473
training: 0.5638720989227295 epoch = 16 step = 573 loss = 0.36589181423187256
training: 0.5280032157897949 epoch = 16 step = 574 loss = 0.3775593042373657
training: 0.5823297500610352 epoch = 16 step = 575 loss = 0.39596185088157654
training: 0.5115904808044434 epoch = 16 step = 576 loss = 0.39001548290252686
training: 0.5110867023468018 epoch = 16 step = 577 loss = 0.4547615051269531
training: 0.583580732345581 epoch = 16 step = 578 loss = 0.35964640974998474
training: 0.5910427570343018 epoch = 16 step = 579 loss = 0.3660690188407898
training: 0.6627728939056396 epoch = 16 step = 580 loss = 0.41232818365097046
training: 0.6122629642486572 epoch = 16 step = 581 loss = 0.4180203378200531
training: 0.5729660987854004 epoch = 16 step = 582 loss = 0.39753949642181396
training: 0.4864332675933838 epoch = 16 step = 583 loss = 0.36947643756866455
training: 0.5923199653625488 epoch = 16 step = 584 loss = 0.39415526390075684
training: 0.45603489875793457 epoch = 16 step = 585 loss = 0.43171244859695435
training: 0.513312578201294 epoch = 16 step = 586 loss = 0.40849149227142334
training: 0.4462242126464844 epoch = 16 step = 587 loss = 0.4196584224700928
training: 0.7501945495605469 epoch = 16 step = 588 loss = 0.38000044226646423
training: 0.5710794925689697 epoch = 16 step = 589 loss = 0.37399768829345703
training: 0.4485349655151367 epoch = 17 step = 590 loss = 0.39187753200531006
training: 0.4718501567840576 epoch = 17 step = 591 loss = 0.5458767414093018
training: 0.7402324676513672 epoch = 17 step = 592 loss = 0.38902902603149414
training: 0.48574042320251465 epoch = 17 step = 593 loss = 0.35785776376724243
training: 0.4718167781829834 epoch = 17 step = 594 loss = 0.41757678985595703
training: 0.5315067768096924 epoch = 17 step = 595 loss = 0.3904281556606293
training: 0.714186429977417 epoch = 17 step = 596 loss = 0.38185426592826843
training: 0.44600582122802734 epoch = 17 step = 597 loss = 0.42920053005218506
training: 0.512505292892456 epoch = 17 step = 598 loss = 0.4154519736766815
training: 0.45449018478393555 epoch = 17 step = 599 loss = 0.3841833174228668
training: 0.7597978115081787 epoch = 17 step = 600 loss = 0.4160100221633911

Devolope:
Devoloped = 0.563739538192749, epoch = 17 step = 601 loss = 0.709755539894104
Devoloped = 0.5180110931396484, epoch = 17 step = 602 loss = 0.7717373371124268
Devoloped = 0.695641040802002, epoch = 17 step = 603 loss = 0.8396213054656982
Devoloped = 0.4968380928039551, epoch = 17 step = 604 loss = 0.626067042350769
Devoloped = 0.4873692989349365, epoch = 17 step = 605 loss = 0.7603017091751099
Devoloped = 0.4654548168182373, epoch = 17 step = 606 loss = 0.9189075231552124
Devoloped = 0.6813745498657227, epoch = 17 step = 607 loss = 0.6195082664489746
Devoloped = 0.4895157814025879, epoch = 17 step = 608 loss = 0.798904538154602

Evaluate:
[ 0  0 13 ...  0  0  0]
[0 0 0 ... 0 0 0]
Testing 1.4884653091430664 step = 608
 precision= 0.8662079510703364 recall= 0.8662079510703364 f1_score= 0.8662079510703364
608 0.8662079510703364 0.8662079510703364 0.8662079510703364

training: 0.5523436069488525 epoch = 17 step = 609 loss = 0.3928724527359009
training: 0.43944501876831055 epoch = 17 step = 610 loss = 0.37292200326919556
training: 0.4633643627166748 epoch = 17 step = 611 loss = 0.3945329189300537
training: 0.3883931636810303 epoch = 17 step = 612 loss = 0.43349891901016235
training: 0.7415850162506104 epoch = 17 step = 613 loss = 0.41600993275642395
training: 0.5163724422454834 epoch = 17 step = 614 loss = 0.4434082806110382
training: 0.4419229030609131 epoch = 17 step = 615 loss = 0.36936578154563904
training: 0.5328681468963623 epoch = 17 step = 616 loss = 0.38122254610061646
training: 0.6399190425872803 epoch = 17 step = 617 loss = 0.46457478404045105
training: 0.5323677062988281 epoch = 17 step = 618 loss = 0.4553278684616089
training: 0.46315693855285645 epoch = 17 step = 619 loss = 0.42762988805770874
training: 0.4301021099090576 epoch = 17 step = 620 loss = 0.3852532207965851
training: 0.676856279373169 epoch = 17 step = 621 loss = 0.3704823851585388
training: 0.634584903717041 epoch = 17 step = 622 loss = 0.399742990732193
training: 0.4274113178253174 epoch = 17 step = 623 loss = 0.403208464384079
training: 0.4492776393890381 epoch = 17 step = 624 loss = 0.39278239011764526
training: 0.6476435661315918 epoch = 17 step = 625 loss = 0.40759795904159546
training: 0.47179269790649414 epoch = 17 step = 626 loss = 0.3769930303096771
training: 0.5370302200317383 epoch = 17 step = 627 loss = 0.34740594029426575
training: 0.5510029792785645 epoch = 17 step = 628 loss = 0.41881898045539856
training: 0.5745751857757568 epoch = 17 step = 629 loss = 0.42856448888778687
training: 0.6221718788146973 epoch = 17 step = 630 loss = 0.3820587992668152
training: 0.4087526798248291 epoch = 18 step = 631 loss = 0.3903122544288635
training: 0.40843844413757324 epoch = 18 step = 632 loss = 0.4152396023273468
training: 0.6498193740844727 epoch = 18 step = 633 loss = 0.39455246925354004
training: 0.5210726261138916 epoch = 18 step = 634 loss = 0.36504650115966797
training: 0.46886634826660156 epoch = 18 step = 635 loss = 0.34796980023384094
training: 0.4476041793823242 epoch = 18 step = 636 loss = 0.3987962007522583
training: 0.6203482151031494 epoch = 18 step = 637 loss = 0.34871774911880493
training: 0.4751925468444824 epoch = 18 step = 638 loss = 0.35920700430870056
training: 0.534451961517334 epoch = 18 step = 639 loss = 0.37526577711105347
training: 0.6132521629333496 epoch = 18 step = 640 loss = 0.3561422824859619
training: 0.5854644775390625 epoch = 18 step = 641 loss = 0.4145595133304596
training: 0.4609527587890625 epoch = 18 step = 642 loss = 0.36006250977516174
training: 0.425753116607666 epoch = 18 step = 643 loss = 0.3651638627052307
training: 0.5851023197174072 epoch = 18 step = 644 loss = 0.378023624420166
training: 0.6113631725311279 epoch = 18 step = 645 loss = 0.3611767888069153
training: 0.5677616596221924 epoch = 18 step = 646 loss = 0.4014452397823334
training: 0.5008254051208496 epoch = 18 step = 647 loss = 0.3757805824279785
training: 0.4501631259918213 epoch = 18 step = 648 loss = 0.3843742907047272
training: 0.5653371810913086 epoch = 18 step = 649 loss = 0.40119266510009766
training: 0.5443615913391113 epoch = 18 step = 650 loss = 0.37498876452445984
training: 0.6004884243011475 epoch = 18 step = 651 loss = 0.36853066086769104
training: 0.4582817554473877 epoch = 18 step = 652 loss = 0.35290831327438354
training: 0.7400803565979004 epoch = 18 step = 653 loss = 0.3398335576057434
training: 0.5344095230102539 epoch = 18 step = 654 loss = 0.3628382682800293
training: 0.5079078674316406 epoch = 18 step = 655 loss = 0.3690152168273926
training: 0.6688024997711182 epoch = 18 step = 656 loss = 0.3395916819572449
training: 0.49910449981689453 epoch = 18 step = 657 loss = 0.35643085837364197
training: 0.5034265518188477 epoch = 18 step = 658 loss = 0.37903982400894165
training: 0.4791686534881592 epoch = 18 step = 659 loss = 0.3805551826953888
training: 0.762484073638916 epoch = 18 step = 660 loss = 0.44527655839920044
training: 0.4335143566131592 epoch = 18 step = 661 loss = 0.4395088255405426
training: 0.6025776863098145 epoch = 18 step = 662 loss = 0.4182092547416687
training: 0.3770129680633545 epoch = 19 step = 663 loss = 0.4325578510761261
training: 0.6274607181549072 epoch = 19 step = 664 loss = 0.33533111214637756
training: 0.5192818641662598 epoch = 19 step = 665 loss = 0.3745213747024536
training: 0.47867441177368164 epoch = 19 step = 666 loss = 0.3451731204986572
training: 0.49439573287963867 epoch = 19 step = 667 loss = 0.3355570435523987
training: 0.619560718536377 epoch = 19 step = 668 loss = 0.37037211656570435
training: 0.4823033809661865 epoch = 19 step = 669 loss = 0.39725494384765625
training: 0.59726881980896 epoch = 19 step = 670 loss = 0.36052393913269043
training: 0.5265345573425293 epoch = 19 step = 671 loss = 0.3351028859615326
training: 0.598698616027832 epoch = 19 step = 672 loss = 0.3682525157928467
training: 0.5197582244873047 epoch = 19 step = 673 loss = 0.3859714865684509
training: 0.5026340484619141 epoch = 19 step = 674 loss = 0.3681480884552002
training: 0.47953128814697266 epoch = 19 step = 675 loss = 0.3268522620201111
training: 0.5449855327606201 epoch = 19 step = 676 loss = 0.36004728078842163
training: 0.5504717826843262 epoch = 19 step = 677 loss = 0.3808496594429016
training: 0.5085122585296631 epoch = 19 step = 678 loss = 0.4440761208534241
training: 0.5538687705993652 epoch = 19 step = 679 loss = 0.42250946164131165
training: 0.7356939315795898 epoch = 19 step = 680 loss = 0.45214998722076416
training: 0.49109697341918945 epoch = 19 step = 681 loss = 0.33772969245910645
training: 0.5485761165618896 epoch = 19 step = 682 loss = 0.35667726397514343
training: 0.5304701328277588 epoch = 19 step = 683 loss = 0.38358405232429504
training: 0.6434881687164307 epoch = 19 step = 684 loss = 0.3784745931625366
training: 0.457263708114624 epoch = 19 step = 685 loss = 0.3700696527957916
training: 0.6015641689300537 epoch = 19 step = 686 loss = 0.3276790976524353
training: 0.5179784297943115 epoch = 19 step = 687 loss = 0.36425334215164185
training: 0.6496179103851318 epoch = 19 step = 688 loss = 0.37909287214279175
training: 0.5433573722839355 epoch = 19 step = 689 loss = 0.3866276741027832
training: 0.4468240737915039 epoch = 19 step = 690 loss = 0.3501459062099457
training: 0.702871561050415 epoch = 19 step = 691 loss = 0.34960684180259705
training: 0.5140883922576904 epoch = 19 step = 692 loss = 0.3438641428947449
training: 0.6235811710357666 epoch = 19 step = 693 loss = 0.36751317977905273
training: 0.564103364944458 epoch = 19 step = 694 loss = 0.3860491216182709
training: 0.7461206912994385 epoch = 20 step = 695 loss = 0.35170459747314453
training: 0.472872257232666 epoch = 20 step = 696 loss = 0.3414350748062134
training: 0.5068984031677246 epoch = 20 step = 697 loss = 0.30757617950439453
training: 0.4918367862701416 epoch = 20 step = 698 loss = 0.33913564682006836
training: 0.6428399085998535 epoch = 20 step = 699 loss = 0.3626496195793152
training: 0.5771875381469727 epoch = 20 step = 700 loss = 0.3192031979560852

Devolope:
Devoloped = 0.6352753639221191, epoch = 20 step = 701 loss = 0.6643475294113159
Devoloped = 0.4362008571624756, epoch = 20 step = 702 loss = 0.5076718926429749
Devoloped = 0.6394844055175781, epoch = 20 step = 703 loss = 0.6826251745223999
Devoloped = 0.4751572608947754, epoch = 20 step = 704 loss = 0.5887659788131714
Devoloped = 0.5142395496368408, epoch = 20 step = 705 loss = 0.5710521936416626
Devoloped = 0.7722454071044922, epoch = 20 step = 706 loss = 0.5048905611038208
Devoloped = 0.5787935256958008, epoch = 20 step = 707 loss = 0.5916348695755005

Evaluate:
[0 0 0 ... 0 0 0]
[0 0 0 ... 0 0 0]
Testing 1.599060297012329 step = 707
 precision= 0.8839449541284403 recall= 0.8839449541284403 f1_score= 0.8839449541284403
707 0.8839449541284403 0.8839449541284403 0.8839449541284403

training: 0.5024311542510986 epoch = 20 step = 708 loss = 0.3492567539215088
training: 0.5426754951477051 epoch = 20 step = 709 loss = 0.3346019685268402
training: 0.5979611873626709 epoch = 20 step = 710 loss = 0.3905912935733795
training: 0.6779696941375732 epoch = 20 step = 711 loss = 0.346844345331192
training: 0.6317310333251953 epoch = 20 step = 712 loss = 0.40072327852249146
training: 0.48899030685424805 epoch = 20 step = 713 loss = 0.3705246150493622
training: 0.504279375076294 epoch = 20 step = 714 loss = 0.3707461953163147
training: 0.4991455078125 epoch = 20 step = 715 loss = 0.3573543429374695
training: 0.5431928634643555 epoch = 20 step = 716 loss = 0.3503504991531372
training: 0.4091801643371582 epoch = 20 step = 717 loss = 0.34247535467147827
training: 0.4196758270263672 epoch = 20 step = 718 loss = 0.3320125937461853
training: 0.6272411346435547 epoch = 20 step = 719 loss = 0.3202040195465088
training: 0.5227930545806885 epoch = 20 step = 720 loss = 0.37726888060569763
training: 0.48416805267333984 epoch = 20 step = 721 loss = 0.4694288969039917
training: 0.4762864112854004 epoch = 20 step = 722 loss = 0.36493098735809326
training: 0.5221998691558838 epoch = 20 step = 723 loss = 0.34920111298561096
training: 0.5107464790344238 epoch = 20 step = 724 loss = 0.39611706137657166
training: 0.45837998390197754 epoch = 20 step = 725 loss = 0.36138901114463806
training: 0.5149190425872803 epoch = 20 step = 726 loss = 0.36224815249443054
training: 0.7448930740356445 epoch = 20 step = 727 loss = 0.3842566907405853
training: 0.49017882347106934 epoch = 20 step = 728 loss = 0.33182650804519653
training: 0.5521373748779297 epoch = 20 step = 729 loss = 0.4210197925567627
training: 0.4436666965484619 epoch = 20 step = 730 loss = 0.32513880729675293
training: 0.686182975769043 epoch = 20 step = 731 loss = 0.3500191569328308
training: 0.4664180278778076 epoch = 20 step = 732 loss = 0.39992040395736694
training: 0.513897180557251 epoch = 20 step = 733 loss = 0.3541688919067383
training: 0.5200166702270508 epoch = 21 step = 734 loss = 0.339754194021225
training: 0.6656718254089355 epoch = 21 step = 735 loss = 0.35449692606925964
training: 0.5876719951629639 epoch = 21 step = 736 loss = 0.33980661630630493
training: 0.46446871757507324 epoch = 21 step = 737 loss = 0.3177955150604248
training: 0.5044701099395752 epoch = 21 step = 738 loss = 0.33290988206863403
training: 0.690424919128418 epoch = 21 step = 739 loss = 0.34199947118759155
training: 0.4761538505554199 epoch = 21 step = 740 loss = 0.3375440239906311
training: 0.6498913764953613 epoch = 21 step = 741 loss = 0.3625558316707611
training: 0.5157337188720703 epoch = 21 step = 742 loss = 0.36030837893486023
training: 0.6075997352600098 epoch = 21 step = 743 loss = 0.33666524291038513
training: 0.41230225563049316 epoch = 21 step = 744 loss = 0.3536709249019623
training: 0.5233011245727539 epoch = 21 step = 745 loss = 0.3283129930496216
training: 0.4321279525756836 epoch = 21 step = 746 loss = 0.3157750070095062
training: 0.721276044845581 epoch = 21 step = 747 loss = 0.33339953422546387
training: 0.42560553550720215 epoch = 21 step = 748 loss = 0.3279913067817688
training: 0.4096670150756836 epoch = 21 step = 749 loss = 0.3406203091144562
training: 0.514068603515625 epoch = 21 step = 750 loss = 0.37067240476608276
training: 0.6454691886901855 epoch = 21 step = 751 loss = 0.3193802535533905
training: 0.4396383762359619 epoch = 21 step = 752 loss = 0.30030953884124756
training: 0.4593029022216797 epoch = 21 step = 753 loss = 0.3389549255371094
training: 0.4818246364593506 epoch = 21 step = 754 loss = 0.3522721529006958
training: 0.6194238662719727 epoch = 21 step = 755 loss = 0.3169376254081726
training: 0.5296616554260254 epoch = 21 step = 756 loss = 0.308432012796402
training: 0.48131537437438965 epoch = 21 step = 757 loss = 0.34227806329727173
training: 0.5096349716186523 epoch = 21 step = 758 loss = 0.31385481357574463
training: 0.7043426036834717 epoch = 21 step = 759 loss = 0.3212006986141205
training: 0.5501718521118164 epoch = 21 step = 760 loss = 0.3656470775604248
training: 0.49706411361694336 epoch = 21 step = 761 loss = 0.379871666431427
training: 0.4524819850921631 epoch = 21 step = 762 loss = 0.30749931931495667
training: 0.6813421249389648 epoch = 21 step = 763 loss = 0.31193310022354126
training: 0.6309213638305664 epoch = 21 step = 764 loss = 0.39363494515419006
training: 0.5287368297576904 epoch = 21 step = 765 loss = 0.3288121223449707
training: 0.47823309898376465 epoch = 22 step = 766 loss = 0.36869969964027405
training: 0.5853564739227295 epoch = 22 step = 767 loss = 0.3349066376686096
training: 0.5498242378234863 epoch = 22 step = 768 loss = 0.33996254205703735
training: 0.47287869453430176 epoch = 22 step = 769 loss = 0.3466402292251587
training: 0.5432615280151367 epoch = 22 step = 770 loss = 0.31703242659568787
training: 0.5888071060180664 epoch = 22 step = 771 loss = 0.31811487674713135
training: 0.6150343418121338 epoch = 22 step = 772 loss = 0.2976604104042053
training: 0.47269201278686523 epoch = 22 step = 773 loss = 0.3135179877281189
training: 0.7480504512786865 epoch = 22 step = 774 loss = 0.32771581411361694
training: 0.47370290756225586 epoch = 22 step = 775 loss = 0.3584245443344116
training: 0.5176262855529785 epoch = 22 step = 776 loss = 0.3199032247066498
training: 0.4781515598297119 epoch = 22 step = 777 loss = 0.33817943930625916
training: 0.7132301330566406 epoch = 22 step = 778 loss = 0.43605098128318787
training: 0.48720574378967285 epoch = 22 step = 779 loss = 0.34224358201026917
training: 0.606682300567627 epoch = 22 step = 780 loss = 0.3100440502166748
training: 0.5400519371032715 epoch = 22 step = 781 loss = 0.3398025929927826
training: 0.6173856258392334 epoch = 22 step = 782 loss = 0.3388594388961792
training: 0.5008678436279297 epoch = 22 step = 783 loss = 0.3110244870185852
training: 0.5521504878997803 epoch = 22 step = 784 loss = 0.3269187808036804
training: 0.530745267868042 epoch = 22 step = 785 loss = 0.35210752487182617
training: 0.576305627822876 epoch = 22 step = 786 loss = 0.32289624214172363
training: 0.5462448596954346 epoch = 22 step = 787 loss = 0.3328400254249573
training: 0.43256425857543945 epoch = 22 step = 788 loss = 0.32266613841056824
training: 0.5303566455841064 epoch = 22 step = 789 loss = 0.3009510636329651
training: 0.7641260623931885 epoch = 22 step = 790 loss = 0.29564785957336426
training: 0.4210371971130371 epoch = 22 step = 791 loss = 0.309079110622406
training: 0.49825572967529297 epoch = 22 step = 792 loss = 0.31164664030075073
training: 0.5365114212036133 epoch = 22 step = 793 loss = 0.3473667502403259
training: 0.5263936519622803 epoch = 22 step = 794 loss = 0.3129870295524597
training: 0.5560042858123779 epoch = 22 step = 795 loss = 0.33829593658447266
training: 0.49063825607299805 epoch = 22 step = 796 loss = 0.33407604694366455
training: 0.45507240295410156 epoch = 22 step = 797 loss = 0.32744696736335754
training: 0.6438837051391602 epoch = 23 step = 798 loss = 0.3514378070831299
training: 0.4909324645996094 epoch = 23 step = 799 loss = 0.30350548028945923
training: 0.47667694091796875 epoch = 23 step = 800 loss = 0.3149317502975464

Devolope:
Devoloped = 0.4673035144805908, epoch = 23 step = 801 loss = 0.5492391586303711
Devoloped = 0.746147632598877, epoch = 23 step = 802 loss = 0.4854204058647156
Devoloped = 0.5061805248260498, epoch = 23 step = 803 loss = 0.5342929363250732
Devoloped = 0.48812413215637207, epoch = 23 step = 804 loss = 0.42153599858283997
Devoloped = 0.5234189033508301, epoch = 23 step = 805 loss = 0.536259651184082
Devoloped = 0.6341392993927002, epoch = 23 step = 806 loss = 0.4532606601715088
Devoloped = 0.6437990665435791, epoch = 23 step = 807 loss = 0.4848053455352783

Evaluate:
[ 0  0 33 ...  0  0  0]
[0 0 0 ... 0 0 0]
Testing 1.5166332721710205 step = 807
 precision= 0.8793577981651376 recall= 0.8793577981651376 f1_score= 0.8793577981651376
807 0.8793577981651376 0.8793577981651376 0.8793577981651376

training: 0.5163557529449463 epoch = 23 step = 808 loss = 0.35636863112449646
training: 0.49617695808410645 epoch = 23 step = 809 loss = 0.33545100688934326
training: 0.39005517959594727 epoch = 23 step = 810 loss = 0.3001244366168976
training: 0.6562011241912842 epoch = 23 step = 811 loss = 0.3399697244167328
training: 0.5125143527984619 epoch = 23 step = 812 loss = 0.3369045853614807
training: 0.5105018615722656 epoch = 23 step = 813 loss = 0.34058475494384766
training: 0.39635467529296875 epoch = 23 step = 814 loss = 0.32216304540634155
training: 0.7419264316558838 epoch = 23 step = 815 loss = 0.3382469713687897
training: 0.6176369190216064 epoch = 23 step = 816 loss = 0.2979346811771393
training: 0.4730074405670166 epoch = 23 step = 817 loss = 0.3251228332519531
training: 0.5197594165802002 epoch = 23 step = 818 loss = 0.3313041925430298
training: 0.5427377223968506 epoch = 23 step = 819 loss = 0.31215107440948486
training: 0.45142149925231934 epoch = 23 step = 820 loss = 0.35039207339286804
training: 0.567115068435669 epoch = 23 step = 821 loss = 0.3547948896884918
training: 0.46761369705200195 epoch = 23 step = 822 loss = 0.306213915348053
training: 0.6604952812194824 epoch = 23 step = 823 loss = 0.3307088017463684
training: 0.5237925052642822 epoch = 23 step = 824 loss = 0.29629501700401306
training: 0.5599472522735596 epoch = 23 step = 825 loss = 0.30658507347106934
training: 0.7298605442047119 epoch = 23 step = 826 loss = 0.3194129765033722
training: 0.46642279624938965 epoch = 23 step = 827 loss = 0.3021109104156494
training: 0.4329051971435547 epoch = 23 step = 828 loss = 0.32685014605522156
training: 0.5182051658630371 epoch = 23 step = 829 loss = 0.370516300201416
training: 0.4600517749786377 epoch = 23 step = 830 loss = 0.35093173384666443
training: 0.5103433132171631 epoch = 23 step = 831 loss = 0.28867998719215393
training: 0.4277677536010742 epoch = 23 step = 832 loss = 0.3191424608230591
training: 0.5358960628509521 epoch = 23 step = 833 loss = 0.3044131398200989
training: 0.5203056335449219 epoch = 23 step = 834 loss = 0.3283971846103668
training: 0.7050979137420654 epoch = 23 step = 835 loss = 0.28929561376571655
training: 0.5311648845672607 epoch = 23 step = 836 loss = 0.34291762113571167
training: 0.5050005912780762 epoch = 24 step = 837 loss = 0.3156161904335022
training: 0.45086002349853516 epoch = 24 step = 838 loss = 0.30536267161369324
training: 0.6318824291229248 epoch = 24 step = 839 loss = 0.30560794472694397
training: 0.5118563175201416 epoch = 24 step = 840 loss = 0.35817164182662964
training: 0.5093679428100586 epoch = 24 step = 841 loss = 0.3174784481525421
training: 0.528571367263794 epoch = 24 step = 842 loss = 0.2914814352989197
training: 0.5758845806121826 epoch = 24 step = 843 loss = 0.3329124450683594
training: 0.5352084636688232 epoch = 24 step = 844 loss = 0.30772870779037476
training: 0.522435188293457 epoch = 24 step = 845 loss = 0.30127912759780884
training: 0.4815077781677246 epoch = 24 step = 846 loss = 0.35164108872413635
training: 0.5915305614471436 epoch = 24 step = 847 loss = 0.29632705450057983
training: 0.5641660690307617 epoch = 24 step = 848 loss = 0.316034197807312
training: 0.4885413646697998 epoch = 24 step = 849 loss = 0.31828606128692627
training: 0.4969925880432129 epoch = 24 step = 850 loss = 0.3093036413192749
training: 0.5868277549743652 epoch = 24 step = 851 loss = 0.3675791323184967
training: 0.5710828304290771 epoch = 24 step = 852 loss = 0.3030805289745331
training: 0.405566930770874 epoch = 24 step = 853 loss = 0.2996356785297394
training: 0.556908369064331 epoch = 24 step = 854 loss = 0.33639878034591675
training: 0.5986182689666748 epoch = 24 step = 855 loss = 0.27895525097846985
training: 0.5294253826141357 epoch = 24 step = 856 loss = 0.3076472580432892
training: 0.5101675987243652 epoch = 24 step = 857 loss = 0.28328394889831543
training: 0.5427320003509521 epoch = 24 step = 858 loss = 0.41736578941345215
training: 0.5272436141967773 epoch = 24 step = 859 loss = 0.3188225328922272
training: 0.42869997024536133 epoch = 24 step = 860 loss = 0.31947991251945496
training: 0.612443208694458 epoch = 24 step = 861 loss = 0.30851584672927856
training: 0.4413940906524658 epoch = 24 step = 862 loss = 0.3040495216846466
training: 0.6911594867706299 epoch = 24 step = 863 loss = 0.30087393522262573
training: 0.46654605865478516 epoch = 24 step = 864 loss = 0.304103821516037
training: 0.5501797199249268 epoch = 24 step = 865 loss = 0.30108407139778137
training: 0.5811090469360352 epoch = 24 step = 866 loss = 0.3835478127002716
training: 0.5154695510864258 epoch = 24 step = 867 loss = 0.3188595473766327
training: 0.3952939510345459 epoch = 24 step = 868 loss = 0.3215957283973694
Evaluate:
Training:
[0 0 0 ... 0 0 0]
[0 0 0 ... 0 0 0]
Testing 1.5112316608428955 step = 868
 precision= 0.8738532110091743 recall= 0.8738532110091743 f1_score= 0.8738532110091743
868 0.8738532110091743 0.8738532110091743 0.8738532110091743

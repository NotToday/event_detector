Sents length :  43592  Anchor length :  43592  Vocab length :  8777
dimension: 300, train_size: 30514, test_size: 6538, length: 31
anchor dimension  (30514,)
Writing to /home/soumyadeep/EventDetection/runs/1523541188

training: 1.4910523891448975 epoch = 0 step = 1 loss = 3.765577793121338
training: 0.46915483474731445 epoch = 0 step = 2 loss = 3.6653614044189453
training: 0.5480780601501465 epoch = 0 step = 3 loss = 3.6050479412078857
training: 0.5831742286682129 epoch = 0 step = 4 loss = 3.5281894207000732
training: 0.5535531044006348 epoch = 0 step = 5 loss = 3.466158390045166
training: 0.7823362350463867 epoch = 0 step = 6 loss = 3.3464155197143555
training: 0.47814321517944336 epoch = 0 step = 7 loss = 3.4322521686553955
training: 0.5137817859649658 epoch = 0 step = 8 loss = 3.120063543319702
training: 0.7144460678100586 epoch = 0 step = 9 loss = 3.2876744270324707
training: 0.7350702285766602 epoch = 0 step = 10 loss = 3.058163642883301
training: 0.6665654182434082 epoch = 0 step = 11 loss = 3.015183210372925
training: 0.4847900867462158 epoch = 0 step = 12 loss = 3.080754280090332
training: 0.6189730167388916 epoch = 0 step = 13 loss = 3.1889736652374268
training: 0.5648171901702881 epoch = 0 step = 14 loss = 2.8415653705596924
training: 0.4879336357116699 epoch = 0 step = 15 loss = 2.9849729537963867
training: 0.5139110088348389 epoch = 0 step = 16 loss = 3.050096273422241
training: 0.7355880737304688 epoch = 0 step = 17 loss = 2.7250959873199463
training: 0.5762341022491455 epoch = 0 step = 18 loss = 2.956533908843994
training: 0.5234107971191406 epoch = 0 step = 19 loss = 2.907822608947754
training: 0.48088836669921875 epoch = 0 step = 20 loss = 3.0652308464050293
training: 0.572718620300293 epoch = 0 step = 21 loss = 2.574026107788086
training: 0.5129976272583008 epoch = 0 step = 22 loss = 2.780806541442871
training: 0.5566470623016357 epoch = 0 step = 23 loss = 2.6830806732177734
training: 0.6582150459289551 epoch = 0 step = 24 loss = 2.784600019454956
training: 0.5534486770629883 epoch = 0 step = 25 loss = 2.8588221073150635
training: 0.4823596477508545 epoch = 0 step = 26 loss = 2.826892137527466
training: 0.6110775470733643 epoch = 0 step = 27 loss = 2.699572801589966
training: 0.6524853706359863 epoch = 0 step = 28 loss = 2.7680437564849854
training: 0.49509143829345703 epoch = 0 step = 29 loss = 2.6840388774871826
training: 0.5152249336242676 epoch = 0 step = 30 loss = 2.5640830993652344
training: 0.8376026153564453 epoch = 0 step = 31 loss = 2.559602737426758
training: 0.4420599937438965 epoch = 0 step = 32 loss = 2.692706346511841
training: 0.4783291816711426 epoch = 1 step = 33 loss = 2.60916805267334
training: 0.5039060115814209 epoch = 1 step = 34 loss = 2.5730226039886475
training: 0.6484963893890381 epoch = 1 step = 35 loss = 2.64644455909729
training: 0.6837649345397949 epoch = 1 step = 36 loss = 2.6413536071777344
training: 0.41767120361328125 epoch = 1 step = 37 loss = 2.6375577449798584
training: 0.5155806541442871 epoch = 1 step = 38 loss = 2.6382923126220703
training: 0.6318938732147217 epoch = 1 step = 39 loss = 2.4245309829711914
training: 0.4542064666748047 epoch = 1 step = 40 loss = 2.799578905105591
training: 0.5761597156524658 epoch = 1 step = 41 loss = 2.628664970397949
training: 0.5849347114562988 epoch = 1 step = 42 loss = 2.413878917694092
training: 0.4990875720977783 epoch = 1 step = 43 loss = 2.493894100189209
training: 0.5012998580932617 epoch = 1 step = 44 loss = 2.4531302452087402
training: 0.4955103397369385 epoch = 1 step = 45 loss = 2.5863490104675293
training: 0.5616989135742188 epoch = 1 step = 46 loss = 2.4159762859344482
training: 0.5938723087310791 epoch = 1 step = 47 loss = 2.5210962295532227
training: 0.4682438373565674 epoch = 1 step = 48 loss = 2.6701717376708984
training: 0.6175625324249268 epoch = 1 step = 49 loss = 2.486832618713379
training: 0.5291061401367188 epoch = 1 step = 50 loss = 2.541905403137207
training: 0.521043062210083 epoch = 1 step = 51 loss = 2.754828929901123
training: 0.6581964492797852 epoch = 1 step = 52 loss = 2.594527006149292
training: 0.4699430465698242 epoch = 1 step = 53 loss = 2.6149911880493164
training: 0.6624388694763184 epoch = 1 step = 54 loss = 2.5428619384765625
training: 0.44657349586486816 epoch = 1 step = 55 loss = 2.5441322326660156
training: 0.5217442512512207 epoch = 1 step = 56 loss = 2.426313877105713
training: 0.6569185256958008 epoch = 1 step = 57 loss = 2.5335960388183594
training: 0.5711832046508789 epoch = 1 step = 58 loss = 2.6424410343170166
training: 0.5189995765686035 epoch = 1 step = 59 loss = 2.5055155754089355
training: 0.5563642978668213 epoch = 1 step = 60 loss = 2.6676037311553955
training: 0.49651479721069336 epoch = 1 step = 61 loss = 2.6399729251861572
training: 0.6661820411682129 epoch = 1 step = 62 loss = 2.697380542755127
training: 0.5301470756530762 epoch = 1 step = 63 loss = 2.3619704246520996
training: 0.5411167144775391 epoch = 1 step = 64 loss = 2.5042433738708496
training: 0.5296406745910645 epoch = 2 step = 65 loss = 2.4873414039611816
training: 0.47427988052368164 epoch = 2 step = 66 loss = 2.3358867168426514
training: 0.4734628200531006 epoch = 2 step = 67 loss = 2.5430502891540527
training: 0.5849065780639648 epoch = 2 step = 68 loss = 2.1962883472442627
training: 0.46504712104797363 epoch = 2 step = 69 loss = 2.439126491546631
training: 0.48528337478637695 epoch = 2 step = 70 loss = 2.1222970485687256
training: 0.5422370433807373 epoch = 2 step = 71 loss = 2.35652494430542
training: 0.553056001663208 epoch = 2 step = 72 loss = 2.3384063243865967
training: 0.6928198337554932 epoch = 2 step = 73 loss = 2.4175398349761963
training: 0.49999213218688965 epoch = 2 step = 74 loss = 2.4886085987091064
training: 0.5280437469482422 epoch = 2 step = 75 loss = 2.519767999649048
training: 0.5062990188598633 epoch = 2 step = 76 loss = 2.2812399864196777
training: 0.6988990306854248 epoch = 2 step = 77 loss = 2.285512685775757
training: 0.5259435176849365 epoch = 2 step = 78 loss = 2.391975164413452
training: 0.4559903144836426 epoch = 2 step = 79 loss = 2.1872341632843018
training: 0.5137827396392822 epoch = 2 step = 80 loss = 2.2107303142547607
training: 0.5590250492095947 epoch = 2 step = 81 loss = 2.3109734058380127
training: 0.5448424816131592 epoch = 2 step = 82 loss = 2.5239999294281006
training: 0.5578863620758057 epoch = 2 step = 83 loss = 2.342702627182007
training: 0.4464104175567627 epoch = 2 step = 84 loss = 2.4502944946289062
training: 0.7170505523681641 epoch = 2 step = 85 loss = 2.1775872707366943
training: 0.5267984867095947 epoch = 2 step = 86 loss = 2.225583076477051
training: 0.5016281604766846 epoch = 2 step = 87 loss = 2.3970885276794434
training: 0.39288902282714844 epoch = 2 step = 88 loss = 2.598635673522949
training: 0.7854256629943848 epoch = 2 step = 89 loss = 2.369234085083008
training: 0.5099227428436279 epoch = 2 step = 90 loss = 2.3253753185272217
training: 0.44370532035827637 epoch = 2 step = 91 loss = 2.3340063095092773
training: 0.7063450813293457 epoch = 2 step = 92 loss = 2.5018997192382812
training: 0.5361297130584717 epoch = 2 step = 93 loss = 2.531161308288574
training: 0.4873471260070801 epoch = 2 step = 94 loss = 2.3691253662109375
training: 0.584784984588623 epoch = 2 step = 95 loss = 2.0123658180236816
training: 0.676868200302124 epoch = 2 step = 96 loss = 2.330845832824707
training: 0.502798318862915 epoch = 3 step = 97 loss = 2.2681376934051514
training: 0.5393838882446289 epoch = 3 step = 98 loss = 2.0262608528137207
training: 0.5055403709411621 epoch = 3 step = 99 loss = 2.3919930458068848
training: 0.7904458045959473 epoch = 3 step = 100 loss = 2.2367801666259766

Devolope:
Devoloped = 0.5784244537353516, epoch = 3 step = 101 loss = 2.7284340858459473
Devoloped = 0.5465362071990967, epoch = 3 step = 102 loss = 2.506157875061035
Devoloped = 0.7782244682312012, epoch = 3 step = 103 loss = 2.7640762329101562
Devoloped = 0.4543731212615967, epoch = 3 step = 104 loss = 2.3384921550750732
Devoloped = 0.6169636249542236, epoch = 3 step = 105 loss = 2.7740163803100586
Devoloped = 0.41968655586242676, epoch = 3 step = 106 loss = 2.575676679611206
Devoloped = 0.6758954524993896, epoch = 3 step = 107 loss = 2.4501895904541016
Devoloped = 0.5018420219421387, epoch = 3 step = 108 loss = 2.7401247024536133

Evaluate:
[0 0 5 ... 7 7 5]
[0 0 0 ... 0 0 0]
Testing 2.3043646812438965 step = 108
 precision= 0.4396024464831804 recall= 0.4396024464831804 f1_score= 0.4396024464831804
108 0.4396024464831804 0.4396024464831804 0.4396024464831804

training: 0.540717601776123 epoch = 3 step = 109 loss = 2.129220485687256
training: 0.6527762413024902 epoch = 3 step = 110 loss = 2.0602035522460938
training: 0.5688395500183105 epoch = 3 step = 111 loss = 2.313396453857422
training: 0.49555277824401855 epoch = 3 step = 112 loss = 2.084944725036621
training: 0.5248305797576904 epoch = 3 step = 113 loss = 2.2891244888305664
training: 0.6874513626098633 epoch = 3 step = 114 loss = 2.3558287620544434
training: 0.4705343246459961 epoch = 3 step = 115 loss = 2.3270037174224854
training: 0.45258569717407227 epoch = 3 step = 116 loss = 2.592315673828125
training: 0.6236283779144287 epoch = 3 step = 117 loss = 2.267486333847046
training: 0.4914815425872803 epoch = 3 step = 118 loss = 2.0960402488708496
training: 0.44800734519958496 epoch = 3 step = 119 loss = 1.9596621990203857
training: 0.4714787006378174 epoch = 3 step = 120 loss = 2.087367534637451
training: 0.4998509883880615 epoch = 3 step = 121 loss = 2.1113927364349365
training: 0.7103559970855713 epoch = 3 step = 122 loss = 2.219536781311035
training: 0.5878918170928955 epoch = 3 step = 123 loss = 2.2154958248138428
training: 0.46297168731689453 epoch = 3 step = 124 loss = 2.2477970123291016
training: 0.5277097225189209 epoch = 3 step = 125 loss = 2.0032737255096436
training: 0.5802826881408691 epoch = 3 step = 126 loss = 1.9431893825531006
training: 0.4301595687866211 epoch = 3 step = 127 loss = 2.13810396194458
training: 0.505204439163208 epoch = 3 step = 128 loss = 2.351857900619507
training: 0.5882196426391602 epoch = 3 step = 129 loss = 2.1625924110412598
training: 0.4284060001373291 epoch = 3 step = 130 loss = 1.856339693069458
training: 0.5321314334869385 epoch = 3 step = 131 loss = 2.178341865539551
training: 0.6296675205230713 epoch = 3 step = 132 loss = 2.2757225036621094
training: 0.7119789123535156 epoch = 3 step = 133 loss = 2.1192586421966553
training: 0.4849236011505127 epoch = 3 step = 134 loss = 2.1195125579833984
training: 0.5148968696594238 epoch = 3 step = 135 loss = 2.261916160583496
training: 0.5435042381286621 epoch = 3 step = 136 loss = 2.128591775894165
training: 0.7425699234008789 epoch = 3 step = 137 loss = 1.6383579969406128
training: 0.5491504669189453 epoch = 4 step = 138 loss = 2.0004324913024902
training: 0.5427777767181396 epoch = 4 step = 139 loss = 2.0964136123657227
training: 0.5036835670471191 epoch = 4 step = 140 loss = 1.9179168939590454
training: 0.5257167816162109 epoch = 4 step = 141 loss = 1.921810269355774
training: 0.45832109451293945 epoch = 4 step = 142 loss = 2.080582618713379
training: 0.48250842094421387 epoch = 4 step = 143 loss = 1.9140102863311768
training: 0.5182020664215088 epoch = 4 step = 144 loss = 1.9166663885116577
training: 0.5661423206329346 epoch = 4 step = 145 loss = 2.061628580093384
training: 0.5390191078186035 epoch = 4 step = 146 loss = 1.7259007692337036
training: 0.6218712329864502 epoch = 4 step = 147 loss = 1.9836478233337402
training: 0.514094352722168 epoch = 4 step = 148 loss = 1.9756605625152588
training: 0.5516226291656494 epoch = 4 step = 149 loss = 1.8953533172607422
training: 0.5768616199493408 epoch = 4 step = 150 loss = 2.004692554473877
training: 0.5572957992553711 epoch = 4 step = 151 loss = 2.0034875869750977
training: 0.6948466300964355 epoch = 4 step = 152 loss = 1.8145949840545654
training: 0.5620148181915283 epoch = 4 step = 153 loss = 1.987757682800293
training: 0.5120937824249268 epoch = 4 step = 154 loss = 1.7597674131393433
training: 0.5878510475158691 epoch = 4 step = 155 loss = 2.0223615169525146
training: 0.6116204261779785 epoch = 4 step = 156 loss = 2.0496761798858643
training: 0.5358893871307373 epoch = 4 step = 157 loss = 2.0612337589263916
training: 0.49495673179626465 epoch = 4 step = 158 loss = 1.7422090768814087
training: 0.5212132930755615 epoch = 4 step = 159 loss = 2.0668013095855713
training: 0.4702165126800537 epoch = 4 step = 160 loss = 1.8878453969955444
training: 0.488450288772583 epoch = 4 step = 161 loss = 1.954537272453308
training: 0.5176091194152832 epoch = 4 step = 162 loss = 1.9376262426376343
training: 0.6183233261108398 epoch = 4 step = 163 loss = 1.9047869443893433
training: 0.44231534004211426 epoch = 4 step = 164 loss = 1.9904398918151855
training: 0.5767312049865723 epoch = 4 step = 165 loss = 1.960957407951355
training: 0.4353218078613281 epoch = 4 step = 166 loss = 1.9665592908859253
training: 0.5078616142272949 epoch = 4 step = 167 loss = 1.864626407623291
training: 0.7496609687805176 epoch = 4 step = 168 loss = 1.7755928039550781
training: 0.5968756675720215 epoch = 4 step = 169 loss = 1.9951311349868774
training: 0.6289894580841064 epoch = 5 step = 170 loss = 1.7480483055114746
training: 0.6725523471832275 epoch = 5 step = 171 loss = 1.8483883142471313
training: 0.5935351848602295 epoch = 5 step = 172 loss = 1.626967430114746
training: 0.6083431243896484 epoch = 5 step = 173 loss = 1.6161606311798096
training: 0.664473295211792 epoch = 5 step = 174 loss = 1.7900203466415405
training: 0.4568295478820801 epoch = 5 step = 175 loss = 1.6061064004898071
training: 0.5201530456542969 epoch = 5 step = 176 loss = 1.5555487871170044
training: 0.5753765106201172 epoch = 5 step = 177 loss = 1.7684115171432495
training: 0.6523258686065674 epoch = 5 step = 178 loss = 1.7746607065200806
training: 0.5060269832611084 epoch = 5 step = 179 loss = 1.7330137491226196
training: 0.6030056476593018 epoch = 5 step = 180 loss = 1.814414381980896
training: 0.5829572677612305 epoch = 5 step = 181 loss = 1.7483500242233276
training: 0.6257436275482178 epoch = 5 step = 182 loss = 1.8310716152191162
training: 0.4852440357208252 epoch = 5 step = 183 loss = 1.426640272140503
training: 0.508613109588623 epoch = 5 step = 184 loss = 1.5187816619873047
training: 0.44002628326416016 epoch = 5 step = 185 loss = 1.811129093170166
training: 0.5191195011138916 epoch = 5 step = 186 loss = 1.6815260648727417
training: 0.4627103805541992 epoch = 5 step = 187 loss = 1.6863455772399902
training: 0.5603492259979248 epoch = 5 step = 188 loss = 1.6501845121383667
training: 0.4986398220062256 epoch = 5 step = 189 loss = 1.6451011896133423
training: 0.7429780960083008 epoch = 5 step = 190 loss = 1.8202338218688965
training: 0.5333383083343506 epoch = 5 step = 191 loss = 1.4884181022644043
training: 0.47107458114624023 epoch = 5 step = 192 loss = 1.4889410734176636
training: 0.6533219814300537 epoch = 5 step = 193 loss = 1.7451475858688354
training: 0.6180915832519531 epoch = 5 step = 194 loss = 1.8251689672470093
training: 0.47653627395629883 epoch = 5 step = 195 loss = 1.6044598817825317
training: 0.53277587890625 epoch = 5 step = 196 loss = 1.7943165302276611
training: 0.6121242046356201 epoch = 5 step = 197 loss = 1.6434050798416138
training: 0.5148308277130127 epoch = 5 step = 198 loss = 1.5134351253509521
training: 0.5374855995178223 epoch = 5 step = 199 loss = 1.6870990991592407
training: 0.520512580871582 epoch = 5 step = 200 loss = 1.8901114463806152

Devolope:
Devoloped = 0.675347089767456, epoch = 5 step = 201 loss = 2.2656378746032715
Devoloped = 0.4969465732574463, epoch = 5 step = 202 loss = 2.3422634601593018
Devoloped = 0.43720459938049316, epoch = 5 step = 203 loss = 2.352679967880249
Devoloped = 0.5607109069824219, epoch = 5 step = 204 loss = 2.5739519596099854
Devoloped = 0.6265788078308105, epoch = 5 step = 205 loss = 2.5239267349243164
Devoloped = 0.4275023937225342, epoch = 5 step = 206 loss = 2.355987548828125
Devoloped = 0.5803029537200928, epoch = 5 step = 207 loss = 2.2036263942718506

Evaluate:
[0 0 5 ... 0 0 5]
[0 0 0 ... 0 0 0]
Testing 1.9684524536132812 step = 207
 precision= 0.27660550458715594 recall= 0.27660550458715594 f1_score= 0.27660550458715594
207 0.27660550458715594 0.27660550458715594 0.27660550458715594

training: 0.5527007579803467 epoch = 5 step = 208 loss = 1.6496585607528687
training: 0.520695686340332 epoch = 5 step = 209 loss = 3.2893929481506348
training: 0.49624180793762207 epoch = 6 step = 210 loss = 1.3652780055999756
training: 0.4403090476989746 epoch = 6 step = 211 loss = 1.5715664625167847
training: 0.45385146141052246 epoch = 6 step = 212 loss = 1.5862776041030884
training: 0.6446371078491211 epoch = 6 step = 213 loss = 1.5682799816131592
training: 0.5944936275482178 epoch = 6 step = 214 loss = 1.7246625423431396
training: 0.5539035797119141 epoch = 6 step = 215 loss = 1.7822074890136719
training: 0.7585759162902832 epoch = 6 step = 216 loss = 1.431618571281433
training: 0.4923534393310547 epoch = 6 step = 217 loss = 1.4861418008804321
training: 0.521420955657959 epoch = 6 step = 218 loss = 1.4866790771484375
training: 0.6167898178100586 epoch = 6 step = 219 loss = 1.3415101766586304
training: 0.5825300216674805 epoch = 6 step = 220 loss = 1.4232462644577026
training: 0.5534563064575195 epoch = 6 step = 221 loss = 1.6570056676864624
training: 0.5112137794494629 epoch = 6 step = 222 loss = 1.580284595489502
training: 0.6851112842559814 epoch = 6 step = 223 loss = 1.3314063549041748
training: 0.44574642181396484 epoch = 6 step = 224 loss = 1.6031321287155151
training: 0.5843605995178223 epoch = 6 step = 225 loss = 1.6321563720703125
training: 0.5024616718292236 epoch = 6 step = 226 loss = 1.3958797454833984
training: 0.4395289421081543 epoch = 6 step = 227 loss = 1.6741702556610107
training: 0.6460461616516113 epoch = 6 step = 228 loss = 1.4971907138824463
training: 0.5764062404632568 epoch = 6 step = 229 loss = 1.4971317052841187
training: 0.5076754093170166 epoch = 6 step = 230 loss = 1.4473196268081665
training: 0.6698081493377686 epoch = 6 step = 231 loss = 1.3703099489212036
training: 0.4695439338684082 epoch = 6 step = 232 loss = 1.4234365224838257
training: 0.43575334548950195 epoch = 6 step = 233 loss = 1.384730577468872
training: 0.44266748428344727 epoch = 6 step = 234 loss = 1.536440372467041
training: 0.6781837940216064 epoch = 6 step = 235 loss = 1.2803637981414795
training: 0.6161079406738281 epoch = 6 step = 236 loss = 1.6789695024490356
training: 0.5225992202758789 epoch = 6 step = 237 loss = 1.346084713935852
training: 0.5160937309265137 epoch = 6 step = 238 loss = 1.368775486946106
training: 0.7641468048095703 epoch = 6 step = 239 loss = 1.6191823482513428
training: 0.49360108375549316 epoch = 6 step = 240 loss = 1.4913051128387451
training: 0.5094976425170898 epoch = 6 step = 241 loss = 1.314542531967163
training: 0.5054666996002197 epoch = 7 step = 242 loss = 1.0951992273330688
training: 0.4824228286743164 epoch = 7 step = 243 loss = 1.3845925331115723
training: 0.4887361526489258 epoch = 7 step = 244 loss = 1.282191276550293
training: 0.5413081645965576 epoch = 7 step = 245 loss = 1.2523682117462158
training: 0.5110807418823242 epoch = 7 step = 246 loss = 1.2608145475387573
training: 0.6658799648284912 epoch = 7 step = 247 loss = 1.1218196153640747
training: 0.5197908878326416 epoch = 7 step = 248 loss = 1.2243247032165527
training: 0.5123507976531982 epoch = 7 step = 249 loss = 1.203189492225647
training: 0.461899995803833 epoch = 7 step = 250 loss = 1.4274507761001587
training: 0.5665600299835205 epoch = 7 step = 251 loss = 1.427802324295044
training: 0.5463244915008545 epoch = 7 step = 252 loss = 1.2981085777282715
training: 0.5766937732696533 epoch = 7 step = 253 loss = 1.1013902425765991
training: 0.6595892906188965 epoch = 7 step = 254 loss = 1.1385146379470825
training: 0.5890982151031494 epoch = 7 step = 255 loss = 1.1551016569137573
training: 0.4838566780090332 epoch = 7 step = 256 loss = 1.3500175476074219
training: 0.5409529209136963 epoch = 7 step = 257 loss = 1.221779227256775
training: 0.7297208309173584 epoch = 7 step = 258 loss = 1.3392877578735352
training: 0.6043689250946045 epoch = 7 step = 259 loss = 1.2605968713760376
training: 0.5665955543518066 epoch = 7 step = 260 loss = 1.2085673809051514
training: 0.4521157741546631 epoch = 7 step = 261 loss = 0.9772109985351562
training: 0.6084723472595215 epoch = 7 step = 262 loss = 1.258124828338623
training: 0.49706125259399414 epoch = 7 step = 263 loss = 1.3525142669677734
training: 0.45607924461364746 epoch = 7 step = 264 loss = 1.3443926572799683
training: 0.4867997169494629 epoch = 7 step = 265 loss = 1.2268540859222412
training: 0.595102071762085 epoch = 7 step = 266 loss = 1.2867602109909058
training: 0.5644149780273438 epoch = 7 step = 267 loss = 1.021270751953125
training: 0.5888192653656006 epoch = 7 step = 268 loss = 1.2618882656097412
training: 0.5860159397125244 epoch = 7 step = 269 loss = 1.3632382154464722
training: 0.5714800357818604 epoch = 7 step = 270 loss = 1.2400012016296387
training: 0.5443201065063477 epoch = 7 step = 271 loss = 1.1692323684692383
training: 0.510697603225708 epoch = 7 step = 272 loss = 1.2858290672302246
training: 0.7893702983856201 epoch = 7 step = 273 loss = 1.4524767398834229
training: 0.5183322429656982 epoch = 8 step = 274 loss = 0.9827008843421936
training: 0.5204451084136963 epoch = 8 step = 275 loss = 1.0267752408981323
training: 0.7705082893371582 epoch = 8 step = 276 loss = 0.9941150546073914
training: 0.47672319412231445 epoch = 8 step = 277 loss = 0.9810643196105957
training: 0.6396200656890869 epoch = 8 step = 278 loss = 1.1427556276321411
training: 0.43282270431518555 epoch = 8 step = 279 loss = 1.2492575645446777
training: 0.6002020835876465 epoch = 8 step = 280 loss = 0.8937557935714722
training: 0.5287735462188721 epoch = 8 step = 281 loss = 0.9263941049575806
training: 0.5862936973571777 epoch = 8 step = 282 loss = 0.9444352388381958
training: 0.4547886848449707 epoch = 8 step = 283 loss = 1.1454252004623413
training: 0.7714519500732422 epoch = 8 step = 284 loss = 0.9154500365257263
training: 0.5715978145599365 epoch = 8 step = 285 loss = 1.0156217813491821
training: 0.4519460201263428 epoch = 8 step = 286 loss = 0.9407066702842712
training: 0.6978278160095215 epoch = 8 step = 287 loss = 1.0326156616210938
training: 0.45246076583862305 epoch = 8 step = 288 loss = 1.140868067741394
training: 0.4662134647369385 epoch = 8 step = 289 loss = 0.9377217292785645
training: 0.524193286895752 epoch = 8 step = 290 loss = 1.0605469942092896
training: 0.6196627616882324 epoch = 8 step = 291 loss = 1.0140290260314941
training: 0.45190000534057617 epoch = 8 step = 292 loss = 0.8447616696357727
training: 0.38661837577819824 epoch = 8 step = 293 loss = 1.0785876512527466
training: 0.6173937320709229 epoch = 8 step = 294 loss = 0.8846956491470337
training: 0.6575613021850586 epoch = 8 step = 295 loss = 0.9501214623451233
training: 0.5345752239227295 epoch = 8 step = 296 loss = 1.0991568565368652
training: 0.41777634620666504 epoch = 8 step = 297 loss = 1.1117973327636719
training: 0.4838838577270508 epoch = 8 step = 298 loss = 1.0504119396209717
training: 0.6929192543029785 epoch = 8 step = 299 loss = 0.9518550634384155
training: 0.5459208488464355 epoch = 8 step = 300 loss = 0.9984151124954224

Devolope:
Devoloped = 0.5085701942443848, epoch = 8 step = 301 loss = 2.281745433807373
Devoloped = 0.5056242942810059, epoch = 8 step = 302 loss = 2.10371470451355
Devoloped = 0.6746761798858643, epoch = 8 step = 303 loss = 2.454233407974243
Devoloped = 0.502202033996582, epoch = 8 step = 304 loss = 2.0308890342712402
Devoloped = 0.48607850074768066, epoch = 8 step = 305 loss = 1.974658489227295
Devoloped = 0.5400397777557373, epoch = 8 step = 306 loss = 2.2653608322143555
Devoloped = 0.6223931312561035, epoch = 8 step = 307 loss = 1.885744571685791
Devoloped = 0.4443070888519287, epoch = 8 step = 308 loss = 2.190009832382202

Evaluate:
[7 0 0 ... 0 0 0]
[0 0 0 ... 0 0 0]
Testing 1.9033119678497314 step = 308
 precision= 0.696177370030581 recall= 0.696177370030581 f1_score= 0.696177370030581
308 0.696177370030581 0.696177370030581 0.696177370030581

training: 0.5754475593566895 epoch = 8 step = 309 loss = 1.2870198488235474
training: 0.576890230178833 epoch = 8 step = 310 loss = 1.13044011592865
training: 0.6470427513122559 epoch = 8 step = 311 loss = 1.2476081848144531
training: 0.5378642082214355 epoch = 8 step = 312 loss = 1.260224461555481
training: 0.5132496356964111 epoch = 8 step = 313 loss = 1.1875299215316772
training: 0.5103809833526611 epoch = 9 step = 314 loss = 1.0389366149902344
training: 0.6335489749908447 epoch = 9 step = 315 loss = 0.9086461663246155
training: 0.5372512340545654 epoch = 9 step = 316 loss = 0.881850004196167
training: 0.43125176429748535 epoch = 9 step = 317 loss = 0.7867329716682434
training: 0.5079410076141357 epoch = 9 step = 318 loss = 1.1347633600234985
training: 0.5118777751922607 epoch = 9 step = 319 loss = 0.8762657046318054
training: 0.4564778804779053 epoch = 9 step = 320 loss = 0.975434422492981
training: 0.5448384284973145 epoch = 9 step = 321 loss = 0.8104497194290161
training: 0.5141861438751221 epoch = 9 step = 322 loss = 0.7963676452636719
training: 0.5771217346191406 epoch = 9 step = 323 loss = 1.0898511409759521
training: 0.45972490310668945 epoch = 9 step = 324 loss = 0.7502020001411438
training: 0.49671435356140137 epoch = 9 step = 325 loss = 0.8007731437683105
training: 0.578932523727417 epoch = 9 step = 326 loss = 1.0431238412857056
training: 0.49077558517456055 epoch = 9 step = 327 loss = 0.8579478859901428
training: 0.5757937431335449 epoch = 9 step = 328 loss = 0.8007540702819824
training: 0.6189610958099365 epoch = 9 step = 329 loss = 0.9059439897537231
training: 0.7678279876708984 epoch = 9 step = 330 loss = 0.949932336807251
training: 0.5170493125915527 epoch = 9 step = 331 loss = 0.7370281219482422
training: 0.4732027053833008 epoch = 9 step = 332 loss = 0.9837155938148499
training: 0.45885396003723145 epoch = 9 step = 333 loss = 0.7879269123077393
training: 0.5503537654876709 epoch = 9 step = 334 loss = 0.9010599255561829
training: 0.5366387367248535 epoch = 9 step = 335 loss = 0.8803786635398865
training: 0.5696361064910889 epoch = 9 step = 336 loss = 0.8656453490257263
training: 0.5671520233154297 epoch = 9 step = 337 loss = 0.8937770128250122
training: 0.6385674476623535 epoch = 9 step = 338 loss = 1.00382399559021
training: 0.4669685363769531 epoch = 9 step = 339 loss = 0.9407945871353149
training: 0.636953592300415 epoch = 9 step = 340 loss = 0.766128420829773
training: 0.6712374687194824 epoch = 9 step = 341 loss = 1.1425831317901611
training: 0.4808940887451172 epoch = 9 step = 342 loss = 0.9092204570770264
training: 0.5427670478820801 epoch = 9 step = 343 loss = 0.8959159255027771
training: 0.5361571311950684 epoch = 9 step = 344 loss = 0.9263176918029785
training: 0.6173319816589355 epoch = 9 step = 345 loss = 0.8095189332962036
training: 0.393233060836792 epoch = 10 step = 346 loss = 0.8023034334182739
training: 0.5179831981658936 epoch = 10 step = 347 loss = 0.7620468139648438
training: 0.46829986572265625 epoch = 10 step = 348 loss = 0.8473300933837891
training: 0.7442843914031982 epoch = 10 step = 349 loss = 0.8241137862205505
training: 0.4648284912109375 epoch = 10 step = 350 loss = 0.5277324318885803
training: 0.5911867618560791 epoch = 10 step = 351 loss = 0.670886218547821
training: 0.5282597541809082 epoch = 10 step = 352 loss = 0.8629482984542847
training: 0.8409397602081299 epoch = 10 step = 353 loss = 0.8056259155273438
training: 0.603304386138916 epoch = 10 step = 354 loss = 0.6243730783462524
training: 0.5761380195617676 epoch = 10 step = 355 loss = 0.7921382784843445
training: 0.6090273857116699 epoch = 10 step = 356 loss = 0.7183801531791687
training: 0.5375320911407471 epoch = 10 step = 357 loss = 0.6917410492897034
training: 0.5002164840698242 epoch = 10 step = 358 loss = 0.7802306413650513
training: 0.5069544315338135 epoch = 10 step = 359 loss = 0.7875015139579773
training: 0.6473557949066162 epoch = 10 step = 360 loss = 0.9294039607048035
training: 0.6142208576202393 epoch = 10 step = 361 loss = 0.9222717881202698
training: 0.5672450065612793 epoch = 10 step = 362 loss = 0.7440800666809082
training: 0.7254133224487305 epoch = 10 step = 363 loss = 0.8195641040802002
training: 0.5790126323699951 epoch = 10 step = 364 loss = 0.8245849609375
training: 0.39189815521240234 epoch = 10 step = 365 loss = 0.702123761177063
training: 0.570418119430542 epoch = 10 step = 366 loss = 0.8330704569816589
training: 0.7714951038360596 epoch = 10 step = 367 loss = 0.6639461517333984
training: 0.5417730808258057 epoch = 10 step = 368 loss = 0.8388620615005493
training: 0.40944886207580566 epoch = 10 step = 369 loss = 0.8508428931236267
training: 0.6431021690368652 epoch = 10 step = 370 loss = 0.7019822001457214
training: 0.6080002784729004 epoch = 10 step = 371 loss = 0.7063539028167725
training: 0.4640820026397705 epoch = 10 step = 372 loss = 0.7758945822715759
training: 0.4604666233062744 epoch = 10 step = 373 loss = 0.6662845611572266
training: 0.7278978824615479 epoch = 10 step = 374 loss = 0.7456416487693787
training: 0.48571109771728516 epoch = 10 step = 375 loss = 0.8769186735153198
training: 0.5196776390075684 epoch = 10 step = 376 loss = 0.7561721205711365
training: 0.4721713066101074 epoch = 10 step = 377 loss = 0.7778283357620239
training: 0.789116621017456 epoch = 10 step = 378 loss = 0.7278413772583008
training: 0.4312424659729004 epoch = 11 step = 379 loss = 0.660163402557373
training: 0.5739569664001465 epoch = 11 step = 380 loss = 0.7954941987991333
training: 0.4651331901550293 epoch = 11 step = 381 loss = 0.6547421216964722
training: 0.6418085098266602 epoch = 11 step = 382 loss = 0.631060004234314
training: 0.6147141456604004 epoch = 11 step = 383 loss = 0.519820511341095
training: 0.5354452133178711 epoch = 11 step = 384 loss = 0.6960013508796692
training: 0.46040892601013184 epoch = 11 step = 385 loss = 0.5761809945106506
training: 0.4132401943206787 epoch = 11 step = 386 loss = 0.6599279046058655
training: 0.5457031726837158 epoch = 11 step = 387 loss = 0.6918010711669922
training: 0.37459683418273926 epoch = 11 step = 388 loss = 0.8060889840126038
training: 0.5792062282562256 epoch = 11 step = 389 loss = 0.6101009249687195
training: 0.6128377914428711 epoch = 11 step = 390 loss = 0.5590366125106812
training: 0.5158014297485352 epoch = 11 step = 391 loss = 0.7242023944854736
training: 0.49424266815185547 epoch = 11 step = 392 loss = 0.6787011623382568
training: 0.6107134819030762 epoch = 11 step = 393 loss = 0.7633047103881836
training: 0.562671422958374 epoch = 11 step = 394 loss = 0.7503581643104553
training: 0.44654393196105957 epoch = 11 step = 395 loss = 0.6395195126533508
training: 0.551267147064209 epoch = 11 step = 396 loss = 0.6798826456069946
training: 0.5266637802124023 epoch = 11 step = 397 loss = 0.7523497343063354
training: 0.5506076812744141 epoch = 11 step = 398 loss = 0.6496928930282593
training: 0.528839111328125 epoch = 11 step = 399 loss = 0.7035508751869202
training: 0.6107828617095947 epoch = 11 step = 400 loss = 0.605965256690979

Devolope:
Devoloped = 0.6818313598632812, epoch = 11 step = 401 loss = 1.32196044921875
Devoloped = 0.6683201789855957, epoch = 11 step = 402 loss = 1.5942424535751343
Devoloped = 0.4784395694732666, epoch = 11 step = 403 loss = 1.7816922664642334
Devoloped = 0.554152250289917, epoch = 11 step = 404 loss = 1.603389024734497
Devoloped = 0.682288646697998, epoch = 11 step = 405 loss = 1.5625818967819214
Devoloped = 0.5493993759155273, epoch = 11 step = 406 loss = 1.5535579919815063
Devoloped = 0.42622852325439453, epoch = 11 step = 407 loss = 1.4602375030517578
Devoloped = 0.507636308670044, epoch = 11 step = 408 loss = 1.1002626419067383

Evaluate:
[0 0 5 ... 0 0 0]
[0 0 0 ... 0 0 0]
Testing 1.8762238025665283 step = 408
 precision= 0.6585626911314985 recall= 0.6585626911314985 f1_score= 0.6585626911314985
408 0.6585626911314985 0.6585626911314985 0.6585626911314985

training: 0.7683227062225342 epoch = 11 step = 409 loss = 0.6524931192398071
training: 0.46483445167541504 epoch = 11 step = 410 loss = 0.6463289260864258
training: 0.5564188957214355 epoch = 11 step = 411 loss = 0.843589186668396
training: 0.5248284339904785 epoch = 11 step = 412 loss = 0.7465091943740845
training: 0.513425350189209 epoch = 11 step = 413 loss = 0.7700007557868958
training: 0.4697103500366211 epoch = 11 step = 414 loss = 0.7555480003356934
training: 0.544562816619873 epoch = 11 step = 415 loss = 0.7091702818870544
training: 0.411632776260376 epoch = 11 step = 416 loss = 0.6245843768119812
training: 0.7281494140625 epoch = 11 step = 417 loss = 0.6405751705169678
training: 0.5705914497375488 epoch = 11 step = 418 loss = 0.681795597076416
training: 0.5657246112823486 epoch = 11 step = 419 loss = 0.8203462362289429
training: 0.7061848640441895 epoch = 12 step = 420 loss = 0.6540684700012207
training: 0.45209383964538574 epoch = 12 step = 421 loss = 0.6906971335411072
training: 0.5229263305664062 epoch = 12 step = 422 loss = 0.6827859878540039
training: 0.5607903003692627 epoch = 12 step = 423 loss = 0.530659556388855
training: 0.7498135566711426 epoch = 12 step = 424 loss = 0.5261111259460449
training: 0.5017495155334473 epoch = 12 step = 425 loss = 0.7162894010543823
training: 0.5195820331573486 epoch = 12 step = 426 loss = 0.615188717842102
training: 0.5753283500671387 epoch = 12 step = 427 loss = 0.5485608577728271
training: 0.6156251430511475 epoch = 12 step = 428 loss = 0.7410832047462463
training: 0.42044568061828613 epoch = 12 step = 429 loss = 0.6096158027648926
training: 0.6467247009277344 epoch = 12 step = 430 loss = 0.4781770706176758
training: 0.7539927959442139 epoch = 12 step = 431 loss = 0.6559203863143921
training: 0.639296293258667 epoch = 12 step = 432 loss = 0.5706849098205566
training: 0.4097268581390381 epoch = 12 step = 433 loss = 0.5748528242111206
training: 0.47489380836486816 epoch = 12 step = 434 loss = 0.5226101875305176
training: 0.7101967334747314 epoch = 12 step = 435 loss = 0.5797990560531616
training: 0.6002328395843506 epoch = 12 step = 436 loss = 0.5453277826309204
training: 0.6094119548797607 epoch = 12 step = 437 loss = 0.6815071702003479
training: 0.6064102649688721 epoch = 12 step = 438 loss = 0.5626655220985413
training: 0.4982445240020752 epoch = 12 step = 439 loss = 0.605211079120636
training: 0.45813965797424316 epoch = 12 step = 440 loss = 0.5934239625930786
training: 0.5779762268066406 epoch = 12 step = 441 loss = 0.588668704032898
training: 0.7561624050140381 epoch = 12 step = 442 loss = 0.6030242443084717
training: 0.4708230495452881 epoch = 12 step = 443 loss = 0.5988842248916626
training: 0.5030555725097656 epoch = 12 step = 444 loss = 0.6079074740409851
training: 0.505375862121582 epoch = 12 step = 445 loss = 0.7033589482307434
training: 0.6832327842712402 epoch = 12 step = 446 loss = 0.5900263786315918
training: 0.5350284576416016 epoch = 12 step = 447 loss = 0.601577877998352
training: 0.6263628005981445 epoch = 12 step = 448 loss = 0.6598944664001465
training: 0.6496226787567139 epoch = 12 step = 449 loss = 0.8140649795532227
training: 0.44150590896606445 epoch = 12 step = 450 loss = 0.6616092324256897
training: 0.6386477947235107 epoch = 12 step = 451 loss = 0.7139195203781128
training: 0.4669325351715088 epoch = 13 step = 452 loss = 0.5061593055725098
training: 0.6315248012542725 epoch = 13 step = 453 loss = 0.589440643787384
training: 0.4887664318084717 epoch = 13 step = 454 loss = 0.48500603437423706
training: 0.5851154327392578 epoch = 13 step = 455 loss = 0.5857763290405273
training: 0.49326586723327637 epoch = 13 step = 456 loss = 0.5540072917938232
training: 0.7181789875030518 epoch = 13 step = 457 loss = 0.4926958680152893
training: 0.4424161911010742 epoch = 13 step = 458 loss = 0.4831269085407257
training: 0.5239529609680176 epoch = 13 step = 459 loss = 0.6255040764808655
training: 0.523634672164917 epoch = 13 step = 460 loss = 0.587267279624939
training: 0.5016539096832275 epoch = 13 step = 461 loss = 0.5860098600387573
training: 0.5687880516052246 epoch = 13 step = 462 loss = 0.5582951307296753
training: 0.5564174652099609 epoch = 13 step = 463 loss = 0.5822601318359375
training: 0.6842167377471924 epoch = 13 step = 464 loss = 0.6056112051010132
training: 0.45365166664123535 epoch = 13 step = 465 loss = 0.5755002498626709
training: 0.5578961372375488 epoch = 13 step = 466 loss = 0.5900077223777771
training: 0.4050874710083008 epoch = 13 step = 467 loss = 0.5759875774383545
training: 0.7031893730163574 epoch = 13 step = 468 loss = 0.5373772382736206
training: 0.5024557113647461 epoch = 13 step = 469 loss = 0.5969809293746948
training: 0.39474058151245117 epoch = 13 step = 470 loss = 0.5752801895141602
training: 0.6484954357147217 epoch = 13 step = 471 loss = 0.6010030508041382
training: 0.5786652565002441 epoch = 13 step = 472 loss = 0.44238030910491943
training: 0.430739164352417 epoch = 13 step = 473 loss = 0.592632532119751
training: 0.418748140335083 epoch = 13 step = 474 loss = 0.6587345600128174
training: 0.4481830596923828 epoch = 13 step = 475 loss = 0.48794323205947876
training: 0.533963680267334 epoch = 13 step = 476 loss = 0.5609509348869324
training: 0.5022556781768799 epoch = 13 step = 477 loss = 0.5731263160705566
training: 0.532766580581665 epoch = 13 step = 478 loss = 0.5558693408966064
training: 0.4913144111633301 epoch = 13 step = 479 loss = 0.4849531054496765
training: 0.5682175159454346 epoch = 13 step = 480 loss = 0.632477879524231
training: 0.45409202575683594 epoch = 13 step = 481 loss = 0.5639868974685669
training: 0.5383439064025879 epoch = 13 step = 482 loss = 0.45452117919921875
training: 0.5027074813842773 epoch = 13 step = 483 loss = 0.5047453045845032
training: 0.4644331932067871 epoch = 13 step = 484 loss = 0.6562561392784119
training: 0.6070849895477295 epoch = 14 step = 485 loss = 0.45254841446876526
training: 0.4814879894256592 epoch = 14 step = 486 loss = 0.6263359189033508
training: 0.496309757232666 epoch = 14 step = 487 loss = 0.590060830116272
training: 0.5580081939697266 epoch = 14 step = 488 loss = 0.5349726676940918
training: 0.5816466808319092 epoch = 14 step = 489 loss = 0.5210368633270264
training: 0.47400832176208496 epoch = 14 step = 490 loss = 0.5034828186035156
training: 0.6046223640441895 epoch = 14 step = 491 loss = 0.45707789063453674
training: 0.7219908237457275 epoch = 14 step = 492 loss = 0.4429970383644104
training: 0.5814542770385742 epoch = 14 step = 493 loss = 0.5427582859992981
training: 0.5615813732147217 epoch = 14 step = 494 loss = 0.4790201783180237
training: 0.5098786354064941 epoch = 14 step = 495 loss = 0.49163854122161865
training: 0.7021727561950684 epoch = 14 step = 496 loss = 0.5706675052642822
training: 0.5326447486877441 epoch = 14 step = 497 loss = 0.538840115070343
training: 0.45293617248535156 epoch = 14 step = 498 loss = 0.4905042052268982
training: 0.8335998058319092 epoch = 14 step = 499 loss = 0.5541446208953857
training: 0.5360884666442871 epoch = 14 step = 500 loss = 0.5203317403793335

Devolope:
Devoloped = 0.47026968002319336, epoch = 14 step = 501 loss = 1.3526287078857422
Devoloped = 0.5197455883026123, epoch = 14 step = 502 loss = 1.1070019006729126
Devoloped = 0.8093166351318359, epoch = 14 step = 503 loss = 1.167238473892212
Devoloped = 0.5565965175628662, epoch = 14 step = 504 loss = 0.9865250587463379
Devoloped = 0.4675123691558838, epoch = 14 step = 505 loss = 1.1232163906097412
Devoloped = 0.6650917530059814, epoch = 14 step = 506 loss = 1.1656206846237183
Devoloped = 0.5808310508728027, epoch = 14 step = 507 loss = 1.2238987684249878
Devoloped = 0.4999825954437256, epoch = 14 step = 508 loss = 0.842873215675354

Evaluate:
[0 0 5 ... 0 0 0]
[0 0 0 ... 0 0 0]
Testing 1.8744020462036133 step = 508
 precision= 0.7400611620795107 recall= 0.7400611620795107 f1_score= 0.7400611620795108
508 0.7400611620795107 0.7400611620795107 0.7400611620795108

training: 0.5136981010437012 epoch = 14 step = 509 loss = 0.5960016250610352
training: 0.5587210655212402 epoch = 14 step = 510 loss = 0.4974626302719116
training: 0.5129079818725586 epoch = 14 step = 511 loss = 0.5007025003433228
training: 0.4733438491821289 epoch = 14 step = 512 loss = 0.5553600788116455
training: 0.6004760265350342 epoch = 14 step = 513 loss = 0.5409247279167175
training: 0.4168527126312256 epoch = 14 step = 514 loss = 0.5210961103439331
training: 0.615506649017334 epoch = 14 step = 515 loss = 0.4924931526184082
training: 0.5719988346099854 epoch = 14 step = 516 loss = 0.5015717148780823
training: 0.5003843307495117 epoch = 14 step = 517 loss = 0.6086212396621704
training: 0.6833810806274414 epoch = 14 step = 518 loss = 0.5482232570648193
training: 0.5595746040344238 epoch = 14 step = 519 loss = 0.472622811794281
training: 0.5225677490234375 epoch = 14 step = 520 loss = 0.5378398299217224
training: 0.5608816146850586 epoch = 14 step = 521 loss = 0.48930758237838745
training: 0.649101734161377 epoch = 14 step = 522 loss = 0.5433798432350159
training: 0.41904354095458984 epoch = 14 step = 523 loss = 0.45658770203590393
training: 0.5873441696166992 epoch = 14 step = 524 loss = 0.5189389586448669
training: 0.4559967517852783 epoch = 14 step = 525 loss = 0.4514164328575134
training: 0.6571993827819824 epoch = 15 step = 526 loss = 0.43501994013786316
training: 0.5364062786102295 epoch = 15 step = 527 loss = 0.5182737112045288
training: 0.4714970588684082 epoch = 15 step = 528 loss = 0.49422258138656616
training: 0.45076990127563477 epoch = 15 step = 529 loss = 0.4074932038784027
training: 0.8036606311798096 epoch = 15 step = 530 loss = 0.5300934910774231
training: 0.411313533782959 epoch = 15 step = 531 loss = 0.5358874797821045
training: 0.5675013065338135 epoch = 15 step = 532 loss = 0.39833858609199524
training: 0.5410497188568115 epoch = 15 step = 533 loss = 0.41091954708099365
training: 0.4656810760498047 epoch = 15 step = 534 loss = 0.5517370104789734
training: 0.4723935127258301 epoch = 15 step = 535 loss = 0.536149263381958
training: 0.5771400928497314 epoch = 15 step = 536 loss = 0.6033413410186768
training: 0.4844684600830078 epoch = 15 step = 537 loss = 0.4610014855861664
training: 0.5477659702301025 epoch = 15 step = 538 loss = 0.5215964317321777
training: 0.48665809631347656 epoch = 15 step = 539 loss = 0.42427024245262146
training: 0.45110034942626953 epoch = 15 step = 540 loss = 0.5104615688323975
training: 0.4570012092590332 epoch = 15 step = 541 loss = 0.4166431725025177
training: 0.7123937606811523 epoch = 15 step = 542 loss = 0.5714249610900879
training: 0.5419082641601562 epoch = 15 step = 543 loss = 0.4664207994937897
training: 0.5235874652862549 epoch = 15 step = 544 loss = 0.5068493485450745
training: 0.7193512916564941 epoch = 15 step = 545 loss = 0.4596591293811798
training: 0.623816967010498 epoch = 15 step = 546 loss = 0.4602024555206299
training: 0.579646110534668 epoch = 15 step = 547 loss = 0.4651426672935486
training: 0.38857460021972656 epoch = 15 step = 548 loss = 0.43155235052108765
training: 0.7867922782897949 epoch = 15 step = 549 loss = 0.5206250548362732
training: 0.4162709712982178 epoch = 15 step = 550 loss = 0.4877511262893677
training: 0.41468358039855957 epoch = 15 step = 551 loss = 0.4816995859146118
training: 0.5559968948364258 epoch = 15 step = 552 loss = 0.5982040166854858
training: 0.7092711925506592 epoch = 15 step = 553 loss = 0.5604317784309387
training: 0.5038022994995117 epoch = 15 step = 554 loss = 0.4846816658973694
training: 0.4931325912475586 epoch = 15 step = 555 loss = 0.5043728351593018
training: 0.6953837871551514 epoch = 15 step = 556 loss = 0.41432255506515503
training: 0.5424129962921143 epoch = 15 step = 557 loss = 0.519609808921814
training: 0.50128173828125 epoch = 16 step = 558 loss = 0.4127518832683563
training: 0.5632460117340088 epoch = 16 step = 559 loss = 0.4488504230976105
training: 0.7109649181365967 epoch = 16 step = 560 loss = 0.4342826008796692
training: 0.48600196838378906 epoch = 16 step = 561 loss = 0.47828882932662964
training: 0.4220998287200928 epoch = 16 step = 562 loss = 0.4375080466270447
training: 0.5347096920013428 epoch = 16 step = 563 loss = 0.42263659834861755
training: 0.7286319732666016 epoch = 16 step = 564 loss = 0.5118904113769531
training: 0.457028865814209 epoch = 16 step = 565 loss = 0.3919978141784668
training: 0.552638053894043 epoch = 16 step = 566 loss = 0.486679345369339
training: 0.5668830871582031 epoch = 16 step = 567 loss = 0.5869840979576111
training: 0.6080212593078613 epoch = 16 step = 568 loss = 0.5229925513267517
training: 0.6433875560760498 epoch = 16 step = 569 loss = 0.42974910140037537
training: 0.41007113456726074 epoch = 16 step = 570 loss = 0.4018368124961853
training: 0.7366702556610107 epoch = 16 step = 571 loss = 0.4102356731891632
training: 0.6980903148651123 epoch = 16 step = 572 loss = 0.43500638008117676
training: 0.5211973190307617 epoch = 16 step = 573 loss = 0.41882508993148804
training: 0.44176435470581055 epoch = 16 step = 574 loss = 0.46445637941360474
training: 0.7082624435424805 epoch = 16 step = 575 loss = 0.4669419825077057
training: 0.48471617698669434 epoch = 16 step = 576 loss = 0.4261382222175598
training: 0.627570390701294 epoch = 16 step = 577 loss = 0.4047703146934509
training: 0.7069830894470215 epoch = 16 step = 578 loss = 0.46479466557502747
training: 0.5102250576019287 epoch = 16 step = 579 loss = 0.4243497848510742
training: 0.601140022277832 epoch = 16 step = 580 loss = 0.44052308797836304
training: 0.5765020847320557 epoch = 16 step = 581 loss = 0.4472137689590454
training: 0.5949904918670654 epoch = 16 step = 582 loss = 0.39933767914772034
training: 0.5148203372955322 epoch = 16 step = 583 loss = 0.38970404863357544
training: 0.4428689479827881 epoch = 16 step = 584 loss = 0.44963687658309937
training: 0.5794806480407715 epoch = 16 step = 585 loss = 0.4044108986854553
training: 0.5291092395782471 epoch = 16 step = 586 loss = 0.45407935976982117
training: 0.4890778064727783 epoch = 16 step = 587 loss = 0.4105706810951233
training: 0.5223186016082764 epoch = 16 step = 588 loss = 0.4732057452201843
training: 0.3915133476257324 epoch = 16 step = 589 loss = 0.4548146426677704
training: 0.712637186050415 epoch = 17 step = 590 loss = 0.4303840398788452
training: 0.4836280345916748 epoch = 17 step = 591 loss = 0.529125452041626
training: 0.515688419342041 epoch = 17 step = 592 loss = 0.403922438621521
training: 0.4555034637451172 epoch = 17 step = 593 loss = 0.41443127393722534
training: 0.6050126552581787 epoch = 17 step = 594 loss = 0.3875482976436615
training: 0.6052134037017822 epoch = 17 step = 595 loss = 0.3964328467845917
training: 0.5313482284545898 epoch = 17 step = 596 loss = 0.48001039028167725
training: 0.7257318496704102 epoch = 17 step = 597 loss = 0.4412083327770233
training: 0.5664823055267334 epoch = 17 step = 598 loss = 0.4239465594291687
training: 0.5628552436828613 epoch = 17 step = 599 loss = 0.4004029333591461
training: 0.6382882595062256 epoch = 17 step = 600 loss = 0.552280068397522

Devolope:
Devoloped = 0.4954357147216797, epoch = 17 step = 601 loss = 0.9763891696929932
Devoloped = 0.4401130676269531, epoch = 17 step = 602 loss = 0.6962392330169678
Devoloped = 0.59352707862854, epoch = 17 step = 603 loss = 0.9037783145904541
Devoloped = 0.44248151779174805, epoch = 17 step = 604 loss = 0.9709486961364746
Devoloped = 0.632286548614502, epoch = 17 step = 605 loss = 0.8455217480659485
Devoloped = 0.40990781784057617, epoch = 17 step = 606 loss = 0.8309707641601562
Devoloped = 0.6033868789672852, epoch = 17 step = 607 loss = 0.6972253918647766

Evaluate:
[ 0  0 13 ...  0 33  0]
[0 0 0 ... 0 0 0]
Testing 1.8608050346374512 step = 607
 precision= 0.7536697247706422 recall= 0.7536697247706422 f1_score= 0.7536697247706422
607 0.7536697247706422 0.7536697247706422 0.7536697247706422

training: 0.5583548545837402 epoch = 17 step = 608 loss = 0.42772960662841797
training: 0.7137081623077393 epoch = 17 step = 609 loss = 0.4244757294654846
training: 0.5072386264801025 epoch = 17 step = 610 loss = 0.4787737727165222
training: 0.5513770580291748 epoch = 17 step = 611 loss = 0.5368432402610779
training: 0.7180149555206299 epoch = 17 step = 612 loss = 0.42852669954299927
training: 0.6383669376373291 epoch = 17 step = 613 loss = 0.4651437997817993
training: 0.5859668254852295 epoch = 17 step = 614 loss = 0.45106902718544006
training: 0.48737597465515137 epoch = 17 step = 615 loss = 0.4564436078071594
training: 0.6683249473571777 epoch = 17 step = 616 loss = 0.4593317210674286
training: 0.4472179412841797 epoch = 17 step = 617 loss = 0.43745851516723633
training: 0.4997885227203369 epoch = 17 step = 618 loss = 0.39610621333122253
training: 0.49321722984313965 epoch = 17 step = 619 loss = 0.483583927154541
training: 0.7940723896026611 epoch = 17 step = 620 loss = 0.43487706780433655
training: 0.49086761474609375 epoch = 17 step = 621 loss = 0.42967313528060913
training: 0.43804168701171875 epoch = 17 step = 622 loss = 0.4323207139968872
training: 0.6455893516540527 epoch = 17 step = 623 loss = 0.5277246236801147
training: 0.523219108581543 epoch = 17 step = 624 loss = 0.4065566658973694
training: 0.4907689094543457 epoch = 17 step = 625 loss = 0.48894003033638
training: 0.5080389976501465 epoch = 17 step = 626 loss = 0.4569075107574463
training: 0.5503408908843994 epoch = 17 step = 627 loss = 0.3645550012588501
training: 0.5764622688293457 epoch = 17 step = 628 loss = 0.46725475788116455
training: 0.613793134689331 epoch = 18 step = 629 loss = 0.4352255165576935
training: 0.4740722179412842 epoch = 18 step = 630 loss = 0.42977309226989746
training: 0.6245846748352051 epoch = 18 step = 631 loss = 0.49157509207725525
training: 0.47815895080566406 epoch = 18 step = 632 loss = 0.3870897591114044
training: 0.37001776695251465 epoch = 18 step = 633 loss = 0.39162665605545044
training: 0.5475928783416748 epoch = 18 step = 634 loss = 0.37772005796432495
training: 0.629204511642456 epoch = 18 step = 635 loss = 0.40272918343544006
training: 0.570972204208374 epoch = 18 step = 636 loss = 0.4532069265842438
training: 0.5003392696380615 epoch = 18 step = 637 loss = 0.4220561981201172
training: 0.576880693435669 epoch = 18 step = 638 loss = 0.4117399752140045
training: 0.7581465244293213 epoch = 18 step = 639 loss = 0.3993046283721924
training: 0.40838050842285156 epoch = 18 step = 640 loss = 0.4214699864387512
training: 0.5250916481018066 epoch = 18 step = 641 loss = 0.39576399326324463
training: 0.4388890266418457 epoch = 18 step = 642 loss = 0.43782222270965576
training: 0.681732177734375 epoch = 18 step = 643 loss = 0.47991394996643066
training: 0.46427178382873535 epoch = 18 step = 644 loss = 0.41203218698501587
training: 0.49333715438842773 epoch = 18 step = 645 loss = 0.43700525164604187
training: 0.7893309593200684 epoch = 18 step = 646 loss = 0.5041478872299194
training: 0.47594666481018066 epoch = 18 step = 647 loss = 0.5304455757141113
training: 0.5131916999816895 epoch = 18 step = 648 loss = 0.4204813539981842
training: 0.5455124378204346 epoch = 18 step = 649 loss = 0.4553980827331543
training: 0.6047601699829102 epoch = 18 step = 650 loss = 0.38382208347320557
training: 0.5349361896514893 epoch = 18 step = 651 loss = 0.38049453496932983
training: 0.6417732238769531 epoch = 18 step = 652 loss = 0.4220837354660034
training: 0.48978233337402344 epoch = 18 step = 653 loss = 0.40552327036857605
training: 0.6863408088684082 epoch = 18 step = 654 loss = 0.4234079122543335
training: 0.6023569107055664 epoch = 18 step = 655 loss = 0.48710745573043823
training: 0.5618796348571777 epoch = 18 step = 656 loss = 0.4794943332672119
training: 0.6687057018280029 epoch = 18 step = 657 loss = 0.4190753102302551
training: 0.5183682441711426 epoch = 18 step = 658 loss = 0.39494091272354126
training: 0.4536318778991699 epoch = 18 step = 659 loss = 0.4332236051559448
training: 0.5612316131591797 epoch = 18 step = 660 loss = 0.46185779571533203
training: 0.6488869190216064 epoch = 19 step = 661 loss = 0.37967753410339355
training: 0.5318148136138916 epoch = 19 step = 662 loss = 0.4225854277610779
training: 0.4900672435760498 epoch = 19 step = 663 loss = 0.3666819930076599
training: 0.5519788265228271 epoch = 19 step = 664 loss = 0.3896876871585846
training: 0.6383373737335205 epoch = 19 step = 665 loss = 0.3800927400588989
training: 0.5117959976196289 epoch = 19 step = 666 loss = 0.38407307863235474
training: 0.5338308811187744 epoch = 19 step = 667 loss = 0.37987932562828064
training: 0.5259957313537598 epoch = 19 step = 668 loss = 0.36658725142478943
training: 0.6269931793212891 epoch = 19 step = 669 loss = 0.3981618881225586
training: 0.44556379318237305 epoch = 19 step = 670 loss = 0.4539359211921692
training: 0.5202693939208984 epoch = 19 step = 671 loss = 0.3812720477581024
training: 0.6946353912353516 epoch = 19 step = 672 loss = 0.4128970801830292
training: 0.48029541969299316 epoch = 19 step = 673 loss = 0.3757972717285156
training: 0.4585380554199219 epoch = 19 step = 674 loss = 0.38413915038108826
training: 0.5909702777862549 epoch = 19 step = 675 loss = 0.4101482331752777
training: 0.6044771671295166 epoch = 19 step = 676 loss = 0.3902341425418854
training: 0.46402931213378906 epoch = 19 step = 677 loss = 0.38039639592170715
training: 0.5572144985198975 epoch = 19 step = 678 loss = 0.39441946148872375
training: 0.5513911247253418 epoch = 19 step = 679 loss = 0.4042605459690094
training: 0.7588901519775391 epoch = 19 step = 680 loss = 0.36952683329582214
training: 0.455380916595459 epoch = 19 step = 681 loss = 0.39363402128219604
training: 0.48293590545654297 epoch = 19 step = 682 loss = 0.3839721381664276
training: 0.5289449691772461 epoch = 19 step = 683 loss = 0.376340389251709
training: 0.6027169227600098 epoch = 19 step = 684 loss = 0.385783851146698
training: 0.4817969799041748 epoch = 19 step = 685 loss = 0.40466150641441345
training: 0.5164778232574463 epoch = 19 step = 686 loss = 0.3787475824356079
training: 0.5365030765533447 epoch = 19 step = 687 loss = 0.3732813596725464
training: 0.6484425067901611 epoch = 19 step = 688 loss = 0.4258981943130493
training: 0.5067253112792969 epoch = 19 step = 689 loss = 0.36868274211883545
training: 0.5581197738647461 epoch = 19 step = 690 loss = 0.40430569648742676
training: 0.6563823223114014 epoch = 19 step = 691 loss = 0.36972576379776
training: 0.5271604061126709 epoch = 19 step = 692 loss = 0.41556864976882935
training: 0.37818241119384766 epoch = 19 step = 693 loss = 0.32970187067985535
training: 0.5281450748443604 epoch = 20 step = 694 loss = 0.36584585905075073
training: 0.7501211166381836 epoch = 20 step = 695 loss = 0.41691678762435913
training: 0.42368555068969727 epoch = 20 step = 696 loss = 0.41790175437927246
training: 0.5686795711517334 epoch = 20 step = 697 loss = 0.351078063249588
training: 0.5819506645202637 epoch = 20 step = 698 loss = 0.3639930784702301
training: 0.7576267719268799 epoch = 20 step = 699 loss = 0.44564276933670044
training: 0.491793155670166 epoch = 20 step = 700 loss = 0.4021478295326233

Devolope:
Devoloped = 0.6817722320556641, epoch = 20 step = 701 loss = 0.6043156385421753
Devoloped = 0.9142169952392578, epoch = 20 step = 702 loss = 0.6885273456573486
Devoloped = 0.5321836471557617, epoch = 20 step = 703 loss = 0.6798059940338135
Devoloped = 0.5378963947296143, epoch = 20 step = 704 loss = 0.7374448776245117
Devoloped = 0.7444052696228027, epoch = 20 step = 705 loss = 0.7552630305290222
Devoloped = 0.4761676788330078, epoch = 20 step = 706 loss = 0.6714264154434204
Devoloped = 0.5802240371704102, epoch = 20 step = 707 loss = 0.6532551050186157

Evaluate:
[0 0 0 ... 0 0 0]
[0 0 0 ... 0 0 0]
Testing 2.04475474357605 step = 707
 precision= 0.8585626911314985 recall= 0.8585626911314985 f1_score= 0.8585626911314985
707 0.8585626911314985 0.8585626911314985 0.8585626911314985

training: 0.5779154300689697 epoch = 20 step = 708 loss = 0.3800472617149353
training: 0.6233251094818115 epoch = 20 step = 709 loss = 0.42571383714675903
training: 0.5674924850463867 epoch = 20 step = 710 loss = 0.4598098695278168
training: 0.47721290588378906 epoch = 20 step = 711 loss = 0.37909552454948425
training: 0.519477367401123 epoch = 20 step = 712 loss = 0.4138319492340088
training: 0.7373497486114502 epoch = 20 step = 713 loss = 0.43778884410858154
training: 0.45200014114379883 epoch = 20 step = 714 loss = 0.3982500433921814
training: 0.4209873676300049 epoch = 20 step = 715 loss = 0.35623490810394287
training: 0.4408280849456787 epoch = 20 step = 716 loss = 0.34824860095977783
training: 0.6311407089233398 epoch = 20 step = 717 loss = 0.4041427969932556
training: 0.5071568489074707 epoch = 20 step = 718 loss = 0.35074588656425476
training: 0.538090705871582 epoch = 20 step = 719 loss = 0.3749673366546631
training: 0.4544506072998047 epoch = 20 step = 720 loss = 0.3986112177371979
training: 0.5936813354492188 epoch = 20 step = 721 loss = 0.4296725392341614
training: 0.5373482704162598 epoch = 20 step = 722 loss = 0.35348212718963623
training: 0.6009490489959717 epoch = 20 step = 723 loss = 0.39678800106048584
training: 0.7144443988800049 epoch = 20 step = 724 loss = 0.3825051784515381
training: 0.4551360607147217 epoch = 20 step = 725 loss = 0.3447251319885254
training: 0.5721840858459473 epoch = 20 step = 726 loss = 0.4152561128139496
training: 0.47440505027770996 epoch = 20 step = 727 loss = 0.4124506115913391
training: 0.6674087047576904 epoch = 20 step = 728 loss = 0.38873177766799927
training: 0.4930460453033447 epoch = 20 step = 729 loss = 0.45962458848953247
training: 0.46423888206481934 epoch = 20 step = 730 loss = 0.3896366357803345
training: 0.48011136054992676 epoch = 20 step = 731 loss = 0.34719717502593994
training: 0.7237842082977295 epoch = 20 step = 732 loss = 0.3888910710811615
training: 0.4871211051940918 epoch = 21 step = 733 loss = 0.3982490599155426
training: 0.5612361431121826 epoch = 21 step = 734 loss = 0.4000186026096344
training: 0.47492122650146484 epoch = 21 step = 735 loss = 0.42740145325660706
training: 0.5776872634887695 epoch = 21 step = 736 loss = 0.44547468423843384
training: 0.6754381656646729 epoch = 21 step = 737 loss = 0.42081552743911743
training: 0.5378224849700928 epoch = 21 step = 738 loss = 0.38492584228515625
training: 0.633866548538208 epoch = 21 step = 739 loss = 0.37423399090766907
training: 0.5455417633056641 epoch = 21 step = 740 loss = 0.33315134048461914
training: 0.5709691047668457 epoch = 21 step = 741 loss = 0.35788920521736145
training: 0.5834236145019531 epoch = 21 step = 742 loss = 0.3568859100341797
training: 0.6198821067810059 epoch = 21 step = 743 loss = 0.336324006319046
training: 0.6659431457519531 epoch = 21 step = 744 loss = 0.38324907422065735
training: 0.41118621826171875 epoch = 21 step = 745 loss = 0.3895062208175659
training: 0.46609926223754883 epoch = 21 step = 746 loss = 0.3643910586833954
training: 0.5680935382843018 epoch = 21 step = 747 loss = 0.36619675159454346
training: 0.5192034244537354 epoch = 21 step = 748 loss = 0.3527339994907379
training: 0.5771067142486572 epoch = 21 step = 749 loss = 0.3645479381084442
training: 0.7763891220092773 epoch = 21 step = 750 loss = 0.3750443756580353
training: 0.5115814208984375 epoch = 21 step = 751 loss = 0.3483765423297882
training: 0.5595760345458984 epoch = 21 step = 752 loss = 0.41457247734069824
training: 0.6217062473297119 epoch = 21 step = 753 loss = 0.3441337049007416
training: 0.6665816307067871 epoch = 21 step = 754 loss = 0.35803577303886414
training: 0.4732205867767334 epoch = 21 step = 755 loss = 0.43909117579460144
training: 0.4980032444000244 epoch = 21 step = 756 loss = 0.34057483077049255
training: 0.4983088970184326 epoch = 21 step = 757 loss = 0.3305622637271881
training: 0.541780948638916 epoch = 21 step = 758 loss = 0.35010552406311035
training: 0.5519309043884277 epoch = 21 step = 759 loss = 0.4173080325126648
training: 0.4453432559967041 epoch = 21 step = 760 loss = 0.34689605236053467
training: 0.523578405380249 epoch = 21 step = 761 loss = 0.3684123754501343
training: 0.6095108985900879 epoch = 21 step = 762 loss = 0.3545744717121124
training: 0.46920323371887207 epoch = 21 step = 763 loss = 0.35908055305480957
training: 0.45244312286376953 epoch = 21 step = 764 loss = 0.36333534121513367
training: 0.5027673244476318 epoch = 22 step = 765 loss = 0.4005201756954193
training: 0.6306016445159912 epoch = 22 step = 766 loss = 0.3442133367061615
training: 0.47278666496276855 epoch = 22 step = 767 loss = 0.3258731961250305
training: 0.5368320941925049 epoch = 22 step = 768 loss = 0.3963789939880371
training: 0.5402531623840332 epoch = 22 step = 769 loss = 0.35690629482269287
training: 0.4945034980773926 epoch = 22 step = 770 loss = 0.3751712739467621
training: 0.5295698642730713 epoch = 22 step = 771 loss = 0.38689935207366943
training: 0.4809093475341797 epoch = 22 step = 772 loss = 0.44477707147598267
training: 0.47541260719299316 epoch = 22 step = 773 loss = 0.41853830218315125
training: 0.6190712451934814 epoch = 22 step = 774 loss = 0.3528035879135132
training: 0.48123979568481445 epoch = 22 step = 775 loss = 0.3494551181793213
training: 0.43700671195983887 epoch = 22 step = 776 loss = 0.3491339683532715
training: 0.47200942039489746 epoch = 22 step = 777 loss = 0.5071429014205933
training: 0.6608293056488037 epoch = 22 step = 778 loss = 0.377219021320343
training: 0.4692506790161133 epoch = 22 step = 779 loss = 0.3744235038757324
training: 0.4925508499145508 epoch = 22 step = 780 loss = 0.3489595651626587
training: 0.5289077758789062 epoch = 22 step = 781 loss = 0.3651500940322876
training: 0.6185219287872314 epoch = 22 step = 782 loss = 0.4100184440612793
training: 0.48084568977355957 epoch = 22 step = 783 loss = 0.4012324810028076
training: 0.5751738548278809 epoch = 22 step = 784 loss = 0.33007189631462097
training: 0.45278215408325195 epoch = 22 step = 785 loss = 0.3308517634868622
training: 0.5894317626953125 epoch = 22 step = 786 loss = 0.37945035099983215
training: 0.5149579048156738 epoch = 22 step = 787 loss = 0.4774220585823059
training: 0.46231818199157715 epoch = 22 step = 788 loss = 0.39878514409065247
training: 0.547283411026001 epoch = 22 step = 789 loss = 0.3361203074455261
training: 0.5194973945617676 epoch = 22 step = 790 loss = 0.3641347289085388
training: 0.45927882194519043 epoch = 22 step = 791 loss = 0.36511069536209106
training: 0.492171049118042 epoch = 22 step = 792 loss = 0.3815522789955139
training: 0.48329854011535645 epoch = 22 step = 793 loss = 0.3681962192058563
training: 0.6763293743133545 epoch = 22 step = 794 loss = 0.3292568325996399
training: 0.5401427745819092 epoch = 22 step = 795 loss = 0.38107994198799133
training: 0.50634765625 epoch = 22 step = 796 loss = 0.36592984199523926
training: 0.532616376876831 epoch = 22 step = 797 loss = 0.330109566450119
training: 0.49457502365112305 epoch = 23 step = 798 loss = 0.3447093963623047
training: 0.5224523544311523 epoch = 23 step = 799 loss = 0.34575188159942627
training: 0.5011861324310303 epoch = 23 step = 800 loss = 0.38056644797325134

Devolope:
Devoloped = 0.5013105869293213, epoch = 23 step = 801 loss = 0.6781316995620728
Devoloped = 0.5859992504119873, epoch = 23 step = 802 loss = 0.5810824632644653
Devoloped = 0.6788845062255859, epoch = 23 step = 803 loss = 0.6580498218536377
Devoloped = 0.547856330871582, epoch = 23 step = 804 loss = 0.4953410029411316
Devoloped = 0.718609094619751, epoch = 23 step = 805 loss = 0.5915747880935669
Devoloped = 0.6292285919189453, epoch = 23 step = 806 loss = 0.4814356863498688
Devoloped = 0.4342162609100342, epoch = 23 step = 807 loss = 0.5568093061447144
Devoloped = 0.5372543334960938, epoch = 23 step = 808 loss = 0.5881354808807373

Evaluate:
[0 0 0 ... 0 0 0]
[0 0 0 ... 0 0 0]
Testing 1.9076268672943115 step = 808
 precision= 0.8784403669724771 recall= 0.8784403669724771 f1_score= 0.8784403669724771
808 0.8784403669724771 0.8784403669724771 0.8784403669724771

training: 0.684368371963501 epoch = 23 step = 809 loss = 0.38758260011672974
training: 0.5200128555297852 epoch = 23 step = 810 loss = 0.4078587591648102
training: 0.5319428443908691 epoch = 23 step = 811 loss = 0.3568565547466278
training: 0.5095059871673584 epoch = 23 step = 812 loss = 0.3289642632007599
training: 0.6706509590148926 epoch = 23 step = 813 loss = 0.33460044860839844
training: 0.48590946197509766 epoch = 23 step = 814 loss = 0.37637829780578613
training: 0.5726850032806396 epoch = 23 step = 815 loss = 0.38485926389694214
training: 0.4704279899597168 epoch = 23 step = 816 loss = 0.37897905707359314
training: 0.554163932800293 epoch = 23 step = 817 loss = 0.37308788299560547
training: 0.4670376777648926 epoch = 23 step = 818 loss = 0.3114202320575714
training: 0.466416597366333 epoch = 23 step = 819 loss = 0.35995495319366455
training: 0.48539185523986816 epoch = 23 step = 820 loss = 0.3463558554649353
training: 0.600757360458374 epoch = 23 step = 821 loss = 0.41301918029785156
training: 0.5287442207336426 epoch = 23 step = 822 loss = 0.4367522597312927
training: 0.5637590885162354 epoch = 23 step = 823 loss = 0.3550814986228943
training: 0.7285568714141846 epoch = 23 step = 824 loss = 0.36623525619506836
training: 0.5164430141448975 epoch = 23 step = 825 loss = 0.3982192873954773
training: 0.5436968803405762 epoch = 23 step = 826 loss = 0.40084564685821533
training: 0.4260141849517822 epoch = 23 step = 827 loss = 0.44405239820480347
training: 0.5955653190612793 epoch = 23 step = 828 loss = 0.3333468735218048
training: 0.4562060832977295 epoch = 23 step = 829 loss = 0.36323457956314087
training: 0.4250600337982178 epoch = 23 step = 830 loss = 0.32978981733322144
training: 0.4857006072998047 epoch = 23 step = 831 loss = 0.3442092537879944
training: 0.3642311096191406 epoch = 23 step = 832 loss = 0.3357527256011963
training: 0.6353878974914551 epoch = 23 step = 833 loss = 0.3757670521736145
training: 0.6148667335510254 epoch = 23 step = 834 loss = 0.3500533401966095
training: 0.4934830665588379 epoch = 23 step = 835 loss = 0.34383702278137207
training: 0.6184592247009277 epoch = 23 step = 836 loss = 0.33613321185112
training: 0.46401453018188477 epoch = 23 step = 837 loss = 0.3475099802017212
training: 0.4709954261779785 epoch = 24 step = 838 loss = 0.3478701412677765
training: 0.6664290428161621 epoch = 24 step = 839 loss = 0.3387503921985626
training: 0.6333436965942383 epoch = 24 step = 840 loss = 0.3315817415714264
training: 0.43825268745422363 epoch = 24 step = 841 loss = 0.42204540967941284
training: 0.4839291572570801 epoch = 24 step = 842 loss = 0.33253052830696106
training: 0.5537817478179932 epoch = 24 step = 843 loss = 0.3761051297187805
training: 0.6281466484069824 epoch = 24 step = 844 loss = 0.44717901945114136
training: 0.629610538482666 epoch = 24 step = 845 loss = 0.33314386010169983
training: 0.6268587112426758 epoch = 24 step = 846 loss = 0.34464719891548157
training: 0.6358730792999268 epoch = 24 step = 847 loss = 0.3925475478172302
training: 0.5226070880889893 epoch = 24 step = 848 loss = 0.34891313314437866
training: 0.4978625774383545 epoch = 24 step = 849 loss = 0.36354008316993713
training: 0.46254658699035645 epoch = 24 step = 850 loss = 0.3306509852409363
training: 0.7020819187164307 epoch = 24 step = 851 loss = 0.3485748767852783
training: 0.6761519908905029 epoch = 24 step = 852 loss = 0.33597245812416077
training: 0.4871060848236084 epoch = 24 step = 853 loss = 0.37268632650375366
training: 0.45194244384765625 epoch = 24 step = 854 loss = 0.3455828130245209
training: 0.6713104248046875 epoch = 24 step = 855 loss = 0.31270989775657654
training: 0.5317914485931396 epoch = 24 step = 856 loss = 0.33393487334251404
training: 0.5432589054107666 epoch = 24 step = 857 loss = 0.33785271644592285
training: 0.4500243663787842 epoch = 24 step = 858 loss = 0.4801803529262543
training: 0.5589711666107178 epoch = 24 step = 859 loss = 0.3479357361793518
training: 0.4667990207672119 epoch = 24 step = 860 loss = 0.3387109637260437
training: 0.5431857109069824 epoch = 24 step = 861 loss = 0.38199421763420105
training: 0.5964221954345703 epoch = 24 step = 862 loss = 0.3148825168609619
training: 0.6305246353149414 epoch = 24 step = 863 loss = 0.36242055892944336
training: 0.40273189544677734 epoch = 24 step = 864 loss = 0.37818241119384766
training: 0.5149343013763428 epoch = 24 step = 865 loss = 0.3945291340351105
training: 0.5382685661315918 epoch = 24 step = 866 loss = 0.3590187430381775
training: 0.4725956916809082 epoch = 24 step = 867 loss = 0.3220415711402893
training: 0.5261120796203613 epoch = 24 step = 868 loss = 0.3589150011539459
training: 0.5530109405517578 epoch = 24 step = 869 loss = 0.3341972827911377
Evaluate:
Training:
[0 0 0 ... 0 0 0]
[0 0 0 ... 0 0 0]
Testing 1.9498145580291748 step = 869
 precision= 0.8608562691131498 recall= 0.8608562691131498 f1_score= 0.8608562691131498
869 0.8608562691131498 0.8608562691131498 0.8608562691131498

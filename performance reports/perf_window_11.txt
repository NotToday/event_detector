Sents length :  43592  Anchor length :  43592  Vocab length :  8777
dimension: 300, train_size: 30514, test_size: 6538, length: 11
anchor dimension  (30514,)
Writing to /home/soumyadeep/EventDetection/runs/1523704716

training: 1.1803288459777832 epoch = 0 step = 1 loss = 3.7160568237304688
training: 0.5986390113830566 epoch = 0 step = 2 loss = 3.6641926765441895
training: 0.5128881931304932 epoch = 0 step = 3 loss = 3.544804811477661
training: 0.6628191471099854 epoch = 0 step = 4 loss = 3.4504153728485107
training: 0.4461512565612793 epoch = 0 step = 5 loss = 3.4225966930389404
training: 0.5072464942932129 epoch = 0 step = 6 loss = 3.3075368404388428
training: 0.45201563835144043 epoch = 0 step = 7 loss = 3.327566623687744
training: 0.6438605785369873 epoch = 0 step = 8 loss = 3.2589075565338135
training: 0.5718178749084473 epoch = 0 step = 9 loss = 3.109187126159668
training: 0.5038948059082031 epoch = 0 step = 10 loss = 3.047811269760132
training: 0.6186730861663818 epoch = 0 step = 11 loss = 3.0258288383483887
training: 0.6951093673706055 epoch = 0 step = 12 loss = 3.0361862182617188
training: 0.6354074478149414 epoch = 0 step = 13 loss = 3.112971305847168
training: 0.4616551399230957 epoch = 0 step = 14 loss = 2.966804265975952
training: 0.5514066219329834 epoch = 0 step = 15 loss = 2.7925994396209717
training: 0.46283817291259766 epoch = 0 step = 16 loss = 2.934767246246338
training: 0.5736813545227051 epoch = 0 step = 17 loss = 2.6282880306243896
training: 0.41821956634521484 epoch = 0 step = 18 loss = 2.9532666206359863
training: 0.5985498428344727 epoch = 0 step = 19 loss = 2.7691147327423096
training: 0.6420714855194092 epoch = 0 step = 20 loss = 2.8864614963531494
training: 0.4711496829986572 epoch = 0 step = 21 loss = 2.885923147201538
training: 0.531172513961792 epoch = 0 step = 22 loss = 2.7023532390594482
training: 0.9303667545318604 epoch = 0 step = 23 loss = 2.704500436782837
training: 0.47951340675354004 epoch = 0 step = 24 loss = 2.782585382461548
training: 0.5668182373046875 epoch = 0 step = 25 loss = 2.812385082244873
training: 0.6403672695159912 epoch = 0 step = 26 loss = 2.658811330795288
training: 0.6493885517120361 epoch = 0 step = 27 loss = 2.7628443241119385
training: 0.4466869831085205 epoch = 0 step = 28 loss = 2.8248674869537354
training: 0.4997885227203369 epoch = 0 step = 29 loss = 2.786733627319336
training: 0.5234496593475342 epoch = 0 step = 30 loss = 2.7035534381866455
training: 0.6677863597869873 epoch = 0 step = 31 loss = 2.7100958824157715
training: 0.5297889709472656 epoch = 0 step = 32 loss = 2.4927313327789307
training: 0.41560792922973633 epoch = 1 step = 33 loss = 2.6169257164001465
training: 0.4177250862121582 epoch = 1 step = 34 loss = 2.6419317722320557
training: 0.7330532073974609 epoch = 1 step = 35 loss = 2.566694498062134
training: 0.46202993392944336 epoch = 1 step = 36 loss = 2.64288592338562
training: 0.5711355209350586 epoch = 1 step = 37 loss = 2.948446750640869
training: 0.5507848262786865 epoch = 1 step = 38 loss = 2.409804582595825
training: 0.5458128452301025 epoch = 1 step = 39 loss = 2.529524803161621
training: 0.4626944065093994 epoch = 1 step = 40 loss = 2.724426031112671
training: 0.5198235511779785 epoch = 1 step = 41 loss = 2.9582324028015137
training: 0.45954370498657227 epoch = 1 step = 42 loss = 2.5932235717773438
training: 0.6068065166473389 epoch = 1 step = 43 loss = 2.5106899738311768
training: 0.4571511745452881 epoch = 1 step = 44 loss = 2.3807053565979004
training: 0.3751180171966553 epoch = 1 step = 45 loss = 2.448803424835205
training: 0.4759078025817871 epoch = 1 step = 46 loss = 2.4058690071105957
training: 0.5929510593414307 epoch = 1 step = 47 loss = 2.6754963397979736
training: 0.49268221855163574 epoch = 1 step = 48 loss = 2.617973566055298
training: 0.3898468017578125 epoch = 1 step = 49 loss = 2.582045316696167
training: 0.6245098114013672 epoch = 1 step = 50 loss = 2.58671236038208
training: 0.5971434116363525 epoch = 1 step = 51 loss = 2.871431350708008
training: 0.4933359622955322 epoch = 1 step = 52 loss = 2.434727191925049
training: 0.6309370994567871 epoch = 1 step = 53 loss = 2.682753801345825
training: 0.47266530990600586 epoch = 1 step = 54 loss = 2.596328020095825
training: 0.6056118011474609 epoch = 1 step = 55 loss = 2.5353620052337646
training: 0.5099501609802246 epoch = 1 step = 56 loss = 2.5659940242767334
training: 0.6057925224304199 epoch = 1 step = 57 loss = 2.4473133087158203
training: 0.4451718330383301 epoch = 1 step = 58 loss = 2.5251331329345703
training: 0.6664752960205078 epoch = 1 step = 59 loss = 2.7888474464416504
training: 0.5669848918914795 epoch = 1 step = 60 loss = 2.578294277191162
training: 0.5475504398345947 epoch = 1 step = 61 loss = 2.482194662094116
training: 0.4616057872772217 epoch = 1 step = 62 loss = 2.7275307178497314
training: 0.6978709697723389 epoch = 1 step = 63 loss = 2.6146016120910645
training: 0.44234371185302734 epoch = 1 step = 64 loss = 2.3739707469940186
training: 0.3732011318206787 epoch = 1 step = 65 loss = 2.286294460296631
training: 0.46073389053344727 epoch = 2 step = 66 loss = 2.3996312618255615
training: 0.6698360443115234 epoch = 2 step = 67 loss = 2.3410584926605225
training: 0.44324159622192383 epoch = 2 step = 68 loss = 2.524487018585205
training: 0.5065522193908691 epoch = 2 step = 69 loss = 2.4951021671295166
training: 0.5222227573394775 epoch = 2 step = 70 loss = 2.244800329208374
training: 0.731426477432251 epoch = 2 step = 71 loss = 2.4818081855773926
training: 0.5753185749053955 epoch = 2 step = 72 loss = 2.5945377349853516
training: 0.5104885101318359 epoch = 2 step = 73 loss = 2.4067838191986084
training: 0.4553496837615967 epoch = 2 step = 74 loss = 2.464128017425537
training: 0.6496438980102539 epoch = 2 step = 75 loss = 2.3636057376861572
training: 0.4741811752319336 epoch = 2 step = 76 loss = 2.571246862411499
training: 0.5575501918792725 epoch = 2 step = 77 loss = 2.366396903991699
training: 0.550900936126709 epoch = 2 step = 78 loss = 2.3834409713745117
training: 0.5845603942871094 epoch = 2 step = 79 loss = 2.325906753540039
training: 0.5125579833984375 epoch = 2 step = 80 loss = 2.4095919132232666
training: 0.5005841255187988 epoch = 2 step = 81 loss = 2.4646568298339844
training: 0.5677335262298584 epoch = 2 step = 82 loss = 2.355468988418579
training: 0.6387975215911865 epoch = 2 step = 83 loss = 2.5169830322265625
training: 0.46608543395996094 epoch = 2 step = 84 loss = 2.473844051361084
training: 0.6065080165863037 epoch = 2 step = 85 loss = 2.3784971237182617
training: 0.49957847595214844 epoch = 2 step = 86 loss = 2.3618545532226562
training: 0.5471639633178711 epoch = 2 step = 87 loss = 2.2298896312713623
training: 0.487642765045166 epoch = 2 step = 88 loss = 2.2827394008636475
training: 0.488466739654541 epoch = 2 step = 89 loss = 2.375257968902588
training: 0.47386932373046875 epoch = 2 step = 90 loss = 2.3990511894226074
training: 0.6308445930480957 epoch = 2 step = 91 loss = 2.2634716033935547
training: 0.6385133266448975 epoch = 2 step = 92 loss = 2.4885966777801514
training: 0.508803129196167 epoch = 2 step = 93 loss = 2.2583465576171875
training: 0.45838022232055664 epoch = 2 step = 94 loss = 2.5220558643341064
training: 0.5292305946350098 epoch = 2 step = 95 loss = 2.416990041732788
training: 0.6167149543762207 epoch = 2 step = 96 loss = 2.141481876373291
training: 0.5576026439666748 epoch = 2 step = 97 loss = 2.159066677093506
training: 0.7438936233520508 epoch = 3 step = 98 loss = 2.3230652809143066
training: 0.48647165298461914 epoch = 3 step = 99 loss = 2.155366897583008
training: 0.5042550563812256 epoch = 3 step = 100 loss = 2.1896860599517822

Devolope:
Devoloped = 0.5436718463897705, epoch = 3 step = 101 loss = 2.817841053009033
Devoloped = 0.6401667594909668, epoch = 3 step = 102 loss = 2.6624982357025146
Devoloped = 0.5453569889068604, epoch = 3 step = 103 loss = 2.750974655151367
Devoloped = 0.5391058921813965, epoch = 3 step = 104 loss = 2.587662935256958
Devoloped = 0.544947624206543, epoch = 3 step = 105 loss = 2.735560894012451
Devoloped = 0.751192569732666, epoch = 3 step = 106 loss = 2.7409818172454834
Devoloped = 0.5493996143341064, epoch = 3 step = 107 loss = 2.3867077827453613
Devoloped = 0.4804995059967041, epoch = 3 step = 108 loss = 1.8565341234207153

Evaluate:
[0 0 0 ... 0 7 0]
[0 0 0 ... 0 0 0]
Testing 1.3290166854858398 step = 108
 precision= 0.7105504587155963 recall= 0.7105504587155963 f1_score= 0.7105504587155963
108 0.7105504587155963 0.7105504587155963 0.7105504587155963

training: 0.5575335025787354 epoch = 3 step = 109 loss = 2.1028201580047607
training: 0.5144181251525879 epoch = 3 step = 110 loss = 2.146998405456543
training: 0.6829233169555664 epoch = 3 step = 111 loss = 2.176632881164551
training: 0.44829630851745605 epoch = 3 step = 112 loss = 2.1205849647521973
training: 0.6270401477813721 epoch = 3 step = 113 loss = 2.136364459991455
training: 0.4241173267364502 epoch = 3 step = 114 loss = 2.283626079559326
training: 0.6517007350921631 epoch = 3 step = 115 loss = 2.1062748432159424
training: 0.5656120777130127 epoch = 3 step = 116 loss = 2.271785020828247
training: 0.599876880645752 epoch = 3 step = 117 loss = 2.5440175533294678
training: 0.7826342582702637 epoch = 3 step = 118 loss = 2.1909029483795166
training: 0.3249809741973877 epoch = 3 step = 119 loss = 2.1383492946624756
training: 0.5169210433959961 epoch = 3 step = 120 loss = 2.0046184062957764
training: 0.5248115062713623 epoch = 3 step = 121 loss = 2.238466262817383
training: 0.42491698265075684 epoch = 3 step = 122 loss = 2.0416452884674072
training: 0.6983175277709961 epoch = 3 step = 123 loss = 2.0078225135803223
training: 0.5986576080322266 epoch = 3 step = 124 loss = 2.388582468032837
training: 0.5781717300415039 epoch = 3 step = 125 loss = 2.0599117279052734
training: 0.5999956130981445 epoch = 3 step = 126 loss = 1.9240443706512451
training: 0.526961088180542 epoch = 3 step = 127 loss = 1.978639006614685
training: 0.4937312602996826 epoch = 3 step = 128 loss = 2.2410054206848145
training: 0.5052986145019531 epoch = 3 step = 129 loss = 2.2254629135131836
training: 0.5327801704406738 epoch = 3 step = 130 loss = 2.1697165966033936
training: 0.570885419845581 epoch = 3 step = 131 loss = 1.9838539361953735
training: 0.4411592483520508 epoch = 3 step = 132 loss = 1.9149361848831177
training: 0.5012280941009521 epoch = 3 step = 133 loss = 2.1319572925567627
training: 0.6551275253295898 epoch = 3 step = 134 loss = 2.1283769607543945
training: 0.46053051948547363 epoch = 3 step = 135 loss = 2.0130999088287354
training: 0.4521019458770752 epoch = 3 step = 136 loss = 2.2161529064178467
training: 0.4803733825683594 epoch = 3 step = 137 loss = 2.082104206085205
training: 0.4276151657104492 epoch = 3 step = 138 loss = 1.003519058227539
training: 0.5795602798461914 epoch = 4 step = 139 loss = 1.9369920492172241
training: 0.457019567489624 epoch = 4 step = 140 loss = 2.001145124435425
training: 0.46720194816589355 epoch = 4 step = 141 loss = 1.7791424989700317
training: 0.5461907386779785 epoch = 4 step = 142 loss = 1.8715758323669434
training: 0.8328988552093506 epoch = 4 step = 143 loss = 1.745827555656433
training: 0.447232723236084 epoch = 4 step = 144 loss = 1.9371901750564575
training: 0.40885138511657715 epoch = 4 step = 145 loss = 1.997018575668335
training: 0.8098177909851074 epoch = 4 step = 146 loss = 1.8435314893722534
training: 0.5129299163818359 epoch = 4 step = 147 loss = 1.5785428285598755
training: 0.4339115619659424 epoch = 4 step = 148 loss = 1.539842963218689
training: 0.4820129871368408 epoch = 4 step = 149 loss = 1.590025544166565
training: 0.4771132469177246 epoch = 4 step = 150 loss = 1.7482638359069824
training: 0.6576926708221436 epoch = 4 step = 151 loss = 1.8212560415267944
training: 0.43547749519348145 epoch = 4 step = 152 loss = 1.9648549556732178
training: 0.6271030902862549 epoch = 4 step = 153 loss = 1.7692815065383911
training: 0.620558500289917 epoch = 4 step = 154 loss = 1.950764536857605
training: 0.6631534099578857 epoch = 4 step = 155 loss = 1.722651481628418
training: 0.5996146202087402 epoch = 4 step = 156 loss = 1.6507381200790405
training: 0.4419374465942383 epoch = 4 step = 157 loss = 2.024392604827881
training: 0.6173601150512695 epoch = 4 step = 158 loss = 1.7136746644973755
training: 0.5111081600189209 epoch = 4 step = 159 loss = 1.8030056953430176
training: 0.4717986583709717 epoch = 4 step = 160 loss = 1.7243988513946533
training: 0.46364569664001465 epoch = 4 step = 161 loss = 1.6819761991500854
training: 0.6993255615234375 epoch = 4 step = 162 loss = 1.7211322784423828
training: 0.5445001125335693 epoch = 4 step = 163 loss = 1.8564813137054443
training: 0.47193050384521484 epoch = 4 step = 164 loss = 1.6155835390090942
training: 0.8048872947692871 epoch = 4 step = 165 loss = 1.8679522275924683
training: 0.5122766494750977 epoch = 4 step = 166 loss = 1.665992259979248
training: 0.6770105361938477 epoch = 4 step = 167 loss = 1.9308385848999023
training: 0.6043109893798828 epoch = 4 step = 168 loss = 1.7133113145828247
training: 0.6851010322570801 epoch = 4 step = 169 loss = 1.4849286079406738
training: 0.5267984867095947 epoch = 4 step = 170 loss = 1.924994707107544
training: 0.4918379783630371 epoch = 5 step = 171 loss = 1.4481639862060547
training: 0.5094015598297119 epoch = 5 step = 172 loss = 1.2637125253677368
training: 0.732464075088501 epoch = 5 step = 173 loss = 1.4873806238174438
training: 0.6078708171844482 epoch = 5 step = 174 loss = 1.5672420263290405
training: 0.44705653190612793 epoch = 5 step = 175 loss = 1.5250670909881592
training: 0.5124166011810303 epoch = 5 step = 176 loss = 1.5988119840621948
training: 0.7460877895355225 epoch = 5 step = 177 loss = 1.4436659812927246
training: 0.4903838634490967 epoch = 5 step = 178 loss = 1.4274094104766846
training: 0.5808699131011963 epoch = 5 step = 179 loss = 1.2068248987197876
training: 0.5122706890106201 epoch = 5 step = 180 loss = 1.3572516441345215
training: 0.5224735736846924 epoch = 5 step = 181 loss = 1.5506234169006348
training: 0.4470643997192383 epoch = 5 step = 182 loss = 1.2745280265808105
training: 0.5581300258636475 epoch = 5 step = 183 loss = 1.4664642810821533
training: 0.8922700881958008 epoch = 5 step = 184 loss = 1.2267076969146729
training: 0.46030735969543457 epoch = 5 step = 185 loss = 1.2392871379852295
training: 0.4977390766143799 epoch = 5 step = 186 loss = 1.6361808776855469
training: 0.622807502746582 epoch = 5 step = 187 loss = 1.4022761583328247
training: 0.5769810676574707 epoch = 5 step = 188 loss = 1.320909857749939
training: 0.5720300674438477 epoch = 5 step = 189 loss = 1.3443653583526611
training: 0.41100597381591797 epoch = 5 step = 190 loss = 1.3669441938400269
training: 0.5169675350189209 epoch = 5 step = 191 loss = 1.4560867547988892
training: 0.6985454559326172 epoch = 5 step = 192 loss = 1.0661121606826782
training: 0.5239722728729248 epoch = 5 step = 193 loss = 1.2530783414840698
training: 0.5536553859710693 epoch = 5 step = 194 loss = 1.275537371635437
training: 0.6493945121765137 epoch = 5 step = 195 loss = 1.597593069076538
training: 0.5063388347625732 epoch = 5 step = 196 loss = 1.3120461702346802
training: 0.4582209587097168 epoch = 5 step = 197 loss = 1.430084228515625
training: 0.4485619068145752 epoch = 5 step = 198 loss = 1.278327226638794
training: 0.4896376132965088 epoch = 5 step = 199 loss = 1.0420366525650024
training: 0.5853526592254639 epoch = 5 step = 200 loss = 1.5066461563110352

Devolope:
Devoloped = 0.5171988010406494, epoch = 5 step = 201 loss = 2.021413803100586
Devoloped = 0.43599963188171387, epoch = 5 step = 202 loss = 2.5422439575195312
Devoloped = 0.46142077445983887, epoch = 5 step = 203 loss = 1.9644042253494263
Devoloped = 0.6607966423034668, epoch = 5 step = 204 loss = 2.1753222942352295
Devoloped = 0.5124180316925049, epoch = 5 step = 205 loss = 2.4885764122009277
Devoloped = 0.4463479518890381, epoch = 5 step = 206 loss = 2.1288869380950928
Devoloped = 0.5600829124450684, epoch = 5 step = 207 loss = 1.9985257387161255
Devoloped = 0.5870187282562256, epoch = 5 step = 208 loss = 0.7522678971290588

Evaluate:
[0 0 0 ... 0 0 0]
[0 0 0 ... 0 0 0]
Testing 0.9765775203704834 step = 208
 precision= 0.7622324159021406 recall= 0.7622324159021406 f1_score= 0.7622324159021406
208 0.7622324159021406 0.7622324159021406 0.7622324159021406

training: 0.5280447006225586 epoch = 5 step = 209 loss = 1.534224510192871
training: 0.6901617050170898 epoch = 5 step = 210 loss = 1.480805516242981
training: 0.5201148986816406 epoch = 6 step = 211 loss = 1.0208747386932373
training: 0.6028342247009277 epoch = 6 step = 212 loss = 1.3688507080078125
training: 0.6781373023986816 epoch = 6 step = 213 loss = 1.1192721128463745
training: 0.5767507553100586 epoch = 6 step = 214 loss = 1.109598159790039
training: 0.47469210624694824 epoch = 6 step = 215 loss = 0.9556069374084473
training: 0.4251115322113037 epoch = 6 step = 216 loss = 1.2210378646850586
training: 0.6184771060943604 epoch = 6 step = 217 loss = 1.1615580320358276
training: 0.5710902214050293 epoch = 6 step = 218 loss = 1.0941540002822876
training: 0.4532585144042969 epoch = 6 step = 219 loss = 1.0805888175964355
training: 0.4224832057952881 epoch = 6 step = 220 loss = 0.9925734400749207
training: 0.5665531158447266 epoch = 6 step = 221 loss = 0.9694282412528992
training: 0.5898911952972412 epoch = 6 step = 222 loss = 1.1558458805084229
training: 0.4371929168701172 epoch = 6 step = 223 loss = 1.1004412174224854
training: 0.5481717586517334 epoch = 6 step = 224 loss = 1.0657367706298828
training: 0.485015869140625 epoch = 6 step = 225 loss = 0.9989403486251831
training: 0.5316262245178223 epoch = 6 step = 226 loss = 1.111021637916565
training: 0.4738140106201172 epoch = 6 step = 227 loss = 1.1525059938430786
training: 0.5637960433959961 epoch = 6 step = 228 loss = 1.4022172689437866
training: 0.558051347732544 epoch = 6 step = 229 loss = 1.0953495502471924
training: 0.4863603115081787 epoch = 6 step = 230 loss = 0.7710874080657959
training: 0.5262784957885742 epoch = 6 step = 231 loss = 0.8458361625671387
training: 0.4227907657623291 epoch = 6 step = 232 loss = 1.0353777408599854
training: 0.6160781383514404 epoch = 6 step = 233 loss = 1.0203109979629517
training: 0.63773512840271 epoch = 6 step = 234 loss = 1.0959570407867432
training: 0.5260443687438965 epoch = 6 step = 235 loss = 1.0096174478530884
training: 0.5191242694854736 epoch = 6 step = 236 loss = 0.7832028865814209
training: 0.7809438705444336 epoch = 6 step = 237 loss = 0.9825567007064819
training: 0.4943201541900635 epoch = 6 step = 238 loss = 0.9362203478813171
training: 0.5379526615142822 epoch = 6 step = 239 loss = 0.9824299812316895
training: 0.5042984485626221 epoch = 6 step = 240 loss = 1.1176373958587646
training: 0.5686190128326416 epoch = 6 step = 241 loss = 0.8732090592384338
training: 0.5431640148162842 epoch = 6 step = 242 loss = 0.9216775894165039
training: 0.5368716716766357 epoch = 7 step = 243 loss = 0.8402971029281616
training: 0.47441840171813965 epoch = 7 step = 244 loss = 0.8971459865570068
training: 0.7348349094390869 epoch = 7 step = 245 loss = 0.8157179951667786
training: 0.48456811904907227 epoch = 7 step = 246 loss = 0.8767104744911194
training: 0.6182327270507812 epoch = 7 step = 247 loss = 0.8291803002357483
training: 0.5139470100402832 epoch = 7 step = 248 loss = 0.8902131915092468
training: 0.666478157043457 epoch = 7 step = 249 loss = 0.6453230381011963
training: 0.5145916938781738 epoch = 7 step = 250 loss = 0.7401638031005859
training: 0.6259794235229492 epoch = 7 step = 251 loss = 0.7322897911071777
training: 0.6503782272338867 epoch = 7 step = 252 loss = 1.1090971231460571
training: 0.6063375473022461 epoch = 7 step = 253 loss = 0.9391180872917175
training: 0.5664224624633789 epoch = 7 step = 254 loss = 0.7524092793464661
training: 0.40795087814331055 epoch = 7 step = 255 loss = 0.7836203575134277
training: 0.6938245296478271 epoch = 7 step = 256 loss = 0.7894012928009033
training: 0.5057108402252197 epoch = 7 step = 257 loss = 0.7741587162017822
training: 0.4343574047088623 epoch = 7 step = 258 loss = 0.7599767446517944
training: 0.5205144882202148 epoch = 7 step = 259 loss = 0.737009584903717
training: 0.5594210624694824 epoch = 7 step = 260 loss = 0.7006242275238037
training: 0.5764055252075195 epoch = 7 step = 261 loss = 0.7169429659843445
training: 0.5202677249908447 epoch = 7 step = 262 loss = 1.054112195968628
training: 0.5320174694061279 epoch = 7 step = 263 loss = 0.7245184183120728
training: 0.9171476364135742 epoch = 7 step = 264 loss = 0.91042160987854
training: 0.4700653553009033 epoch = 7 step = 265 loss = 0.8808223009109497
training: 0.4999539852142334 epoch = 7 step = 266 loss = 0.6537039279937744
training: 0.4189589023590088 epoch = 7 step = 267 loss = 0.8445067405700684
training: 0.7651405334472656 epoch = 7 step = 268 loss = 0.618166983127594
training: 0.47290825843811035 epoch = 7 step = 269 loss = 0.8295459151268005
training: 0.5022976398468018 epoch = 7 step = 270 loss = 0.8288164138793945
training: 0.5099318027496338 epoch = 7 step = 271 loss = 0.7712591290473938
training: 0.5045638084411621 epoch = 7 step = 272 loss = 0.6547378897666931
training: 0.47731733322143555 epoch = 7 step = 273 loss = 0.7001839876174927
training: 0.4461052417755127 epoch = 7 step = 274 loss = 0.7867069840431213
training: 0.46030378341674805 epoch = 8 step = 275 loss = 0.6149259209632874
training: 0.5478012561798096 epoch = 8 step = 276 loss = 0.5992612838745117
training: 0.5783231258392334 epoch = 8 step = 277 loss = 0.670366644859314
training: 0.5509030818939209 epoch = 8 step = 278 loss = 0.594001829624176
training: 0.513599157333374 epoch = 8 step = 279 loss = 0.7472919821739197
training: 0.6701016426086426 epoch = 8 step = 280 loss = 0.6768892407417297
training: 0.581129789352417 epoch = 8 step = 281 loss = 0.5354548692703247
training: 0.44191741943359375 epoch = 8 step = 282 loss = 0.6632687449455261
training: 0.48162150382995605 epoch = 8 step = 283 loss = 0.7055200934410095
training: 0.646453857421875 epoch = 8 step = 284 loss = 0.7310512661933899
training: 0.47007274627685547 epoch = 8 step = 285 loss = 0.6615601778030396
training: 0.5302672386169434 epoch = 8 step = 286 loss = 0.466993510723114
training: 0.4740605354309082 epoch = 8 step = 287 loss = 0.5475413799285889
training: 0.7157058715820312 epoch = 8 step = 288 loss = 0.8622351884841919
training: 0.40991759300231934 epoch = 8 step = 289 loss = 0.5427210330963135
training: 0.5794403553009033 epoch = 8 step = 290 loss = 0.46654754877090454
training: 0.5071902275085449 epoch = 8 step = 291 loss = 0.631839394569397
training: 0.6364367008209229 epoch = 8 step = 292 loss = 0.6280789375305176
training: 0.5215306282043457 epoch = 8 step = 293 loss = 0.612954318523407
training: 0.5555882453918457 epoch = 8 step = 294 loss = 0.5439680218696594
training: 0.4996206760406494 epoch = 8 step = 295 loss = 0.609644889831543
training: 0.4688906669616699 epoch = 8 step = 296 loss = 0.7191031575202942
training: 0.5558071136474609 epoch = 8 step = 297 loss = 0.6197943091392517
training: 0.45379638671875 epoch = 8 step = 298 loss = 0.6038789749145508
training: 0.38895177841186523 epoch = 8 step = 299 loss = 0.5655225515365601
training: 0.6196708679199219 epoch = 8 step = 300 loss = 0.5871506333351135

Devolope:
Devoloped = 0.5391829013824463, epoch = 8 step = 301 loss = 1.2294657230377197
Devoloped = 0.4654715061187744, epoch = 8 step = 302 loss = 1.5558513402938843
Devoloped = 0.3873624801635742, epoch = 8 step = 303 loss = 1.6042943000793457
Devoloped = 0.6650698184967041, epoch = 8 step = 304 loss = 1.7031956911087036
Devoloped = 0.5061502456665039, epoch = 8 step = 305 loss = 1.8561313152313232
Devoloped = 0.4672098159790039, epoch = 8 step = 306 loss = 1.4931530952453613
Devoloped = 0.5616106986999512, epoch = 8 step = 307 loss = 1.791999101638794

Evaluate:
[31  0  0 ...  0 25  0]
[0 0 0 ... 0 0 0]
Testing 1.0156333446502686 step = 307
 precision= 0.7155963302752294 recall= 0.7155963302752294 f1_score= 0.7155963302752294
307 0.7155963302752294 0.7155963302752294 0.7155963302752294

training: 0.6375830173492432 epoch = 8 step = 308 loss = 0.6582790017127991
training: 0.5263967514038086 epoch = 8 step = 309 loss = 0.6611974239349365
training: 0.7443985939025879 epoch = 8 step = 310 loss = 0.5928360223770142
training: 0.654843807220459 epoch = 8 step = 311 loss = 0.589863121509552
training: 0.5384562015533447 epoch = 8 step = 312 loss = 0.7235904932022095
training: 0.45099496841430664 epoch = 8 step = 313 loss = 0.7009203433990479
training: 0.5434474945068359 epoch = 9 step = 314 loss = 0.5119702816009521
training: 0.5385446548461914 epoch = 9 step = 315 loss = 0.4285311996936798
training: 0.5335841178894043 epoch = 9 step = 316 loss = 0.48273175954818726
training: 0.5286099910736084 epoch = 9 step = 317 loss = 0.6180296540260315
training: 0.4660987854003906 epoch = 9 step = 318 loss = 0.4425835907459259
training: 0.4497377872467041 epoch = 9 step = 319 loss = 0.568676233291626
training: 0.5441462993621826 epoch = 9 step = 320 loss = 0.48469555377960205
training: 0.4911227226257324 epoch = 9 step = 321 loss = 0.5232008695602417
training: 0.7041976451873779 epoch = 9 step = 322 loss = 0.6136490106582642
training: 0.473651647567749 epoch = 9 step = 323 loss = 0.4763142466545105
training: 0.45177316665649414 epoch = 9 step = 324 loss = 0.5236163139343262
training: 0.5160558223724365 epoch = 9 step = 325 loss = 0.5921382904052734
training: 0.8994698524475098 epoch = 9 step = 326 loss = 0.5863529443740845
training: 0.5552120208740234 epoch = 9 step = 327 loss = 0.452364981174469
training: 0.5154240131378174 epoch = 9 step = 328 loss = 0.46611255407333374
training: 0.5753180980682373 epoch = 9 step = 329 loss = 0.5666210651397705
training: 0.5182769298553467 epoch = 9 step = 330 loss = 0.5226061344146729
training: 0.5414202213287354 epoch = 9 step = 331 loss = 0.4042498469352722
training: 0.4557971954345703 epoch = 9 step = 332 loss = 0.6324859261512756
training: 0.5512998104095459 epoch = 9 step = 333 loss = 0.5748593211174011
training: 0.5747978687286377 epoch = 9 step = 334 loss = 0.5679759979248047
training: 0.6120634078979492 epoch = 9 step = 335 loss = 0.5391367077827454
training: 0.5346841812133789 epoch = 9 step = 336 loss = 0.5984960794448853
training: 0.6911220550537109 epoch = 9 step = 337 loss = 0.45394808053970337
training: 0.5008294582366943 epoch = 9 step = 338 loss = 0.5712968707084656
training: 0.5601167678833008 epoch = 9 step = 339 loss = 0.5444505214691162
training: 0.49037599563598633 epoch = 9 step = 340 loss = 0.4736921787261963
training: 0.5683510303497314 epoch = 9 step = 341 loss = 0.6284147500991821
training: 0.5356605052947998 epoch = 9 step = 342 loss = 0.6265743970870972
training: 0.6105051040649414 epoch = 9 step = 343 loss = 0.46696120500564575
training: 0.5299897193908691 epoch = 9 step = 344 loss = 0.5234639644622803
training: 0.5573375225067139 epoch = 9 step = 345 loss = 0.49677687883377075
training: 0.5402040481567383 epoch = 9 step = 346 loss = 0.369024395942688
training: 0.5166759490966797 epoch = 10 step = 347 loss = 0.4575101435184479
training: 0.44853687286376953 epoch = 10 step = 348 loss = 0.4715263843536377
training: 0.6538903713226318 epoch = 10 step = 349 loss = 0.5113592147827148
training: 0.4710884094238281 epoch = 10 step = 350 loss = 0.45552265644073486
training: 0.5347936153411865 epoch = 10 step = 351 loss = 0.4005367159843445
training: 0.4867894649505615 epoch = 10 step = 352 loss = 0.43961721658706665
training: 0.6263682842254639 epoch = 10 step = 353 loss = 0.46536916494369507
training: 0.5921306610107422 epoch = 10 step = 354 loss = 0.4550905227661133
training: 0.5347254276275635 epoch = 10 step = 355 loss = 0.37707608938217163
training: 0.5794858932495117 epoch = 10 step = 356 loss = 0.4772869944572449
training: 0.6049566268920898 epoch = 10 step = 357 loss = 0.5695197582244873
training: 0.45522522926330566 epoch = 10 step = 358 loss = 0.48022401332855225
training: 0.43131136894226074 epoch = 10 step = 359 loss = 0.453228622674942
training: 0.5055160522460938 epoch = 10 step = 360 loss = 0.5239250063896179
training: 0.5133981704711914 epoch = 10 step = 361 loss = 0.39918261766433716
training: 0.44677305221557617 epoch = 10 step = 362 loss = 0.480796754360199
training: 0.5192372798919678 epoch = 10 step = 363 loss = 0.5226783752441406
training: 0.5377163887023926 epoch = 10 step = 364 loss = 0.46083521842956543
training: 0.7311468124389648 epoch = 10 step = 365 loss = 0.46713173389434814
training: 0.5334177017211914 epoch = 10 step = 366 loss = 0.4085981845855713
training: 0.5475797653198242 epoch = 10 step = 367 loss = 0.45300695300102234
training: 0.6835727691650391 epoch = 10 step = 368 loss = 0.4029052257537842
training: 0.5598118305206299 epoch = 10 step = 369 loss = 0.5192320942878723
training: 0.4632425308227539 epoch = 10 step = 370 loss = 0.49101945757865906
training: 0.5803418159484863 epoch = 10 step = 371 loss = 0.4222205877304077
training: 0.627763032913208 epoch = 10 step = 372 loss = 0.4537563920021057
training: 0.46656250953674316 epoch = 10 step = 373 loss = 0.5243009924888611
training: 0.49951720237731934 epoch = 10 step = 374 loss = 0.39308246970176697
training: 0.49494147300720215 epoch = 10 step = 375 loss = 0.39084580540657043
training: 0.5166590213775635 epoch = 10 step = 376 loss = 0.4761154055595398
training: 0.46466565132141113 epoch = 10 step = 377 loss = 0.5060480833053589
training: 0.4152946472167969 epoch = 10 step = 378 loss = 0.49904686212539673
training: 0.5535950660705566 epoch = 10 step = 379 loss = 0.5960099101066589
training: 0.4869859218597412 epoch = 11 step = 380 loss = 0.41748663783073425
training: 0.6782858371734619 epoch = 11 step = 381 loss = 0.4432741403579712
training: 0.4717080593109131 epoch = 11 step = 382 loss = 0.40337663888931274
training: 0.45810747146606445 epoch = 11 step = 383 loss = 0.48917824029922485
training: 0.6492528915405273 epoch = 11 step = 384 loss = 0.5021690130233765
training: 0.51743483543396 epoch = 11 step = 385 loss = 0.44191431999206543
training: 0.5292999744415283 epoch = 11 step = 386 loss = 0.34865880012512207
training: 0.4319593906402588 epoch = 11 step = 387 loss = 0.3929283022880554
training: 0.4368736743927002 epoch = 11 step = 388 loss = 0.44996750354766846
training: 0.6950492858886719 epoch = 11 step = 389 loss = 0.3622460961341858
training: 0.6776509284973145 epoch = 11 step = 390 loss = 0.390933632850647
training: 0.5268948078155518 epoch = 11 step = 391 loss = 0.39177483320236206
training: 0.7371773719787598 epoch = 11 step = 392 loss = 0.36247408390045166
training: 0.39812278747558594 epoch = 11 step = 393 loss = 0.3983941078186035
training: 0.446791410446167 epoch = 11 step = 394 loss = 0.4753854274749756
training: 0.5616610050201416 epoch = 11 step = 395 loss = 0.41753947734832764
training: 0.6818010807037354 epoch = 11 step = 396 loss = 0.47479814291000366
training: 0.5350594520568848 epoch = 11 step = 397 loss = 0.46073469519615173
training: 0.5712521076202393 epoch = 11 step = 398 loss = 0.3857690095901489
training: 0.4807422161102295 epoch = 11 step = 399 loss = 0.3842047452926636
training: 0.671966552734375 epoch = 11 step = 400 loss = 0.3738601505756378

Devolope:
Devoloped = 0.46530652046203613, epoch = 11 step = 401 loss = 1.0103203058242798
Devoloped = 0.4421992301940918, epoch = 11 step = 402 loss = 1.1317577362060547
Devoloped = 0.45244646072387695, epoch = 11 step = 403 loss = 1.2007709741592407
Devoloped = 0.7472150325775146, epoch = 11 step = 404 loss = 0.8739179372787476
Devoloped = 0.4210031032562256, epoch = 11 step = 405 loss = 1.1188864707946777
Devoloped = 0.49266958236694336, epoch = 11 step = 406 loss = 1.126460075378418
Devoloped = 0.5290870666503906, epoch = 11 step = 407 loss = 0.8927785158157349
Devoloped = 0.6459152698516846, epoch = 11 step = 408 loss = 1.1832334995269775

Evaluate:
[ 0  0  0 ...  0 25  0]
[0 0 0 ... 0 0 0]
Testing 1.0883464813232422 step = 408
 precision= 0.8152905198776759 recall= 0.8152905198776759 f1_score= 0.8152905198776759
408 0.8152905198776759 0.8152905198776759 0.8152905198776759

training: 0.4966442584991455 epoch = 11 step = 409 loss = 0.4614446759223938
training: 0.7056565284729004 epoch = 11 step = 410 loss = 0.3647291958332062
training: 0.5832269191741943 epoch = 11 step = 411 loss = 0.42407023906707764
training: 0.5317771434783936 epoch = 11 step = 412 loss = 0.34530895948410034
training: 0.4489758014678955 epoch = 11 step = 413 loss = 0.40771248936653137
training: 0.49486517906188965 epoch = 11 step = 414 loss = 0.4305614233016968
training: 0.4976167678833008 epoch = 11 step = 415 loss = 0.42941340804100037
training: 0.5594282150268555 epoch = 11 step = 416 loss = 0.4127997159957886
training: 0.500591516494751 epoch = 11 step = 417 loss = 0.4268046021461487
training: 0.5693831443786621 epoch = 11 step = 418 loss = 0.4535894989967346
training: 0.5726282596588135 epoch = 11 step = 419 loss = 0.4883967638015747
training: 0.5377287864685059 epoch = 12 step = 420 loss = 0.38284769654273987
training: 0.5455865859985352 epoch = 12 step = 421 loss = 0.374517023563385
training: 0.5423059463500977 epoch = 12 step = 422 loss = 0.438975989818573
training: 0.4941422939300537 epoch = 12 step = 423 loss = 0.38222211599349976
training: 0.4528810977935791 epoch = 12 step = 424 loss = 0.46387606859207153
training: 0.5072193145751953 epoch = 12 step = 425 loss = 0.3807476758956909
training: 0.6684310436248779 epoch = 12 step = 426 loss = 0.34904342889785767
training: 0.46434974670410156 epoch = 12 step = 427 loss = 0.3688790500164032
training: 0.47237730026245117 epoch = 12 step = 428 loss = 0.41085362434387207
training: 0.424405574798584 epoch = 12 step = 429 loss = 0.42307594418525696
training: 0.6693532466888428 epoch = 12 step = 430 loss = 0.4765862822532654
training: 0.4927666187286377 epoch = 12 step = 431 loss = 0.41095423698425293
training: 0.47559452056884766 epoch = 12 step = 432 loss = 0.37645745277404785
training: 0.39740419387817383 epoch = 12 step = 433 loss = 0.367868572473526
training: 0.7283964157104492 epoch = 12 step = 434 loss = 0.3781777024269104
training: 0.5673418045043945 epoch = 12 step = 435 loss = 0.37834927439689636
training: 0.4784529209136963 epoch = 12 step = 436 loss = 0.4086875319480896
training: 0.539567232131958 epoch = 12 step = 437 loss = 0.4198055863380432
training: 0.6663296222686768 epoch = 12 step = 438 loss = 0.4750244617462158
training: 0.6026022434234619 epoch = 12 step = 439 loss = 0.37939000129699707
training: 0.6112370491027832 epoch = 12 step = 440 loss = 0.43627578020095825
training: 0.7469174861907959 epoch = 12 step = 441 loss = 0.35130709409713745
training: 0.5182571411132812 epoch = 12 step = 442 loss = 0.3554050028324127
training: 0.4850926399230957 epoch = 12 step = 443 loss = 0.41136908531188965
training: 0.5449385643005371 epoch = 12 step = 444 loss = 0.4118780493736267
training: 0.7528848648071289 epoch = 12 step = 445 loss = 0.4275834560394287
training: 0.5064115524291992 epoch = 12 step = 446 loss = 0.3367992639541626
training: 0.4478139877319336 epoch = 12 step = 447 loss = 0.3567850589752197
training: 0.5841114521026611 epoch = 12 step = 448 loss = 0.40170130133628845
training: 0.728036642074585 epoch = 12 step = 449 loss = 0.3827529847621918
training: 0.4747884273529053 epoch = 12 step = 450 loss = 0.3866620659828186
training: 0.5351047515869141 epoch = 12 step = 451 loss = 0.41853582859039307
training: 0.4890427589416504 epoch = 13 step = 452 loss = 0.3949648141860962
training: 0.4712512493133545 epoch = 13 step = 453 loss = 0.4393066167831421
training: 0.5819084644317627 epoch = 13 step = 454 loss = 0.36961448192596436
training: 0.5021016597747803 epoch = 13 step = 455 loss = 0.3361814022064209
training: 0.4850924015045166 epoch = 13 step = 456 loss = 0.37470293045043945
training: 0.49532318115234375 epoch = 13 step = 457 loss = 0.42039933800697327
training: 0.5857458114624023 epoch = 13 step = 458 loss = 0.35563135147094727
training: 0.42766737937927246 epoch = 13 step = 459 loss = 0.4344770312309265
training: 0.5999507904052734 epoch = 13 step = 460 loss = 0.361895889043808
training: 0.6588208675384521 epoch = 13 step = 461 loss = 0.36503171920776367
training: 0.5332379341125488 epoch = 13 step = 462 loss = 0.3834189176559448
training: 0.6005773544311523 epoch = 13 step = 463 loss = 0.37232130765914917
training: 0.6339178085327148 epoch = 13 step = 464 loss = 0.3657698631286621
training: 0.5971400737762451 epoch = 13 step = 465 loss = 0.4013502597808838
training: 0.5284469127655029 epoch = 13 step = 466 loss = 0.35775765776634216
training: 0.48974084854125977 epoch = 13 step = 467 loss = 0.39535170793533325
training: 0.7319145202636719 epoch = 13 step = 468 loss = 0.3695935606956482
training: 0.4795510768890381 epoch = 13 step = 469 loss = 0.3999863862991333
training: 0.5466728210449219 epoch = 13 step = 470 loss = 0.36633312702178955
training: 0.5273654460906982 epoch = 13 step = 471 loss = 0.3547344505786896
training: 0.6783416271209717 epoch = 13 step = 472 loss = 0.34297725558280945
training: 0.5291249752044678 epoch = 13 step = 473 loss = 0.39036762714385986
training: 0.4810802936553955 epoch = 13 step = 474 loss = 0.3398329019546509
training: 0.4884049892425537 epoch = 13 step = 475 loss = 0.35224854946136475
training: 0.526608943939209 epoch = 13 step = 476 loss = 0.3550350069999695
training: 0.527209997177124 epoch = 13 step = 477 loss = 0.3740779757499695
training: 0.42430925369262695 epoch = 13 step = 478 loss = 0.35553881525993347
training: 0.5398144721984863 epoch = 13 step = 479 loss = 0.38292136788368225
training: 0.7082803249359131 epoch = 13 step = 480 loss = 0.3711114525794983
training: 0.43210530281066895 epoch = 13 step = 481 loss = 0.41103965044021606
training: 0.45962023735046387 epoch = 13 step = 482 loss = 0.32796555757522583
training: 0.5670015811920166 epoch = 13 step = 483 loss = 0.39468759298324585
training: 0.7036576271057129 epoch = 14 step = 484 loss = 0.38800400495529175
training: 0.5798745155334473 epoch = 14 step = 485 loss = 0.4032953679561615
training: 0.4767932891845703 epoch = 14 step = 486 loss = 0.3572752773761749
training: 0.44092416763305664 epoch = 14 step = 487 loss = 0.3256264925003052
training: 0.6350226402282715 epoch = 14 step = 488 loss = 0.37275734543800354
training: 0.5456597805023193 epoch = 14 step = 489 loss = 0.31596654653549194
training: 0.49477458000183105 epoch = 14 step = 490 loss = 0.29992952942848206
training: 0.4246253967285156 epoch = 14 step = 491 loss = 0.3074794411659241
training: 0.7184479236602783 epoch = 14 step = 492 loss = 0.3327644467353821
training: 0.48030662536621094 epoch = 14 step = 493 loss = 0.35295140743255615
training: 0.5713539123535156 epoch = 14 step = 494 loss = 0.3373560905456543
training: 0.4775886535644531 epoch = 14 step = 495 loss = 0.3258574306964874
training: 0.5406644344329834 epoch = 14 step = 496 loss = 0.32524704933166504
training: 0.3911006450653076 epoch = 14 step = 497 loss = 0.32556894421577454
training: 0.48554015159606934 epoch = 14 step = 498 loss = 0.3152315020561218
training: 0.4837515354156494 epoch = 14 step = 499 loss = 0.33999085426330566
training: 0.7033777236938477 epoch = 14 step = 500 loss = 0.33311188220977783

Devolope:
Devoloped = 0.5227062702178955, epoch = 14 step = 501 loss = 0.740615725517273
Devoloped = 0.4458603858947754, epoch = 14 step = 502 loss = 0.770879864692688
Devoloped = 0.43599915504455566, epoch = 14 step = 503 loss = 0.6310138702392578
Devoloped = 0.6726791858673096, epoch = 14 step = 504 loss = 0.60829758644104
Devoloped = 0.5128402709960938, epoch = 14 step = 505 loss = 0.7124451994895935
Devoloped = 0.4627399444580078, epoch = 14 step = 506 loss = 0.6511712074279785
Devoloped = 0.4424011707305908, epoch = 14 step = 507 loss = 0.7132357358932495
Devoloped = 0.5820779800415039, epoch = 14 step = 508 loss = 0.5253101587295532

Evaluate:
[ 0  0  0 ...  0 31  0]
[0 0 0 ... 0 0 0]
Testing 1.0254878997802734 step = 508
 precision= 0.8469418960244648 recall= 0.8469418960244648 f1_score= 0.8469418960244648
508 0.8469418960244648 0.8469418960244648 0.8469418960244648

training: 0.5816400051116943 epoch = 14 step = 509 loss = 0.31164610385894775
training: 0.5323421955108643 epoch = 14 step = 510 loss = 0.3074946105480194
training: 0.47817349433898926 epoch = 14 step = 511 loss = 0.38549020886421204
training: 0.5046639442443848 epoch = 14 step = 512 loss = 0.3207118809223175
training: 0.5752520561218262 epoch = 14 step = 513 loss = 0.34997954964637756
training: 0.725830078125 epoch = 14 step = 514 loss = 0.3289187550544739
training: 0.4653761386871338 epoch = 14 step = 515 loss = 0.33539873361587524
training: 0.5227870941162109 epoch = 14 step = 516 loss = 0.35011160373687744
training: 0.5936694145202637 epoch = 14 step = 517 loss = 0.44555526971817017
training: 0.7352242469787598 epoch = 14 step = 518 loss = 0.35576188564300537
training: 0.5287134647369385 epoch = 14 step = 519 loss = 0.3726353645324707
training: 0.4562489986419678 epoch = 14 step = 520 loss = 0.3350721001625061
training: 0.49402832984924316 epoch = 14 step = 521 loss = 0.3354731798171997
training: 0.5361652374267578 epoch = 14 step = 522 loss = 0.3199191689491272
training: 0.5646998882293701 epoch = 14 step = 523 loss = 0.3745024800300598
training: 0.47948479652404785 epoch = 15 step = 524 loss = 0.3516311049461365
training: 0.5211317539215088 epoch = 15 step = 525 loss = 0.31295153498649597
training: 0.5749821662902832 epoch = 15 step = 526 loss = 0.3159679174423218
training: 0.5316402912139893 epoch = 15 step = 527 loss = 0.39167845249176025
training: 0.5385854244232178 epoch = 15 step = 528 loss = 0.33126774430274963
training: 0.7250931262969971 epoch = 15 step = 529 loss = 0.31745272874832153
training: 0.5590903759002686 epoch = 15 step = 530 loss = 0.32366564869880676
training: 0.48308873176574707 epoch = 15 step = 531 loss = 0.3352419137954712
training: 0.5633344650268555 epoch = 15 step = 532 loss = 0.3509480059146881
training: 0.5946383476257324 epoch = 15 step = 533 loss = 0.33378076553344727
training: 0.5308175086975098 epoch = 15 step = 534 loss = 0.3173665404319763
training: 0.5010166168212891 epoch = 15 step = 535 loss = 0.33668017387390137
training: 0.5565900802612305 epoch = 15 step = 536 loss = 0.33422285318374634
training: 0.7127866744995117 epoch = 15 step = 537 loss = 0.38179177045822144
training: 0.5806810855865479 epoch = 15 step = 538 loss = 0.362973153591156
training: 0.48565125465393066 epoch = 15 step = 539 loss = 0.32749059796333313
training: 0.40730834007263184 epoch = 15 step = 540 loss = 0.31193313002586365
training: 0.5881552696228027 epoch = 15 step = 541 loss = 0.31142905354499817
training: 0.5064225196838379 epoch = 15 step = 542 loss = 0.34193819761276245
training: 0.5666713714599609 epoch = 15 step = 543 loss = 0.35124263167381287
training: 0.4726450443267822 epoch = 15 step = 544 loss = 0.336304634809494
training: 0.6306905746459961 epoch = 15 step = 545 loss = 0.341747909784317
training: 0.5459301471710205 epoch = 15 step = 546 loss = 0.31728678941726685
training: 0.5037815570831299 epoch = 15 step = 547 loss = 0.31546223163604736
training: 0.5104842185974121 epoch = 15 step = 548 loss = 0.34590110182762146
training: 0.6796863079071045 epoch = 15 step = 549 loss = 0.3214725852012634
training: 0.5949912071228027 epoch = 15 step = 550 loss = 0.3635059893131256
training: 0.4395420551300049 epoch = 15 step = 551 loss = 0.33914101123809814
training: 0.5917017459869385 epoch = 15 step = 552 loss = 0.3605016767978668
training: 0.5399377346038818 epoch = 15 step = 553 loss = 0.3387843072414398
training: 0.4794282913208008 epoch = 15 step = 554 loss = 0.3342878818511963
training: 0.6117138862609863 epoch = 15 step = 555 loss = 0.3334096372127533
training: 0.46085309982299805 epoch = 16 step = 556 loss = 0.3103027641773224
training: 0.5010485649108887 epoch = 16 step = 557 loss = 0.29553067684173584
training: 0.3611786365509033 epoch = 16 step = 558 loss = 0.32407355308532715
training: 0.5780360698699951 epoch = 16 step = 559 loss = 0.32265618443489075
training: 0.6696786880493164 epoch = 16 step = 560 loss = 0.32828590273857117
training: 0.5873754024505615 epoch = 16 step = 561 loss = 0.36047521233558655
training: 0.4832780361175537 epoch = 16 step = 562 loss = 0.32582253217697144
training: 0.6132233142852783 epoch = 16 step = 563 loss = 0.3363952338695526
training: 0.7207818031311035 epoch = 16 step = 564 loss = 0.32558539509773254
training: 0.4952566623687744 epoch = 16 step = 565 loss = 0.32060638070106506
training: 0.49086523056030273 epoch = 16 step = 566 loss = 0.3236317038536072
training: 0.43035054206848145 epoch = 16 step = 567 loss = 0.3408539295196533
training: 0.7279403209686279 epoch = 16 step = 568 loss = 0.3240945339202881
training: 0.5407109260559082 epoch = 16 step = 569 loss = 0.28515860438346863
training: 0.45768046379089355 epoch = 16 step = 570 loss = 0.30983853340148926
training: 0.5006697177886963 epoch = 16 step = 571 loss = 0.30417969822883606
training: 0.6764719486236572 epoch = 16 step = 572 loss = 0.364333838224411
training: 0.4898948669433594 epoch = 16 step = 573 loss = 0.34954172372817993
training: 0.563849687576294 epoch = 16 step = 574 loss = 0.3379170596599579
training: 0.6183128356933594 epoch = 16 step = 575 loss = 0.31562092900276184
training: 0.7451074123382568 epoch = 16 step = 576 loss = 0.30984964966773987
training: 0.5311715602874756 epoch = 16 step = 577 loss = 0.36451372504234314
training: 0.509669303894043 epoch = 16 step = 578 loss = 0.3541257977485657
training: 0.5332241058349609 epoch = 16 step = 579 loss = 0.29902517795562744
training: 0.6674234867095947 epoch = 16 step = 580 loss = 0.30635398626327515
training: 0.5315067768096924 epoch = 16 step = 581 loss = 0.29602739214897156
training: 0.4297654628753662 epoch = 16 step = 582 loss = 0.3252161741256714
training: 0.7583765983581543 epoch = 16 step = 583 loss = 0.2954902648925781
training: 0.497408390045166 epoch = 16 step = 584 loss = 0.3215042054653168
training: 0.6657590866088867 epoch = 16 step = 585 loss = 0.30890488624572754
training: 0.4727811813354492 epoch = 16 step = 586 loss = 0.3080095648765564
training: 0.6360702514648438 epoch = 16 step = 587 loss = 0.3146209120750427
training: 0.5445523262023926 epoch = 17 step = 588 loss = 0.29673221707344055
training: 0.4203317165374756 epoch = 17 step = 589 loss = 0.3562295436859131
training: 0.5141746997833252 epoch = 17 step = 590 loss = 0.3252449929714203
training: 0.7216713428497314 epoch = 17 step = 591 loss = 0.3448437452316284
training: 0.5400660037994385 epoch = 17 step = 592 loss = 0.2788746953010559
training: 0.46031928062438965 epoch = 17 step = 593 loss = 0.2803180515766144
training: 0.49581074714660645 epoch = 17 step = 594 loss = 0.3644278049468994
training: 0.6828780174255371 epoch = 17 step = 595 loss = 0.33293935656547546
training: 0.5999982357025146 epoch = 17 step = 596 loss = 0.3096005618572235
training: 0.6239662170410156 epoch = 17 step = 597 loss = 0.3560095429420471
training: 0.666339635848999 epoch = 17 step = 598 loss = 0.31961074471473694
training: 0.4599583148956299 epoch = 17 step = 599 loss = 0.2926802933216095
training: 0.3952319622039795 epoch = 17 step = 600 loss = 0.2927977740764618

Devolope:
Devoloped = 0.5843303203582764, epoch = 17 step = 601 loss = 0.4097033143043518
Devoloped = 0.6963932514190674, epoch = 17 step = 602 loss = 0.4455633759498596
Devoloped = 0.48381876945495605, epoch = 17 step = 603 loss = 0.6353225708007812
Devoloped = 0.519874095916748, epoch = 17 step = 604 loss = 0.5536908507347107
Devoloped = 0.6629116535186768, epoch = 17 step = 605 loss = 0.5997564196586609
Devoloped = 0.6648645401000977, epoch = 17 step = 606 loss = 0.49044069647789
Devoloped = 0.4906041622161865, epoch = 17 step = 607 loss = 0.4591975808143616

Evaluate:
[0 0 0 ... 0 0 0]
[0 0 0 ... 0 0 0]
Testing 0.975689172744751 step = 607
 precision= 0.8721712538226299 recall= 0.8721712538226299 f1_score= 0.8721712538226299
607 0.8721712538226299 0.8721712538226299 0.8721712538226299

training: 0.6783263683319092 epoch = 17 step = 608 loss = 0.3306158483028412
training: 0.43392348289489746 epoch = 17 step = 609 loss = 0.3320710361003876
training: 0.520195484161377 epoch = 17 step = 610 loss = 0.29388004541397095
training: 0.39418959617614746 epoch = 17 step = 611 loss = 0.3161323666572571
training: 0.6037271022796631 epoch = 17 step = 612 loss = 0.3112833797931671
training: 0.5113098621368408 epoch = 17 step = 613 loss = 0.363612562417984
training: 0.4359092712402344 epoch = 17 step = 614 loss = 0.2998519241809845
training: 0.4927079677581787 epoch = 17 step = 615 loss = 0.32865577936172485
training: 0.4238438606262207 epoch = 17 step = 616 loss = 0.29050010442733765
training: 0.5094678401947021 epoch = 17 step = 617 loss = 0.35312625765800476
training: 0.6390178203582764 epoch = 17 step = 618 loss = 0.33937376737594604
training: 0.4788491725921631 epoch = 17 step = 619 loss = 0.436708927154541
training: 0.519672155380249 epoch = 17 step = 620 loss = 0.2921963632106781
training: 0.5725796222686768 epoch = 17 step = 621 loss = 0.2966170907020569
training: 0.5628445148468018 epoch = 17 step = 622 loss = 0.29946169257164
training: 0.5164587497711182 epoch = 17 step = 623 loss = 0.3009275197982788
training: 0.47546935081481934 epoch = 17 step = 624 loss = 0.33513569831848145
training: 0.49138355255126953 epoch = 17 step = 625 loss = 0.3158007860183716
training: 0.5023291110992432 epoch = 17 step = 626 loss = 0.2861851155757904
training: 0.4842045307159424 epoch = 17 step = 627 loss = 0.2528245747089386
training: 0.5550482273101807 epoch = 18 step = 628 loss = 0.31752780079841614
training: 0.6639695167541504 epoch = 18 step = 629 loss = 0.300261914730072
training: 0.44625377655029297 epoch = 18 step = 630 loss = 0.3295240104198456
training: 0.6709432601928711 epoch = 18 step = 631 loss = 0.309967041015625
training: 0.42305660247802734 epoch = 18 step = 632 loss = 0.30975231528282166
training: 0.5764613151550293 epoch = 18 step = 633 loss = 0.27880826592445374
training: 0.5494213104248047 epoch = 18 step = 634 loss = 0.3041994869709015
training: 0.4497060775756836 epoch = 18 step = 635 loss = 0.32710379362106323
training: 0.5501270294189453 epoch = 18 step = 636 loss = 0.303438663482666
training: 0.611112117767334 epoch = 18 step = 637 loss = 0.31393706798553467
training: 0.5097091197967529 epoch = 18 step = 638 loss = 0.31348544359207153
training: 0.5079832077026367 epoch = 18 step = 639 loss = 0.29294657707214355
training: 0.42166733741760254 epoch = 18 step = 640 loss = 0.30924880504608154
training: 0.6713883876800537 epoch = 18 step = 641 loss = 0.2892243266105652
training: 0.6704964637756348 epoch = 18 step = 642 loss = 0.2713404893875122
training: 0.5446987152099609 epoch = 18 step = 643 loss = 0.271738737821579
training: 0.7229948043823242 epoch = 18 step = 644 loss = 0.2942665219306946
training: 0.4554176330566406 epoch = 18 step = 645 loss = 0.33321133255958557
training: 0.4965360164642334 epoch = 18 step = 646 loss = 0.30684584379196167
training: 0.5489482879638672 epoch = 18 step = 647 loss = 0.29664239287376404
training: 0.6896166801452637 epoch = 18 step = 648 loss = 0.2993301749229431
training: 0.6311547756195068 epoch = 18 step = 649 loss = 0.28343021869659424
training: 0.4708278179168701 epoch = 18 step = 650 loss = 0.28869837522506714
training: 0.4586043357849121 epoch = 18 step = 651 loss = 0.2784012258052826
training: 0.6713583469390869 epoch = 18 step = 652 loss = 0.34132713079452515
training: 0.6064996719360352 epoch = 18 step = 653 loss = 0.3035541772842407
training: 0.4901595115661621 epoch = 18 step = 654 loss = 0.28472650051116943
training: 0.44196462631225586 epoch = 18 step = 655 loss = 0.29582104086875916
training: 0.4373800754547119 epoch = 18 step = 656 loss = 0.271182119846344
training: 0.503727912902832 epoch = 18 step = 657 loss = 0.3340288996696472
training: 0.5846076011657715 epoch = 18 step = 658 loss = 0.29138901829719543
training: 0.49977612495422363 epoch = 18 step = 659 loss = 0.28684133291244507
training: 0.6369538307189941 epoch = 19 step = 660 loss = 0.294211208820343
training: 0.4794609546661377 epoch = 19 step = 661 loss = 0.2853838801383972
training: 0.4497387409210205 epoch = 19 step = 662 loss = 0.30320125818252563
training: 0.5677018165588379 epoch = 19 step = 663 loss = 0.28971928358078003
training: 0.8070378303527832 epoch = 19 step = 664 loss = 0.2930517792701721
training: 0.5231049060821533 epoch = 19 step = 665 loss = 0.28500789403915405
training: 0.4616677761077881 epoch = 19 step = 666 loss = 0.28901785612106323
training: 0.6460123062133789 epoch = 19 step = 667 loss = 0.2791360914707184
training: 0.5144238471984863 epoch = 19 step = 668 loss = 0.26820671558380127
training: 0.49729299545288086 epoch = 19 step = 669 loss = 0.2766452133655548
training: 0.5097553730010986 epoch = 19 step = 670 loss = 0.2871878743171692
training: 0.7004501819610596 epoch = 19 step = 671 loss = 0.2687690258026123
training: 0.525853157043457 epoch = 19 step = 672 loss = 0.28829675912857056
training: 0.49611926078796387 epoch = 19 step = 673 loss = 0.28875836730003357
training: 0.4278688430786133 epoch = 19 step = 674 loss = 0.2844773530960083
training: 0.6175224781036377 epoch = 19 step = 675 loss = 0.2722146213054657
training: 0.5387866497039795 epoch = 19 step = 676 loss = 0.2958124577999115
training: 0.6065378189086914 epoch = 19 step = 677 loss = 0.2670691907405853
training: 0.48274755477905273 epoch = 19 step = 678 loss = 0.2831917107105255
training: 0.5697188377380371 epoch = 19 step = 679 loss = 0.29761508107185364
training: 0.5617883205413818 epoch = 19 step = 680 loss = 0.2694605886936188
training: 0.6661596298217773 epoch = 19 step = 681 loss = 0.2756860554218292
training: 0.4143846035003662 epoch = 19 step = 682 loss = 0.29280906915664673
training: 0.7028486728668213 epoch = 19 step = 683 loss = 0.2827092409133911
training: 0.6110196113586426 epoch = 19 step = 684 loss = 0.26349496841430664
training: 0.5241556167602539 epoch = 19 step = 685 loss = 0.33059683442115784
training: 0.5294678211212158 epoch = 19 step = 686 loss = 0.28307467699050903
training: 0.5754415988922119 epoch = 19 step = 687 loss = 0.2750820219516754
training: 0.5206813812255859 epoch = 19 step = 688 loss = 0.2642715871334076
training: 0.6105227470397949 epoch = 19 step = 689 loss = 0.2711876630783081
training: 0.7901656627655029 epoch = 19 step = 690 loss = 0.3122653365135193
training: 0.4710371494293213 epoch = 19 step = 691 loss = 0.3116723895072937
training: 0.5725252628326416 epoch = 20 step = 692 loss = 0.26614707708358765
training: 0.5889945030212402 epoch = 20 step = 693 loss = 0.3231494426727295
training: 0.6300745010375977 epoch = 20 step = 694 loss = 0.26307475566864014
training: 0.5178461074829102 epoch = 20 step = 695 loss = 0.27945995330810547
training: 0.5686848163604736 epoch = 20 step = 696 loss = 0.3382493555545807
training: 0.439241886138916 epoch = 20 step = 697 loss = 0.28500232100486755
training: 0.674548864364624 epoch = 20 step = 698 loss = 0.2997364103794098
training: 0.5308754444122314 epoch = 20 step = 699 loss = 0.2794893682003021
training: 0.4357421398162842 epoch = 20 step = 700 loss = 0.2721145749092102

Devolope:
Devoloped = 0.5545423030853271, epoch = 20 step = 701 loss = 0.4136544466018677
Devoloped = 0.5451724529266357, epoch = 20 step = 702 loss = 0.435349702835083
Devoloped = 0.5903787612915039, epoch = 20 step = 703 loss = 0.40969568490982056
Devoloped = 0.523953914642334, epoch = 20 step = 704 loss = 0.48014095425605774
Devoloped = 0.5014863014221191, epoch = 20 step = 705 loss = 0.46521633863449097
Devoloped = 0.5629258155822754, epoch = 20 step = 706 loss = 0.48223641514778137
Devoloped = 0.5120232105255127, epoch = 20 step = 707 loss = 0.3892689347267151
Devoloped = 0.37388157844543457, epoch = 20 step = 708 loss = 1.072015643119812

Evaluate:
[0 0 0 ... 0 0 0]
[0 0 0 ... 0 0 0]
Testing 0.9748623371124268 step = 708
 precision= 0.9276758409785932 recall= 0.9276758409785932 f1_score= 0.9276758409785932
708 0.9276758409785932 0.9276758409785932 0.9276758409785932

training: 0.5131266117095947 epoch = 20 step = 709 loss = 0.2996094226837158
training: 0.4783287048339844 epoch = 20 step = 710 loss = 0.298692911863327
training: 0.5077807903289795 epoch = 20 step = 711 loss = 0.32363176345825195
training: 0.3757026195526123 epoch = 20 step = 712 loss = 0.47724324464797974
training: 0.5608932971954346 epoch = 20 step = 713 loss = 0.3857451379299164
training: 0.4941849708557129 epoch = 20 step = 714 loss = 0.3530708849430084
training: 0.5124123096466064 epoch = 20 step = 715 loss = 0.3357754945755005
training: 0.6990208625793457 epoch = 20 step = 716 loss = 0.3375098407268524
training: 0.5624241828918457 epoch = 20 step = 717 loss = 0.3316928446292877
training: 0.5440168380737305 epoch = 20 step = 718 loss = 0.3139868974685669
training: 0.5786058902740479 epoch = 20 step = 719 loss = 0.30024290084838867
training: 0.5533342361450195 epoch = 20 step = 720 loss = 0.2951315939426422
training: 0.5410957336425781 epoch = 20 step = 721 loss = 0.2779519259929657
training: 0.5822761058807373 epoch = 20 step = 722 loss = 0.3873026967048645
training: 0.457491397857666 epoch = 20 step = 723 loss = 0.29977962374687195
training: 0.6728310585021973 epoch = 20 step = 724 loss = 0.3382991552352905
training: 0.5168819427490234 epoch = 20 step = 725 loss = 0.2892788350582123
training: 0.5930004119873047 epoch = 20 step = 726 loss = 0.28040799498558044
training: 0.5097553730010986 epoch = 20 step = 727 loss = 0.37349289655685425
training: 0.6627767086029053 epoch = 20 step = 728 loss = 0.3533540666103363
training: 0.6479592323303223 epoch = 20 step = 729 loss = 0.375737726688385
training: 0.39516305923461914 epoch = 20 step = 730 loss = 0.2919488549232483
training: 0.7146885395050049 epoch = 20 step = 731 loss = 0.3380265235900879
training: 0.37866806983947754 epoch = 20 step = 732 loss = 0.26754072308540344
training: 0.5345804691314697 epoch = 21 step = 733 loss = 0.27836504578590393
training: 0.5055990219116211 epoch = 21 step = 734 loss = 0.3338763117790222
training: 0.44872212409973145 epoch = 21 step = 735 loss = 0.2849721610546112
training: 0.5888447761535645 epoch = 21 step = 736 loss = 0.28103554248809814
training: 0.535170316696167 epoch = 21 step = 737 loss = 0.3057229816913605
training: 0.60286545753479 epoch = 21 step = 738 loss = 0.32448095083236694
training: 0.7239866256713867 epoch = 21 step = 739 loss = 0.31895196437835693
training: 0.6014740467071533 epoch = 21 step = 740 loss = 0.2875884771347046
training: 0.5965185165405273 epoch = 21 step = 741 loss = 0.3064769208431244
training: 0.5241575241088867 epoch = 21 step = 742 loss = 0.3024020791053772
training: 0.6902272701263428 epoch = 21 step = 743 loss = 0.2985055148601532
training: 0.5197958946228027 epoch = 21 step = 744 loss = 0.2867647409439087
training: 0.5564455986022949 epoch = 21 step = 745 loss = 0.3516770601272583
training: 0.4609341621398926 epoch = 21 step = 746 loss = 0.2987435758113861
training: 0.6048400402069092 epoch = 21 step = 747 loss = 0.28656062483787537
training: 0.49979233741760254 epoch = 21 step = 748 loss = 0.30293041467666626
training: 0.3876819610595703 epoch = 21 step = 749 loss = 0.2817113697528839
training: 0.4282064437866211 epoch = 21 step = 750 loss = 0.3118527829647064
training: 0.6887202262878418 epoch = 21 step = 751 loss = 0.3114702105522156
training: 0.48566555976867676 epoch = 21 step = 752 loss = 0.3006991744041443
training: 0.530663251876831 epoch = 21 step = 753 loss = 0.28079724311828613
training: 0.6172094345092773 epoch = 21 step = 754 loss = 0.270944207906723
training: 0.6722996234893799 epoch = 21 step = 755 loss = 0.27068963646888733
training: 0.5086441040039062 epoch = 21 step = 756 loss = 0.32012438774108887
training: 0.5819282531738281 epoch = 21 step = 757 loss = 0.2617533206939697
training: 0.4866039752960205 epoch = 21 step = 758 loss = 0.30741989612579346
training: 0.5041096210479736 epoch = 21 step = 759 loss = 0.3785318434238434
training: 0.4158353805541992 epoch = 21 step = 760 loss = 0.2773732841014862
training: 0.5701766014099121 epoch = 21 step = 761 loss = 0.2816179394721985
training: 0.5032744407653809 epoch = 21 step = 762 loss = 0.2979419231414795
training: 0.6833326816558838 epoch = 21 step = 763 loss = 0.3051283061504364
training: 0.48036837577819824 epoch = 21 step = 764 loss = 0.3033868074417114
training: 0.5430529117584229 epoch = 22 step = 765 loss = 0.2737751305103302
training: 0.5483226776123047 epoch = 22 step = 766 loss = 0.26512452960014343
training: 0.6270492076873779 epoch = 22 step = 767 loss = 0.26812759041786194
training: 0.4274716377258301 epoch = 22 step = 768 loss = 0.27458104491233826
training: 0.4670298099517822 epoch = 22 step = 769 loss = 0.2759720981121063
training: 0.47512197494506836 epoch = 22 step = 770 loss = 0.26394569873809814
training: 0.6004571914672852 epoch = 22 step = 771 loss = 0.26237115263938904
training: 0.6056888103485107 epoch = 22 step = 772 loss = 0.3149624168872833
training: 0.5220358371734619 epoch = 22 step = 773 loss = 0.2619819939136505
training: 0.7323987483978271 epoch = 22 step = 774 loss = 0.285495787858963
training: 0.38240694999694824 epoch = 22 step = 775 loss = 0.2898188531398773
training: 0.5836637020111084 epoch = 22 step = 776 loss = 0.2777749001979828
training: 0.5856425762176514 epoch = 22 step = 777 loss = 0.3602774143218994
training: 0.6821291446685791 epoch = 22 step = 778 loss = 0.2522318363189697
training: 0.5087778568267822 epoch = 22 step = 779 loss = 0.2662719786167145
training: 0.5285842418670654 epoch = 22 step = 780 loss = 0.26319029927253723
training: 0.49631237983703613 epoch = 22 step = 781 loss = 0.2788160443305969
training: 0.7465333938598633 epoch = 22 step = 782 loss = 0.2916673421859741
training: 0.4881014823913574 epoch = 22 step = 783 loss = 0.2633734345436096
training: 0.5150842666625977 epoch = 22 step = 784 loss = 0.2895776629447937
training: 0.45351743698120117 epoch = 22 step = 785 loss = 0.27066266536712646
training: 0.7242162227630615 epoch = 22 step = 786 loss = 0.26693809032440186
training: 0.5471231937408447 epoch = 22 step = 787 loss = 0.27501899003982544
training: 0.6886916160583496 epoch = 22 step = 788 loss = 0.2704025208950043
training: 0.5668537616729736 epoch = 22 step = 789 loss = 0.2740410566329956
training: 0.5483026504516602 epoch = 22 step = 790 loss = 0.285844087600708
training: 0.5325353145599365 epoch = 22 step = 791 loss = 0.2745487093925476
training: 0.5179779529571533 epoch = 22 step = 792 loss = 0.3066619634628296
training: 0.6565351486206055 epoch = 22 step = 793 loss = 0.25539547204971313
training: 0.5773160457611084 epoch = 22 step = 794 loss = 0.26535338163375854
training: 0.4948863983154297 epoch = 22 step = 795 loss = 0.25994864106178284
training: 0.5516476631164551 epoch = 22 step = 796 loss = 0.274413138628006
training: 0.6285741329193115 epoch = 23 step = 797 loss = 0.3500768840312958
training: 0.5400829315185547 epoch = 23 step = 798 loss = 0.27168625593185425
training: 0.4665210247039795 epoch = 23 step = 799 loss = 0.3013768792152405
training: 0.5454123020172119 epoch = 23 step = 800 loss = 0.2565633952617645

Devolope:
Devoloped = 0.7085864543914795, epoch = 23 step = 801 loss = 0.3969588875770569
Devoloped = 0.6170687675476074, epoch = 23 step = 802 loss = 0.4133793115615845
Devoloped = 0.5038609504699707, epoch = 23 step = 803 loss = 0.35854724049568176
Devoloped = 0.5928516387939453, epoch = 23 step = 804 loss = 0.3644934296607971
Devoloped = 0.47054123878479004, epoch = 23 step = 805 loss = 0.47807711362838745
Devoloped = 0.45431947708129883, epoch = 23 step = 806 loss = 0.47777238488197327
Devoloped = 0.6241903305053711, epoch = 23 step = 807 loss = 0.39509275555610657

Evaluate:
[0 0 0 ... 0 0 0]
[0 0 0 ... 0 0 0]
Testing 0.9812068939208984 step = 807
 precision= 0.9166666666666666 recall= 0.9166666666666666 f1_score= 0.9166666666666666
807 0.9166666666666666 0.9166666666666666 0.9166666666666666

training: 0.5294137001037598 epoch = 23 step = 808 loss = 0.25981202721595764
training: 0.4821949005126953 epoch = 23 step = 809 loss = 0.29064828157424927
training: 0.42286205291748047 epoch = 23 step = 810 loss = 0.27130386233329773
training: 0.7157690525054932 epoch = 23 step = 811 loss = 0.3082411587238312
training: 0.4086613655090332 epoch = 23 step = 812 loss = 0.28598660230636597
training: 0.5776731967926025 epoch = 23 step = 813 loss = 0.28539982438087463
training: 0.4522054195404053 epoch = 23 step = 814 loss = 0.24843305349349976
training: 0.7715256214141846 epoch = 23 step = 815 loss = 0.30226200819015503
training: 0.6275861263275146 epoch = 23 step = 816 loss = 0.27025872468948364
training: 0.5753037929534912 epoch = 23 step = 817 loss = 0.27707424759864807
training: 0.6711676120758057 epoch = 23 step = 818 loss = 0.27267324924468994
training: 0.47363710403442383 epoch = 23 step = 819 loss = 0.25417929887771606
training: 0.4729952812194824 epoch = 23 step = 820 loss = 0.2691662311553955
training: 0.6124961376190186 epoch = 23 step = 821 loss = 0.26903483271598816
training: 0.843925952911377 epoch = 23 step = 822 loss = 0.2782422602176666
training: 0.5908534526824951 epoch = 23 step = 823 loss = 0.2762727737426758
training: 0.5255169868469238 epoch = 23 step = 824 loss = 0.26774153113365173
training: 0.6561880111694336 epoch = 23 step = 825 loss = 0.25530511140823364
training: 0.5393013954162598 epoch = 23 step = 826 loss = 0.3171412944793701
training: 0.4690403938293457 epoch = 23 step = 827 loss = 0.2638544738292694
training: 0.5306520462036133 epoch = 23 step = 828 loss = 0.25019267201423645
training: 0.65802001953125 epoch = 23 step = 829 loss = 0.25320911407470703
training: 0.5818657875061035 epoch = 23 step = 830 loss = 0.24768447875976562
training: 0.44109177589416504 epoch = 23 step = 831 loss = 0.2642931640148163
training: 0.45481252670288086 epoch = 23 step = 832 loss = 0.26076024770736694
training: 0.74066162109375 epoch = 23 step = 833 loss = 0.2553746998310089
training: 0.4837827682495117 epoch = 23 step = 834 loss = 0.25130653381347656
training: 0.5175435543060303 epoch = 23 step = 835 loss = 0.25500231981277466
training: 0.38805270195007324 epoch = 23 step = 836 loss = 0.27517810463905334
training: 0.8189272880554199 epoch = 24 step = 837 loss = 0.26780563592910767
training: 0.4297327995300293 epoch = 24 step = 838 loss = 0.27989059686660767
training: 0.43185997009277344 epoch = 24 step = 839 loss = 0.2680012583732605
training: 0.5190610885620117 epoch = 24 step = 840 loss = 0.28399166464805603
training: 0.6456694602966309 epoch = 24 step = 841 loss = 0.25722363591194153
training: 0.5166263580322266 epoch = 24 step = 842 loss = 0.2632112503051758
training: 0.5730612277984619 epoch = 24 step = 843 loss = 0.25181522965431213
training: 0.4617321491241455 epoch = 24 step = 844 loss = 0.2573050856590271
training: 0.714536190032959 epoch = 24 step = 845 loss = 0.2578865885734558
training: 0.4259333610534668 epoch = 24 step = 846 loss = 0.25525641441345215
training: 0.499617338180542 epoch = 24 step = 847 loss = 0.27846020460128784
training: 0.4657282829284668 epoch = 24 step = 848 loss = 0.2666091322898865
training: 0.7623128890991211 epoch = 24 step = 849 loss = 0.24991020560264587
training: 0.4867696762084961 epoch = 24 step = 850 loss = 0.25355949997901917
training: 0.5861978530883789 epoch = 24 step = 851 loss = 0.25572147965431213
training: 0.4420638084411621 epoch = 24 step = 852 loss = 0.24409376084804535
training: 0.6522526741027832 epoch = 24 step = 853 loss = 0.24838297069072723
training: 0.5508043766021729 epoch = 24 step = 854 loss = 0.25772958993911743
training: 0.5054545402526855 epoch = 24 step = 855 loss = 0.25988495349884033
training: 0.7838642597198486 epoch = 24 step = 856 loss = 0.24697715044021606
training: 0.48162221908569336 epoch = 24 step = 857 loss = 0.24002715945243835
training: 0.5085258483886719 epoch = 24 step = 858 loss = 0.35731416940689087
training: 0.4153006076812744 epoch = 24 step = 859 loss = 0.26157575845718384
training: 0.7921617031097412 epoch = 24 step = 860 loss = 0.24515902996063232
training: 0.45828747749328613 epoch = 24 step = 861 loss = 0.2617473006248474
training: 0.5185315608978271 epoch = 24 step = 862 loss = 0.24204427003860474
training: 0.5379986763000488 epoch = 24 step = 863 loss = 0.2528309226036072
training: 0.7836148738861084 epoch = 24 step = 864 loss = 0.27538952231407166
training: 0.5312435626983643 epoch = 24 step = 865 loss = 0.25794485211372375
training: 0.4830808639526367 epoch = 24 step = 866 loss = 0.2363603115081787
training: 0.4597654342651367 epoch = 24 step = 867 loss = 0.2381548434495926
training: 0.6583943367004395 epoch = 24 step = 868 loss = 0.2612798810005188
training: 0.5331430435180664 epoch = 24 step = 869 loss = 0.22655044496059418
Evaluate:
Training:
[0 0 0 ... 0 0 0]
[0 0 0 ... 0 0 0]
Testing 0.9877800941467285 step = 869
 precision= 0.9001529051987768 recall= 0.9001529051987768 f1_score= 0.9001529051987768
869 0.9001529051987768 0.9001529051987768 0.9001529051987768
